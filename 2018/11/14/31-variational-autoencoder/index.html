
<!DOCTYPE html>
<html lang="zh-tw,en,default">
    
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Dream Maker">
    <title>31 Variational autoencoder - Dream Maker</title>
    <meta name="author" content="Yueh-Hua Tu">
    
        <meta name="keywords" content="machine learning,deep learning,topology,">
    
    
    
        <link rel="alternate" type="application/atom+xml" title="RSS" href="/atom.xml">
    
    <script type="application/ld+json">{"@context":"http://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Yueh-Hua Tu","sameAs":["https://github.com/yuehhua/","https://www.facebook.com/a504082002","https://www.linkedin.com/in/%E5%B2%B3%E8%8F%AF-%E6%9D%9C-6a3995a0/","mailto:a504082002@gmail.com"],"image":"https://www.gravatar.com/avatar/a565749fba4782b717234da670b273fd"},"articleBody":"在 autoencoder 的模型裏面，會希望以一個 unsupervised 方法來做到特徵萃取的目的。\n你也可以說他是一種降維的方法或是有損壓縮的方法。\n基本上就是透過一個線性轉換將原來的特徵，映射到比較低維度的特徵空間上。\n\n\n圖中就是一個基本的 autoencoder 的樣子，而中間的 hidden layer 就是我們希望的特徵萃取結果。\n我們希望所萃取到的特徵，可以被 還原 成原本圖形的樣子。他就會是類似壓縮跟解壓縮的概念。\n\n如果我們想看看他會壓縮成什麼樣子，我們可以將中間的 hidden layer 換成兩個 node 就好，如此一來，我們就可以將他視覺化。\n\n問題\n常常在訓練 autoencoder 之後，我們希望他的 decoder，也就是後半的部份，可以被拿出來作為一個獨立的 generative model 使用。例如，我可以把 MNIST 資料集當中的數字 1 的圖片輸入 encoder 會得到一個特徵向量 $\\mathbf{z}$，相對，這個特徵向量 $\\mathbf{z}$ 可以被放到 decoder 中還原回原本的數字 1 圖片，我們希望如果日後知道某個特徵向量 $\\mathbf{z}$ 也可以用同樣的作法還原出他原本的樣子。\n\n但往往行不通，在 $\\mathbf{z}$ 上有些許的差異，就有可能產生很奇怪的結果。原因在於訓練資料通過 encoder 之後所產生的特徵向量的（流形）空間分佈，只有在訓練資料相對應的特徵向量分佈的附近才能產生出好的結果，離這些特徵向量太遠的是沒辦法產生好的結果，所以模型沒有看到過的資料就無法產生好的結果。\nVariational autoencoder（VAE） 就是為了解決這樣的問題引進了 evidence lower bound（ELOB）的方法，並且將他改進成可用在 gradient-based method 上的模型。接下來會以兩種觀點切入講解，先講比較直觀的觀點。\n直觀觀點\n如果不在點附近的區域就無法產生合理的結果，我們可以去找出這些點是不是會呈現什麼樣的分佈，並且去得到這些分佈的參數。\n如果是使用機率分佈的話，就可以減少空間上有 洞 的情形發生，也就是比較不會有模型沒看過的資料的地方，導致產生的圖不合理的狀況。\n在 VAE 中，假設特徵向量會呈現常態分佈，所以我們會去計算這個分佈的平均值 $\\mu$ 與標準差 $\\sigma$，每個 hidden layer 的 node 都有一個相對應的平均值與標準差向量。\n\n相似的特徵向量會在空間分佈上在比較相近的位置，不同的特徵向量就各自形成各自的分佈情形。舉例來說，數字 1 的特徵向量會在空間分佈上比較接近，所以會形成一個分佈，跟數字 2 的分佈是不同的。如此一來，就可以用機率分佈的方式去涵蓋一些沒有被模型看過的資料。\n\n但是這要怎麼接續後面的 decoder 呢？當我們知道分佈之後，我們可以從分佈中做抽樣阿！\n既然是數字 1 的分佈，我就可以從這個分佈當中做抽樣，抽樣出來的向量應該要可以還原回原本的樣子。\n我們就可以將 encoder 跟 decoder 一起做訓練了！\n機率圖模型觀點\n接下來會以比較抽象的觀點來說明。\n隱含因素\n我們的目標是想造出一個 generative model，這個 generative model 需要產出不同的結果（$\\mathbf{x}$），例如 MNIST 數字，而且我們會給一個 input（$\\mathbf{z}$）來決定要產生出什麼數字，這個 input 就是決定要產生出什麼數字的 因素，我們希望從模型自己去學出來。整體來說，他是一個 unsupervised 問題，我們只能從結果（$\\mathbf{x}$）去做回推這個 generative model（$p(\\mathbf{x}, \\mathbf{z})$）的長相，並且試圖猜測 input（$\\mathbf{z}$）。\n作者從貝氏定理出發，我們手上的資料只有 $\\mathbf{x}$，想去求 $\\mathbf{z}$，我們會假設資料產生的過程是個隨機過程，他牽涉到一個無法觀察的變數 $\\mathbf{z}$。\n$$\np_{\\theta}(\\mathbf{z} | \\mathbf{x}) = \\frac{p_{\\theta}(\\mathbf{x}, \\mathbf{z})}{p_{\\theta}(\\mathbf{x})} = \\frac{p_{\\theta}(\\mathbf{x} | \\mathbf{z}) p_{\\theta}(\\mathbf{z})}{p_{\\theta}(\\mathbf{x})}\n$$\n這個過程包含了兩個部份：\n\n$p(\\mathbf{z})$，$\\mathbf{z}$ 是怎麼被產生的？\n$p(\\mathbf{x} | \\mathbf{z})$，$\\mathbf{x}$ 是如何從 $\\mathbf{z}$ 產生的？\n\n難題\n一般來說，使用貝氏定理會遇到一個難題，也就是需要知道分母怎麼估算，其中需要對 $\\mathbf{z}$ 積分，那麼就需要知道所有的 $\\mathbf{z}$ 排列組合，但是這是不可能的。\n$$\np_{\\theta}(\\mathbf{x}) = \\int p_{\\theta}(\\mathbf{x} | \\mathbf{z}) p_{\\theta}(\\mathbf{z}) d\\mathbf{z}\n$$\n目前貝氏的方法是用抽樣的方法（Markov chain Monte Calro）去估 $p_{\\theta}(\\mathbf{x})$，避開了直接去積分他。而且這樣的方法也太慢了，所以作者希望用 SGD 的方法來取代抽樣的方法。\nEvidence lower bound\n在這邊作者使用了 evidence lower bound（ELOB）的方法，既然要估 $p_{\\theta}(\\mathbf{x})$ 很困難，那麼我們直接去估 $p_{\\theta}(\\mathbf{z} | \\mathbf{x})$ 如何？\n那要怎麼估 $p_{\\theta}(\\mathbf{z} | \\mathbf{x})$ 呢？如果直接算的話就是回到上面的方法，所以 ELOB 方法假設了另一個類似的 $q_{\\phi}(\\mathbf{z} | \\mathbf{x})$ 來逼近 $p_{\\theta}(\\mathbf{z} | \\mathbf{x})$。\n要逼近 $p_{\\theta}(\\mathbf{z} | \\mathbf{x})$，也就是要求兩個機率分佈的 KL divergence（$D_{KL}[q_{\\phi}(\\mathbf{z} | \\mathbf{x}) || p_{\\theta}(\\mathbf{z} | \\mathbf{x})]$）愈小愈好。\n架構\n\n原本的問題就從左圖變成右圖，也就是以 $q_{\\phi}(\\mathbf{z} | \\mathbf{x})$ 來逼近 $p_{\\theta}(\\mathbf{z} | \\mathbf{x})$。$q_{\\phi}(\\mathbf{z} | \\mathbf{x})$ 就是虛線箭頭的部份。\n\n我們再把右圖當中的兩個箭頭拆開，$q_{\\phi}(\\mathbf{z} | \\mathbf{x})$ 就是 encoder，而在\n$$\np_{\\theta}(\\mathbf{z} | \\mathbf{x}) = \\frac{p_{\\theta}(\\mathbf{x} | \\mathbf{z}) p_{\\theta}(\\mathbf{z})}{p_{\\theta}(\\mathbf{x})}\n$$\n當中的 $p_{\\theta}(\\mathbf{x} | \\mathbf{z})$ 就是 decoder 的部份。Encoder 對應到實際神經網路模型中，則是一個 $\\mathbf{z} = f(\\mathbf{x})$ 函數，decoder 對應的是另一個函數 $\\mathbf{x} = g(\\mathbf{z})$。\n\n我們可以把他轉換成這個樣子，這樣就形成了 autoencoder 的架構雛型了。\n抽樣\n回到前面的老問題，我們用一些資料通過 encoder 之後可以得到被壓縮的資料，而我們去估計出這些資料的機率分佈，我們要如何從這些機率分佈繼續往下計算呢？\n是的！就是抽樣！我們會從這些機率分佈當中重新做抽樣，把他作為 decoder 的輸入，並且繼續做訓練。\n但是在模型中間卡一個抽樣的動作，這個動作引進了機率這個不確定因素，這樣要怎麼做 gradient descent 呢？\nReparametrization trick\n\n\n圖片來自 Tutorial on Variational Autoencoders\n\n左圖就是原本的抽樣的模型。要讓模型可以進行 gradient descent，這時候作者做了重新參數化的技巧，這樣的技巧就如同將抽樣的動作抽離出來，就如同右圖那樣。\n重新參數化技巧是從標準常態分佈當中去隨機抽樣，抽樣的結果將他乘上標準差，並且加上平均值，這樣就可以模擬從隱藏層的分佈抽樣的動作。但是這並非重新參數化技巧的巧妙之處，巧妙之處是在於重新參數化之後，就可以將抽樣這個動作從反向傳遞（backpropagation）的路徑上移除，這樣子我們就可以輕鬆的做訓練了！\n將抽樣的動作從反向傳遞的路徑上移除，你可以將這樣的抽樣動作看成資料的一部份，也就是原本的資料上會多加一筆從標準常態分佈的抽樣數值。而資料不也是抽樣而來的嗎？其實兩者的概念是等價的。\n結論\n這個模型結合了 Variational inference 的技巧，並且以 reparametrization trick 來讓模型可以用 gradient descent。這是非常重大的突破，他也開啟了生成型模型的一條路。真的非常推荐大家讀讀這個模型！不過原論文有點難懂就是了…\n","dateCreated":"2018-11-14T16:34:28+08:00","dateModified":"2019-01-01T22:04:26+08:00","datePublished":"2018-11-14T16:34:28+08:00","description":"在 autoencoder 的模型裏面，會希望以一個 unsupervised 方法來做到特徵萃取的目的。\n你也可以說他是一種降維的方法或是有損壓縮的方法。\n基本上就是透過一個線性轉換將原來的特徵，映射到比較低維度的特徵空間上。\n","headline":"31 Variational autoencoder","image":[],"mainEntityOfPage":{"@type":"WebPage","@id":"https://yuehhua.github.io/2018/11/14/31-variational-autoencoder/"},"publisher":{"@type":"Organization","name":"Yueh-Hua Tu","sameAs":["https://github.com/yuehhua/","https://www.facebook.com/a504082002","https://www.linkedin.com/in/%E5%B2%B3%E8%8F%AF-%E6%9D%9C-6a3995a0/","mailto:a504082002@gmail.com"],"image":"https://www.gravatar.com/avatar/a565749fba4782b717234da670b273fd","logo":{"@type":"ImageObject","url":"https://www.gravatar.com/avatar/a565749fba4782b717234da670b273fd"}},"url":"https://yuehhua.github.io/2018/11/14/31-variational-autoencoder/"}</script>
    <meta name="description" content="在 autoencoder 的模型裏面，會希望以一個 unsupervised 方法來做到特徵萃取的目的。 你也可以說他是一種降維的方法或是有損壓縮的方法。 基本上就是透過一個線性轉換將原來的特徵，映射到比較低維度的特徵空間上。">
<meta property="og:type" content="blog">
<meta property="og:title" content="31 Variational autoencoder">
<meta property="og:url" content="https://yuehhua.github.io/2018/11/14/31-variational-autoencoder/index.html">
<meta property="og:site_name" content="Dream Maker">
<meta property="og:description" content="在 autoencoder 的模型裏面，會希望以一個 unsupervised 方法來做到特徵萃取的目的。 你也可以說他是一種降維的方法或是有損壓縮的方法。 基本上就是透過一個線性轉換將原來的特徵，映射到比較低維度的特徵空間上。">
<meta property="og:locale" content="zh_TW">
<meta property="og:image" content="https://yuehhua.github.io/images/autoencoder1.svg">
<meta property="og:image" content="https://yuehhua.github.io/images/autoencoder2.svg">
<meta property="og:image" content="https://yuehhua.github.io/images/autoencoder3.svg">
<meta property="og:image" content="https://yuehhua.github.io/images/autoencoder3.svg">
<meta property="og:image" content="https://yuehhua.github.io/images/VAE1.svg">
<meta property="og:image" content="https://yuehhua.github.io/images/VAE2.svg">
<meta property="og:image" content="https://yuehhua.github.io/images/VAE3.svg">
<meta property="og:image" content="https://yuehhua.github.io/images/VAE4.svg">
<meta property="og:image" content="https://yuehhua.github.io/images/VAE5.svg">
<meta property="og:image" content="https://yuehhua.github.io/images/1606.05908.svg">
<meta property="article:published_time" content="2018-11-14T08:34:28.000Z">
<meta property="article:modified_time" content="2019-01-01T14:04:26.947Z">
<meta property="article:author" content="Yueh-Hua Tu">
<meta property="article:tag" content="machine learning">
<meta property="article:tag" content="deep learning">
<meta property="article:tag" content="topology">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://yuehhua.github.io/images/autoencoder1.svg">
    
    
        
    
    
    
    
    
    <!--STYLES-->
    
<link rel="stylesheet" href="/assets/css/style-3frockyt2j28isvdztjchy5nhkz8tjki9ermufc1ckptmvjdftux94m2ahub.min.css">

    <!--STYLES END-->
    
    <script type="text/javascript">
        (function (i, s, o, g, r, a, m) {
        i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
            (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date(); a = s.createElement(o),
            m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
        })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-119690895-1', 'auto');
        ga('send', 'pageview');
    </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
    
    
</head>

    <body>
        <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="blog">
            <!-- Define author's picture -->


    

<header id="header" data-behavior="5">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a class="header-title-link" href="/%20">Dream Maker</a>
    </div>
    
        
            <a  class="header-right-picture "
                href="#about">
        
        
        </a>
    
</header>

            <!-- Define author's picture -->


<nav id="sidebar" data-behavior="5">
    <div class="sidebar-container">
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/%20"
                            
                            title="首頁"
                        >
                    
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">首頁</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/all-categories"
                            
                            title="分類"
                        >
                    
                        <i class="sidebar-button-icon fa fa-bookmark" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">分類</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/all-tags"
                            
                            title="標籤"
                        >
                    
                        <i class="sidebar-button-icon fa fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">標籤</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/all-archives"
                            
                            title="所有文章"
                        >
                    
                        <i class="sidebar-button-icon fa fa-archive" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">所有文章</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link open-algolia-search"
                             href="#search"
                            
                            title="搜尋"
                        >
                    
                        <i class="sidebar-button-icon fa fa-search" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">搜尋</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="#about"
                            
                            title="關於"
                        >
                    
                        <i class="sidebar-button-icon fa fa-question" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">關於</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link " href="https://github.com/yuehhua/" target="_blank" rel="noopener" title="GitHub">
                    
                        <i class="sidebar-button-icon fab fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">GitHub</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link " href="https://www.facebook.com/a504082002" target="_blank" rel="noopener" title="Facebook">
                    
                        <i class="sidebar-button-icon fab fa-facebook" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Facebook</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link " href="https://www.linkedin.com/in/%E5%B2%B3%E8%8F%AF-%E6%9D%9C-6a3995a0/" target="_blank" rel="noopener" title="LinkedIn">
                    
                        <i class="sidebar-button-icon fab fa-linkedin" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">LinkedIn</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link " href="mailto:a504082002@gmail.com" target="_blank" rel="noopener" title="Email">
                    
                        <i class="sidebar-button-icon fab fa-envelope" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Email</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/atom.xml"
                            
                            title="Atom"
                        >
                    
                        <i class="sidebar-button-icon fa fa-rss" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Atom</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="5"
                 class="
                        hasCoverMetaIn
                        ">
                
    <article class="post">
        
                
                    <div class="post-header main-content-wrap text-left">
    
        <h1 class="post-title">
            31 Variational autoencoder
        </h1>
    
    
        <div class="post-meta">
    <time datetime="2018-11-14T16:34:28+08:00">
	
		    11月 14, 2018
    	
    </time>
    
        <span>分類 </span>
        
    <a class="category-link" href="/categories/Machine-Learning/">Machine Learning</a>, <a class="category-link" href="/categories/Machine-Learning/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%A8%A1%E5%9E%8B%E5%9C%96%E6%9B%B8%E9%A4%A8%EF%BC%9A%E5%BE%9E%E5%82%B3%E7%B5%B1%E6%A8%A1%E5%9E%8B%E5%88%B0%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92/">機器學習模型圖書館：從傳統模型到深度學習</a>


    
</div>

    
</div>

                        
                            <div class="post-content markdown">
                                <div class="main-content-wrap">
                                    <p>在 autoencoder 的模型裏面，會希望以一個 unsupervised 方法來做到特徵萃取的目的。</p>
<p>你也可以說他是一種降維的方法或是有損壓縮的方法。</p>
<p>基本上就是透過一個線性轉換將原來的特徵，映射到比較低維度的特徵空間上。</p>
<p><img src="/images/autoencoder1.svg" alt=""></p>
<a id="more"></a>
<p>圖中就是一個基本的 autoencoder 的樣子，而中間的 hidden layer 就是我們希望的特徵萃取結果。</p>
<p>我們希望所萃取到的特徵，可以被 <strong>還原</strong> 成原本圖形的樣子。他就會是類似壓縮跟解壓縮的概念。</p>
<p><img src="/images/autoencoder2.svg" alt=""></p>
<p>如果我們想看看他會壓縮成什麼樣子，我們可以將中間的 hidden layer 換成兩個 node 就好，如此一來，我們就可以將他視覺化。</p>
<p><img src="/images/autoencoder3.svg" alt=""></p>
<h2 id="問題">問題</h2>
<p>常常在訓練 autoencoder 之後，我們希望他的 decoder，也就是後半的部份，可以被拿出來作為一個獨立的 generative model 使用。例如，我可以把 MNIST 資料集當中的數字 1 的圖片輸入 encoder 會得到一個特徵向量 $\mathbf{z}$，相對，這個特徵向量 $\mathbf{z}$ 可以被放到 decoder 中還原回原本的數字 1 圖片，我們希望如果日後知道某個特徵向量 $\mathbf{z}$ 也可以用同樣的作法還原出他原本的樣子。</p>
<p><img src="/images/autoencoder3.svg" alt=""></p>
<p>但往往行不通，在 $\mathbf{z}$ 上有些許的差異，就有可能產生很奇怪的結果。原因在於訓練資料通過 encoder 之後所產生的特徵向量的（流形）空間分佈，只有在訓練資料相對應的特徵向量分佈的附近才能產生出好的結果，離這些特徵向量太遠的是沒辦法產生好的結果，所以模型沒有看到過的資料就無法產生好的結果。</p>
<p>Variational autoencoder（VAE） 就是為了解決這樣的問題引進了 evidence lower bound（ELOB）的方法，並且將他改進成可用在 gradient-based method 上的模型。接下來會以兩種觀點切入講解，先講比較直觀的觀點。</p>
<h2 id="直觀觀點">直觀觀點</h2>
<p>如果不在點附近的區域就無法產生合理的結果，我們可以去找出這些點是不是會呈現什麼樣的分佈，並且去得到這些分佈的參數。</p>
<p>如果是使用機率分佈的話，就可以減少空間上有 <strong>洞</strong> 的情形發生，也就是比較不會有模型沒看過的資料的地方，導致產生的圖不合理的狀況。</p>
<p>在 VAE 中，假設特徵向量會呈現常態分佈，所以我們會去計算這個分佈的平均值 $\mu$ 與標準差 $\sigma$，每個 hidden layer 的 node 都有一個相對應的平均值與標準差向量。</p>
<p><img src="/images/VAE1.svg" alt=""></p>
<p>相似的特徵向量會在空間分佈上在比較相近的位置，不同的特徵向量就各自形成各自的分佈情形。舉例來說，數字 1 的特徵向量會在空間分佈上比較接近，所以會形成一個分佈，跟數字 2 的分佈是不同的。如此一來，就可以用機率分佈的方式去涵蓋一些沒有被模型看過的資料。</p>
<p><img src="/images/VAE2.svg" alt=""></p>
<p>但是這要怎麼接續後面的 decoder 呢？當我們知道分佈之後，我們可以從分佈中做抽樣阿！</p>
<p>既然是數字 1 的分佈，我就可以從這個分佈當中做抽樣，抽樣出來的向量應該要可以還原回原本的樣子。</p>
<p>我們就可以將 encoder 跟 decoder 一起做訓練了！</p>
<h2 id="機率圖模型觀點">機率圖模型觀點</h2>
<p>接下來會以比較抽象的觀點來說明。</p>
<h3 id="隱含因素">隱含因素</h3>
<p>我們的目標是想造出一個 generative model，這個 generative model 需要產出不同的結果（$\mathbf{x}$），例如 MNIST 數字，而且我們會給一個 input（$\mathbf{z}$）來決定要產生出什麼數字，這個 input 就是決定要產生出什麼數字的 <strong>因素</strong>，我們希望從模型自己去學出來。整體來說，他是一個 unsupervised 問題，我們只能從結果（$\mathbf{x}$）去做回推這個 generative model（$p(\mathbf{x}, \mathbf{z})$）的長相，並且試圖猜測 input（$\mathbf{z}$）。</p>
<p>作者從貝氏定理出發，我們手上的資料只有 $\mathbf{x}$，想去求 $\mathbf{z}$，我們會假設資料產生的過程是個隨機過程，他牽涉到一個無法觀察的變數 $\mathbf{z}$。</p>
<p>$$<br>
p_{\theta}(\mathbf{z} | \mathbf{x}) = \frac{p_{\theta}(\mathbf{x}, \mathbf{z})}{p_{\theta}(\mathbf{x})} = \frac{p_{\theta}(\mathbf{x} | \mathbf{z}) p_{\theta}(\mathbf{z})}{p_{\theta}(\mathbf{x})}<br>
$$</p>
<p>這個過程包含了兩個部份：</p>
<ol>
<li>$p(\mathbf{z})$，$\mathbf{z}$ 是怎麼被產生的？</li>
<li>$p(\mathbf{x} | \mathbf{z})$，$\mathbf{x}$ 是如何從 $\mathbf{z}$ 產生的？</li>
</ol>
<h3 id="難題">難題</h3>
<p>一般來說，使用貝氏定理會遇到一個難題，也就是需要知道分母怎麼估算，其中需要對 $\mathbf{z}$ 積分，那麼就需要知道所有的 $\mathbf{z}$ 排列組合，但是這是不可能的。</p>
<p>$$<br>
p_{\theta}(\mathbf{x}) = \int p_{\theta}(\mathbf{x} | \mathbf{z}) p_{\theta}(\mathbf{z}) d\mathbf{z}<br>
$$</p>
<p>目前貝氏的方法是用抽樣的方法（Markov chain Monte Calro）去估 $p_{\theta}(\mathbf{x})$，避開了直接去積分他。而且這樣的方法也太慢了，所以作者希望用 SGD 的方法來取代抽樣的方法。</p>
<h3 id="Evidence-lower-bound">Evidence lower bound</h3>
<p>在這邊作者使用了 evidence lower bound（ELOB）的方法，既然要估 $p_{\theta}(\mathbf{x})$ 很困難，那麼我們直接去估 $p_{\theta}(\mathbf{z} | \mathbf{x})$ 如何？</p>
<p>那要怎麼估 $p_{\theta}(\mathbf{z} | \mathbf{x})$ 呢？如果直接算的話就是回到上面的方法，所以 ELOB 方法假設了另一個類似的 $q_{\phi}(\mathbf{z} | \mathbf{x})$ 來逼近 $p_{\theta}(\mathbf{z} | \mathbf{x})$。</p>
<p>要逼近 $p_{\theta}(\mathbf{z} | \mathbf{x})$，也就是要求兩個機率分佈的 KL divergence（$D_{KL}[q_{\phi}(\mathbf{z} | \mathbf{x}) || p_{\theta}(\mathbf{z} | \mathbf{x})]$）愈小愈好。</p>
<h3 id="架構">架構</h3>
<p><img src="/images/VAE3.svg" alt=""></p>
<p>原本的問題就從左圖變成右圖，也就是以 $q_{\phi}(\mathbf{z} | \mathbf{x})$ 來逼近 $p_{\theta}(\mathbf{z} | \mathbf{x})$。$q_{\phi}(\mathbf{z} | \mathbf{x})$ 就是虛線箭頭的部份。</p>
<p><img src="/images/VAE4.svg" alt=""></p>
<p>我們再把右圖當中的兩個箭頭拆開，$q_{\phi}(\mathbf{z} | \mathbf{x})$ 就是 encoder，而在</p>
<p>$$<br>
p_{\theta}(\mathbf{z} | \mathbf{x}) = \frac{p_{\theta}(\mathbf{x} | \mathbf{z}) p_{\theta}(\mathbf{z})}{p_{\theta}(\mathbf{x})}<br>
$$</p>
<p>當中的 $p_{\theta}(\mathbf{x} | \mathbf{z})$ 就是 decoder 的部份。Encoder 對應到實際神經網路模型中，則是一個 $\mathbf{z} = f(\mathbf{x})$ 函數，decoder 對應的是另一個函數 $\mathbf{x} = g(\mathbf{z})$。</p>
<p><img src="/images/VAE5.svg" alt=""></p>
<p>我們可以把他轉換成這個樣子，這樣就形成了 autoencoder 的架構雛型了。</p>
<h3 id="抽樣">抽樣</h3>
<p>回到前面的老問題，我們用一些資料通過 encoder 之後可以得到被壓縮的資料，而我們去估計出這些資料的機率分佈，我們要如何從這些機率分佈繼續往下計算呢？</p>
<p>是的！就是抽樣！我們會從這些機率分佈當中重新做抽樣，把他作為 decoder 的輸入，並且繼續做訓練。</p>
<p>但是在模型中間卡一個抽樣的動作，這個動作引進了機率這個不確定因素，這樣要怎麼做 gradient descent 呢？</p>
<h3 id="Reparametrization-trick">Reparametrization trick</h3>
<p><img src="/images/1606.05908.svg" alt=""></p>
<blockquote>
<p>圖片來自 <a href="https://arxiv.org/abs/1606.05908" target="_blank" rel="noopener">Tutorial on Variational Autoencoders</a></p>
</blockquote>
<p>左圖就是原本的抽樣的模型。要讓模型可以進行 gradient descent，這時候作者做了重新參數化的技巧，這樣的技巧就如同將抽樣的動作抽離出來，就如同右圖那樣。</p>
<p>重新參數化技巧是從標準常態分佈當中去隨機抽樣，抽樣的結果將他乘上標準差，並且加上平均值，這樣就可以模擬從隱藏層的分佈抽樣的動作。但是這並非重新參數化技巧的巧妙之處，巧妙之處是在於重新參數化之後，就可以將抽樣這個動作從反向傳遞（backpropagation）的路徑上移除，這樣子我們就可以輕鬆的做訓練了！</p>
<p>將抽樣的動作從反向傳遞的路徑上移除，你可以將這樣的抽樣動作看成資料的一部份，也就是原本的資料上會多加一筆從標準常態分佈的抽樣數值。而資料不也是抽樣而來的嗎？其實兩者的概念是等價的。</p>
<h2 id="結論">結論</h2>
<p>這個模型結合了 Variational inference 的技巧，並且以 reparametrization trick 來讓模型可以用 gradient descent。這是非常重大的突破，他也開啟了生成型模型的一條路。真的非常推荐大家讀讀這個模型！不過原論文有點難懂就是了…</p>

                                        

                                </div>
                            </div>
                            <div id="post-footer" class="post-footer main-content-wrap">
                                
                                        
                                            <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                    <a class="post-action-btn btn btn--default tooltip--top" href="/2018/12/15/ning/" data-tooltip="紀念 - 風超大的高美濕地" aria-label="上一篇: 紀念 - 風超大的高美濕地">
                
                    <i class="fa fa-angle-left" aria-hidden="true"></i>
                    <span class="hide-xs hide-sm text-small icon-ml">上一篇</span>
                </a>
            </li>
            <li class="post-action">
                
                    
                    <a class="post-action-btn btn btn--default tooltip--top" href="/2018/10/31/30-conclusions/" data-tooltip="30 結語" aria-label="下一篇: 30 結語">
                
                    <span class="hide-xs hide-sm text-small icon-mr">下一篇</span>
                    <i class="fa fa-angle-right" aria-hidden="true"></i>
                </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions" aria-label="Share this post">
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://yuehhua.github.io/2018/11/14/31-variational-autoencoder/" title="分享到 Facebook">
                    <i class="fa fa-facebook-official" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
                <li class="post-action">
                    <a class="post-action-btn btn btn--default" href="#disqus_thread">
                        <i class="fa fa-comment-o"></i>
                    </a>
                </li>
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#" aria-label="Back to top">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


                                                
                                                    
                                                        
                                                            <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript" target="_blank" rel="noopener">comments powered by Disqus.</a></noscript>
</div>
                                                                
                                                                            
                            </div>
                            
                                <script src='https://unpkg.com/mermaid@7.1.2/dist/mermaid.min.js'></script>
                                <script>
                                    if (window.mermaid) {
                                        mermaid.initialize({ theme: 'forest' });
                                    }
                                </script>
                                
    </article>

                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2021 Yueh-Hua Tu. All Rights Reserved.
    </span>
</footer>

            </div>
            
                <div id="bottom-bar" class="post-bottom-bar" data-behavior="5">
                    <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                    <a class="post-action-btn btn btn--default tooltip--top" href="/2018/12/15/ning/" data-tooltip="紀念 - 風超大的高美濕地" aria-label="上一篇: 紀念 - 風超大的高美濕地">
                
                    <i class="fa fa-angle-left" aria-hidden="true"></i>
                    <span class="hide-xs hide-sm text-small icon-ml">上一篇</span>
                </a>
            </li>
            <li class="post-action">
                
                    
                    <a class="post-action-btn btn btn--default tooltip--top" href="/2018/10/31/30-conclusions/" data-tooltip="30 結語" aria-label="下一篇: 30 結語">
                
                    <span class="hide-xs hide-sm text-small icon-mr">下一篇</span>
                    <i class="fa fa-angle-right" aria-hidden="true"></i>
                </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions" aria-label="Share this post">
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://yuehhua.github.io/2018/11/14/31-variational-autoencoder/" title="分享到 Facebook">
                    <i class="fa fa-facebook-official" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
                <li class="post-action">
                    <a class="post-action-btn btn btn--default" href="#disqus_thread">
                        <i class="fa fa-comment-o"></i>
                    </a>
                </li>
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#" aria-label="Back to top">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


                </div>
                <div id="share-options-bar" class="share-options-bar" data-behavior="5">
    <i id="btn-close-shareoptions" class="fa fa-close"></i>
    <ul class="share-options">
        
            
            
            <li class="share-option">
                <a class="share-option-btn" target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://yuehhua.github.io/2018/11/14/31-variational-autoencoder/">
                    <i class="fa fa-facebook-official" aria-hidden="true"></i><span>分享到 Facebook</span>
                </a>
            </li>
        
    </ul>
</div>

            
        </div>
        


<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-remove"></i>
        </div>
        
            <h4 id="about-card-name">Yueh-Hua Tu</h4>
        
            <div id="about-card-bio"><p>目標是計算生物學家！</br>Systems Biology, Computational Biology, Machine Learning</br>Julia Taiwan 發起人</p>
</div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                <p>研發替代役研究助理</p>

            </div>
        
        
            <div id="about-card-location">
                <i class="fa fa-map-marker"></i>
                <br/>
                Taiwan
            </div>
        
    </div>
</div>

        
        
<div id="cover" style="background-image:url('/assets/images/cover.jpg');"></div>
        <!--SCRIPTS-->

<script src="/assets/js/script-xzfezjobyekpxrjktw5tz6muvzqfsbmo5n6atk3p5om9ulfptldi3p7cyqd8.min.js"></script>

<!--SCRIPTS END-->


<script>
    var disqus_config = function () {
        this.page.url = 'https://yuehhua.github.io/2018/11/14/31-variational-autoencoder/';
                 
            this.page.identifier = '2018/11/14/31-variational-autoencoder/';
                 
             };
    (function () {
        var d = document, s = d.createElement('script');
        var disqus_shortname = 'dream-maker';
        s.src = '//' + disqus_shortname + '.disqus.com/embed.js';

        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/latest.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->



    </body>
</html>
