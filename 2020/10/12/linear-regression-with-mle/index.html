
<!DOCTYPE html>
<html lang="zh-tw,en,default">
    
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Dream Maker">
    <title>Linear Regression with Maximum Likelihood Estimation - Dream Maker</title>
    <meta name="author" content="Yueh-Hua Tu">
    
        <meta name="keywords" content="machine learning,deep learning,topology,">
    
    
    
        <link rel="alternate" type="application/atom+xml" title="RSS" href="/atom.xml">
    
    <script type="application/ld+json">{"@context":"http://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Yueh-Hua Tu","sameAs":["https://github.com/yuehhua/","https://www.facebook.com/a504082002","https://www.linkedin.com/in/%E5%B2%B3%E8%8F%AF-%E6%9D%9C-6a3995a0/","mailto:a504082002@gmail.com"],"image":"https://www.gravatar.com/avatar/a565749fba4782b717234da670b273fd"},"articleBody":"Maximum likelihood estimation is an essential approach to estimate parameters in statistics. It requires statistical assumptions on error pattern. I will introduce this technique with really simple statistical model - linear regression.\n\nWe usually want to infer the relationship between input and output. They can be cause and effect of a physical phenomena or some indirect relationship in social science. We always want to realize the truth about our interest. Statistical tools are the tools to help you. The relationship between input and output are formulated as a mathematical function as follow:\n$$\ny = f(x)\n$$\nA linear model is assumed in linear regression. The relationship between $x$ and $y$ is assumed to be linear and $w$ and $b$ are introduced as unknown parameters into the model. $w$ denotes the extent of $x$ contributing to $y$ while $b$ denotes an inherent bias in $y$.\n$$\ny = wx + b\n$$\nOn the other side, data are collected in pair of $(x^i, y^i)$. The superscript $n$ denotes the index for each sample.\n$$\n\\mathcal{D} = {(x^1, y^1), (x^2, y^2), \\cdots, (x^n, y^n)}\n$$\nThe maximum likelihood estimation starts from the likelihood function. A likelihood function quantified the likelihood of data generation from the model we specified. That is, how likely the sample $(x_i, y_i)$ are generated from the model. All parameters are reduced into $\\theta$. Precisely, $\\mathcal{L}(\\theta \\mid \\mathcal{D})$ represents the likelihood of model with parameter $\\theta$ given data $\\mathcal{D}$. Notably, data is fixed here. Thus, we want the most likely model that fits our samples. The model with maximum likelihood is estimated.\n$$\n\\begin{aligned}\n\\mathcal{L}(\\theta \\mid \\mathcal{D}) &amp;= f(\\mathcal{D} \\mid \\theta) \\\\\n&amp;= p((x^1, y^1), (x^2, y^2), \\cdots, (x^n, y^n) \\mid \\theta)\n\\end{aligned}\n$$\nA probability distribution is used to estimate the likelihood of model $\\theta$. The interpretation here is the probability of data generation from the model $\\theta$.\n$$\n\\begin{aligned}\n\\mathcal{L}(\\theta \\mid \\mathcal{D}) &amp;= p((x^1, y^1), (x^2, y^2), \\cdots, (x^n, y^n) \\mid \\theta) \\\\\n&amp;= p((x^1, y^1) \\mid \\theta) \\cdot p((x^2, y^2) \\mid \\theta) \\cdots p((x^n, y^n) \\mid \\theta)\n\\end{aligned}\n$$\nIt is formed from the joint probability distributions. A critical statistical assumption is introduced here. Samples $(x^i, y^i)$ are generated independently such that the joint probability can be splitted into multiplcation of probabilities. Further, samples are generated from the same population/model $\\theta$. So, we call that data are independently, identically distributed, or iid, generated from some model.\n$$\n\\begin{aligned}\n\\mathcal{L}(\\theta \\mid \\mathcal{D}) &amp;= p((x^1, y^1) \\mid \\theta) \\cdot p((x^2, y^2) \\mid \\theta) \\cdots p((x^n, y^n) \\mid \\theta) \\\\\n&amp;= \\prod_{i=1}^n p((x^i, y^i) \\mid \\theta)\n\\end{aligned}\n$$\nNormal distribution is used as error pattern in linear regression model. A linear regression model always infers the mean value of $y$ given $x$. The uncertainty of $y$ can be described by normal distribution. We add an error term after the linear regression model.\n$$\ny = wx + b + \\epsilon\n$$\n$$\n\\epsilon = y - wx - b = \\mathcal{N}(z \\mid \\mu = 0, \\sigma^2)\n$$\nOr we can rewrite it into\n$$\n\\epsilon = \\mathcal{N}(y - wx - b \\mid \\mu = 0, \\sigma^2)\n$$\nwhere $\\mathcal{N}(x \\mid \\mu, \\sigma^2) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} exp(-\\frac{1}{2} (\\frac{x-\\mu}{\\sigma})^2)$.\nLikelihood function would be\n$$\n\\begin{aligned}\n\\mathcal{L}(\\theta \\mid \\mathcal{D}) &amp;= \\prod_{i=1}^n p((x^i, y^i) \\mid \\theta) \\\\\n&amp;= \\prod_{i=1}^n \\mathcal{N}(y^i - wx^i - b \\mid \\mu = 0, \\sigma^2)\n\\end{aligned}\n$$.\nNegative log likelihood would be\n$$\n\\begin{aligned}\n\\mathcal{l}(\\theta \\mid \\mathcal{D}) &amp;= - ln \\mathcal{L}(\\theta \\mid \\mathcal{D}) \\\\\n&amp;= - ln \\prod_{i=1}^n \\mathcal{N}(y^i - wx^i - b \\mid \\mu = 0, \\sigma^2) \\\\\n&amp;= - ln \\prod_{i=1}^n \\mathcal{N}(y^i - wx^i - b \\mid \\mu = 0, \\sigma^2) \\\\\n&amp;= - \\sum_{i=1}^n ln \\mathcal{N}(y^i - wx^i - b \\mid \\mu = 0, \\sigma^2) \\\\\n&amp;= - \\sum_{i=1}^n - \\frac{1}{2} (\\frac{y^i - wx^i - b - 0}{\\sigma})^2 - ln(\\sigma \\sqrt{2 \\pi}) \\\\\n&amp;= \\sum_{i=1}^n \\frac{1}{2} (\\frac{y^i - wx^i - b}{\\sigma})^2 + ln(\\sigma) + ln(\\sqrt{2 \\pi})\n\\end{aligned}\n$$\nThe primal goal is to maximize likelihood function $\\arg\\max_{\\theta} \\mathcal{L}(\\theta \\mid \\mathcal{D})$, while we have to minimize the negative log likelihood (NLL) function\n$$\n\\arg\\min_{\\theta} \\mathcal{l}(\\theta \\mid \\mathcal{D})\n$$.\nTo solve this problem, we need to calculate the first-order derivative of NLL. The minimum value happens while $\\frac{\\partial \\mathcal{l}}{\\partial w} = 0$ and $\\frac{\\partial \\mathcal{l}}{\\partial b} = 0$ are satisfied.\n$$\n\\begin{aligned}\n\\frac{\\partial \\mathcal{l}}{\\partial w} &amp;= \\frac{\\partial}{\\partial w} \\sum_{i=1}^n \\frac{1}{2} (\\frac{y^i - wx^i - b}{\\sigma})^2 + ln(\\sigma) + ln(\\sqrt{2 \\pi}) \\\\\n&amp;= \\sum_{i=1}^n \\frac{y^i - wx^i - b}{\\sigma} \\cdot \\frac{\\partial}{\\partial w} \\frac{y^i - wx^i - b}{\\sigma} \\\\\n&amp;= \\sum_{i=1}^n \\frac{y^i - wx^i - b}{\\sigma} \\frac{-x^i}{\\sigma} \\\\\n&amp;= \\frac{-1}{\\sigma^2} \\sum_{i=1}^n x^i (y^i - wx^i - b) \\\\\n&amp;= 0\n\\end{aligned}\n$$\n$$\n\\begin{aligned}\n\\frac{-1}{\\sigma^2} \\sum_{i=1}^n x^i (y^i - wx^i - b) &amp;= 0 \\\\\n\\sum_{i=1}^n x^i (y^i - wx^i - b) &amp;= 0 \\\\\n\\sum_{i=1}^n{x^i y^i} - w \\sum_{i=1}^n{(x^i)^2} - b \\sum_{i=1}^n{x^i} &amp;= 0\n\\end{aligned}\n$$\nThe same way we can have\n$$\n\\sum_{i=1}^n{y^i} - w \\sum_{i=1}^n{x^i} - b = 0\n$$\nderived from $\\frac{\\partial \\mathcal{l}}{\\partial b} = 0$.\nFinally, we can estimate the parameters from the following two equations:\n$$\n\\begin{cases}\n(\\sum_{i=1}^n{(x^i)^2}) w + (\\sum_{i=1}^n{x^i}) b = \\sum_{i=1}^n{x^i y^i} \\\\\n(\\sum_{i=1}^n{x^i}) w + b = \\sum_{i=1}^n{y^i}\n\\end{cases}\n$$\n$$\n\\begin{cases}\nw = ? \\\\\nb = ?\n\\end{cases}\n$$\n","dateCreated":"2020-10-12T01:20:57+08:00","dateModified":"2020-10-12T01:21:50+08:00","datePublished":"2020-10-12T01:20:57+08:00","description":"Maximum likelihood estimation is an essential approach to estimate parameters in statistics. It requires statistical assumptions on error pattern. I will introduce this technique with really simple statistical model - linear regression.","headline":"Linear Regression with Maximum Likelihood Estimation","image":[],"mainEntityOfPage":{"@type":"WebPage","@id":"https://yuehhua.github.io/2020/10/12/linear-regression-with-mle/"},"publisher":{"@type":"Organization","name":"Yueh-Hua Tu","sameAs":["https://github.com/yuehhua/","https://www.facebook.com/a504082002","https://www.linkedin.com/in/%E5%B2%B3%E8%8F%AF-%E6%9D%9C-6a3995a0/","mailto:a504082002@gmail.com"],"image":"https://www.gravatar.com/avatar/a565749fba4782b717234da670b273fd","logo":{"@type":"ImageObject","url":"https://www.gravatar.com/avatar/a565749fba4782b717234da670b273fd"}},"url":"https://yuehhua.github.io/2020/10/12/linear-regression-with-mle/"}</script>
    <meta name="description" content="Maximum likelihood estimation is an essential approach to estimate parameters in statistics. It requires statistical assumptions on error pattern. I will introduce this technique with really simple st">
<meta property="og:type" content="blog">
<meta property="og:title" content="Linear Regression with Maximum Likelihood Estimation">
<meta property="og:url" content="https://yuehhua.github.io/2020/10/12/linear-regression-with-mle/index.html">
<meta property="og:site_name" content="Dream Maker">
<meta property="og:description" content="Maximum likelihood estimation is an essential approach to estimate parameters in statistics. It requires statistical assumptions on error pattern. I will introduce this technique with really simple st">
<meta property="og:locale" content="zh_TW">
<meta property="article:published_time" content="2020-10-11T17:20:57.000Z">
<meta property="article:modified_time" content="2020-10-11T17:21:50.309Z">
<meta property="article:author" content="Yueh-Hua Tu">
<meta property="article:tag" content="machine learning">
<meta property="article:tag" content="deep learning">
<meta property="article:tag" content="topology">
<meta name="twitter:card" content="summary">
    
    
        
    
    
    
    
    
    <!--STYLES-->
    
<link rel="stylesheet" href="/assets/css/style-3frockyt2j28isvdztjchy5nhkz8tjki9ermufc1ckptmvjdftux94m2ahub.min.css">

    <!--STYLES END-->
    
    <script type="text/javascript">
        (function (i, s, o, g, r, a, m) {
        i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
            (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date(); a = s.createElement(o),
            m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
        })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-119690895-1', 'auto');
        ga('send', 'pageview');
    </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
    
    
</head>

    <body>
        <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="blog">
            <!-- Define author's picture -->


    

<header id="header" data-behavior="5">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a class="header-title-link" href="/%20">Dream Maker</a>
    </div>
    
        
            <a  class="header-right-picture "
                href="#about">
        
        
        </a>
    
</header>

            <!-- Define author's picture -->


<nav id="sidebar" data-behavior="5">
    <div class="sidebar-container">
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/%20"
                            
                            title="首頁"
                        >
                    
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">首頁</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/all-categories"
                            
                            title="分類"
                        >
                    
                        <i class="sidebar-button-icon fa fa-bookmark" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">分類</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/all-tags"
                            
                            title="標籤"
                        >
                    
                        <i class="sidebar-button-icon fa fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">標籤</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/all-archives"
                            
                            title="所有文章"
                        >
                    
                        <i class="sidebar-button-icon fa fa-archive" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">所有文章</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link open-algolia-search"
                             href="#search"
                            
                            title="搜尋"
                        >
                    
                        <i class="sidebar-button-icon fa fa-search" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">搜尋</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="#about"
                            
                            title="關於"
                        >
                    
                        <i class="sidebar-button-icon fa fa-question" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">關於</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link " href="https://github.com/yuehhua/" target="_blank" rel="noopener" title="GitHub">
                    
                        <i class="sidebar-button-icon fab fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">GitHub</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link " href="https://www.facebook.com/a504082002" target="_blank" rel="noopener" title="Facebook">
                    
                        <i class="sidebar-button-icon fab fa-facebook" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Facebook</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link " href="https://www.linkedin.com/in/%E5%B2%B3%E8%8F%AF-%E6%9D%9C-6a3995a0/" target="_blank" rel="noopener" title="LinkedIn">
                    
                        <i class="sidebar-button-icon fab fa-linkedin" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">LinkedIn</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link " href="mailto:a504082002@gmail.com" target="_blank" rel="noopener" title="Email">
                    
                        <i class="sidebar-button-icon fab fa-envelope" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Email</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/atom.xml"
                            
                            title="Atom"
                        >
                    
                        <i class="sidebar-button-icon fa fa-rss" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Atom</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="5"
                 class="
                        hasCoverMetaIn
                        ">
                
    <article class="post">
        
                
                    <div class="post-header main-content-wrap text-left">
    
        <h1 class="post-title">
            Linear Regression with Maximum Likelihood Estimation
        </h1>
    
    
        <div class="post-meta">
    <time datetime="2020-10-12T01:20:57+08:00">
	
		    10月 12, 2020
    	
    </time>
    
        <span>分類 </span>
        
    <a class="category-link" href="/categories/Statistics/">Statistics</a>


    
</div>

    
</div>

                        
                            <div class="post-content markdown">
                                <div class="main-content-wrap">
                                    <p>Maximum likelihood estimation is an essential approach to estimate parameters in statistics. It requires statistical assumptions on error pattern. I will introduce this technique with really simple statistical model - linear regression.</p>
<a id="more"></a>
<p>We usually want to infer the relationship between input and output. They can be cause and effect of a physical phenomena or some indirect relationship in social science. We always want to realize the truth about our interest. Statistical tools are the tools to help you. The relationship between input and output are formulated as a mathematical function as follow:</p>
<p>$$<br>
y = f(x)<br>
$$</p>
<p>A linear model is assumed in linear regression. The relationship between $x$ and $y$ is assumed to be linear and $w$ and $b$ are introduced as unknown parameters into the model. $w$ denotes the extent of $x$ contributing to $y$ while $b$ denotes an inherent bias in $y$.</p>
<p>$$<br>
y = wx + b<br>
$$</p>
<p>On the other side, data are collected in pair of $(x^i, y^i)$. The superscript $n$ denotes the index for each sample.</p>
<p>$$<br>
\mathcal{D} = {(x^1, y^1), (x^2, y^2), \cdots, (x^n, y^n)}<br>
$$</p>
<p>The maximum likelihood estimation starts from the likelihood function. A likelihood function quantified the likelihood of data generation from the model we specified. That is, how likely the sample $(x_i, y_i)$ are generated from the model. All parameters are reduced into $\theta$. Precisely, $\mathcal{L}(\theta \mid \mathcal{D})$ represents the likelihood of model with parameter $\theta$ given data $\mathcal{D}$. Notably, data is fixed here. Thus, we want the most likely model that fits our samples. The model with maximum likelihood is estimated.</p>
<p>$$<br>
\begin{aligned}<br>
\mathcal{L}(\theta \mid \mathcal{D}) &amp;= f(\mathcal{D} \mid \theta) \\<br>
&amp;= p((x^1, y^1), (x^2, y^2), \cdots, (x^n, y^n) \mid \theta)<br>
\end{aligned}<br>
$$</p>
<p>A probability distribution is used to estimate the likelihood of model $\theta$. The interpretation here is the probability of data generation from the model $\theta$.</p>
<p>$$<br>
\begin{aligned}<br>
\mathcal{L}(\theta \mid \mathcal{D}) &amp;= p((x^1, y^1), (x^2, y^2), \cdots, (x^n, y^n) \mid \theta) \\<br>
&amp;= p((x^1, y^1) \mid \theta) \cdot p((x^2, y^2) \mid \theta) \cdots p((x^n, y^n) \mid \theta)<br>
\end{aligned}<br>
$$</p>
<p>It is formed from the joint probability distributions. A critical statistical assumption is introduced here. Samples $(x^i, y^i)$ are generated <em>independently</em> such that the joint probability can be splitted into multiplcation of probabilities. Further, samples are generated from the same population/model $\theta$. So, we call that data are <em>independently, identically distributed</em>, or <em>iid</em>, generated from some model.</p>
<p>$$<br>
\begin{aligned}<br>
\mathcal{L}(\theta \mid \mathcal{D}) &amp;= p((x^1, y^1) \mid \theta) \cdot p((x^2, y^2) \mid \theta) \cdots p((x^n, y^n) \mid \theta) \\<br>
&amp;= \prod_{i=1}^n p((x^i, y^i) \mid \theta)<br>
\end{aligned}<br>
$$</p>
<p>Normal distribution is used as error pattern in linear regression model. A linear regression model always infers the mean value of $y$ given $x$. The uncertainty of $y$ can be described by normal distribution. We add an error term after the linear regression model.</p>
<p>$$<br>
y = wx + b + \epsilon<br>
$$</p>
<p>$$<br>
\epsilon = y - wx - b = \mathcal{N}(z \mid \mu = 0, \sigma^2)<br>
$$</p>
<p>Or we can rewrite it into</p>
<p>$$<br>
\epsilon = \mathcal{N}(y - wx - b \mid \mu = 0, \sigma^2)<br>
$$</p>
<p>where $\mathcal{N}(x \mid \mu, \sigma^2) = \frac{1}{\sigma \sqrt{2 \pi}} exp(-\frac{1}{2} (\frac{x-\mu}{\sigma})^2)$.</p>
<p>Likelihood function would be</p>
<p>$$<br>
\begin{aligned}<br>
\mathcal{L}(\theta \mid \mathcal{D}) &amp;= \prod_{i=1}^n p((x^i, y^i) \mid \theta) \\<br>
&amp;= \prod_{i=1}^n \mathcal{N}(y^i - wx^i - b \mid \mu = 0, \sigma^2)<br>
\end{aligned}<br>
$$.</p>
<p>Negative log likelihood would be</p>
<p>$$<br>
\begin{aligned}<br>
\mathcal{l}(\theta \mid \mathcal{D}) &amp;= - ln \mathcal{L}(\theta \mid \mathcal{D}) \\<br>
&amp;= - ln \prod_{i=1}^n \mathcal{N}(y^i - wx^i - b \mid \mu = 0, \sigma^2) \\<br>
&amp;= - ln \prod_{i=1}^n \mathcal{N}(y^i - wx^i - b \mid \mu = 0, \sigma^2) \\<br>
&amp;= - \sum_{i=1}^n ln \mathcal{N}(y^i - wx^i - b \mid \mu = 0, \sigma^2) \\<br>
&amp;= - \sum_{i=1}^n - \frac{1}{2} (\frac{y^i - wx^i - b - 0}{\sigma})^2 - ln(\sigma \sqrt{2 \pi}) \\<br>
&amp;= \sum_{i=1}^n \frac{1}{2} (\frac{y^i - wx^i - b}{\sigma})^2 + ln(\sigma) + ln(\sqrt{2 \pi})<br>
\end{aligned}<br>
$$</p>
<p>The primal goal is to maximize likelihood function $\arg\max_{\theta} \mathcal{L}(\theta \mid \mathcal{D})$, while we have to minimize the negative log likelihood (NLL) function</p>
<p>$$<br>
\arg\min_{\theta} \mathcal{l}(\theta \mid \mathcal{D})<br>
$$.</p>
<p>To solve this problem, we need to calculate the first-order derivative of NLL. The minimum value happens while $\frac{\partial \mathcal{l}}{\partial w} = 0$ and $\frac{\partial \mathcal{l}}{\partial b} = 0$ are satisfied.</p>
<p>$$<br>
\begin{aligned}<br>
\frac{\partial \mathcal{l}}{\partial w} &amp;= \frac{\partial}{\partial w} \sum_{i=1}^n \frac{1}{2} (\frac{y^i - wx^i - b}{\sigma})^2 + ln(\sigma) + ln(\sqrt{2 \pi}) \\<br>
&amp;= \sum_{i=1}^n \frac{y^i - wx^i - b}{\sigma} \cdot \frac{\partial}{\partial w} \frac{y^i - wx^i - b}{\sigma} \\<br>
&amp;= \sum_{i=1}^n \frac{y^i - wx^i - b}{\sigma} \frac{-x^i}{\sigma} \\<br>
&amp;= \frac{-1}{\sigma^2} \sum_{i=1}^n x^i (y^i - wx^i - b) \\<br>
&amp;= 0<br>
\end{aligned}<br>
$$</p>
<p>$$<br>
\begin{aligned}<br>
\frac{-1}{\sigma^2} \sum_{i=1}^n x^i (y^i - wx^i - b) &amp;= 0 \\<br>
\sum_{i=1}^n x^i (y^i - wx^i - b) &amp;= 0 \\<br>
\sum_{i=1}^n{x^i y^i} - w \sum_{i=1}^n{(x^i)^2} - b \sum_{i=1}^n{x^i} &amp;= 0<br>
\end{aligned}<br>
$$</p>
<p>The same way we can have</p>
<p>$$<br>
\sum_{i=1}^n{y^i} - w \sum_{i=1}^n{x^i} - b = 0<br>
$$</p>
<p>derived from $\frac{\partial \mathcal{l}}{\partial b} = 0$.</p>
<p>Finally, we can estimate the parameters from the following two equations:</p>
<p>$$<br>
\begin{cases}<br>
(\sum_{i=1}^n{(x^i)^2}) w + (\sum_{i=1}^n{x^i}) b = \sum_{i=1}^n{x^i y^i} \\<br>
(\sum_{i=1}^n{x^i}) w + b = \sum_{i=1}^n{y^i}<br>
\end{cases}<br>
$$</p>
<p>$$<br>
\begin{cases}<br>
w = ? \\<br>
b = ?<br>
\end{cases}<br>
$$</p>

                                        

                                </div>
                            </div>
                            <div id="post-footer" class="post-footer main-content-wrap">
                                
                                        
                                            <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    <a class="post-action-btn btn btn--disabled">
                
                    <i class="fa fa-angle-left" aria-hidden="true"></i>
                    <span class="hide-xs hide-sm text-small icon-ml">上一篇</span>
                </a>
            </li>
            <li class="post-action">
                
                    
                    <a class="post-action-btn btn btn--default tooltip--top" href="/2020/10/12/from-sharing-to-suggestions/" data-tooltip="從分享到建議" aria-label="下一篇: 從分享到建議">
                
                    <span class="hide-xs hide-sm text-small icon-mr">下一篇</span>
                    <i class="fa fa-angle-right" aria-hidden="true"></i>
                </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions" aria-label="Share this post">
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://yuehhua.github.io/2020/10/12/linear-regression-with-mle/" title="分享到 Facebook">
                    <i class="fa fa-facebook-official" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
                <li class="post-action">
                    <a class="post-action-btn btn btn--default" href="#disqus_thread">
                        <i class="fa fa-comment-o"></i>
                    </a>
                </li>
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#" aria-label="Back to top">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


                                                
                                                    
                                                        
                                                            <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript" target="_blank" rel="noopener">comments powered by Disqus.</a></noscript>
</div>
                                                                
                                                                            
                            </div>
                            
                                <script src='https://unpkg.com/mermaid@7.1.2/dist/mermaid.min.js'></script>
                                <script>
                                    if (window.mermaid) {
                                        mermaid.initialize({ theme: 'forest' });
                                    }
                                </script>
                                
    </article>

                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2020 Yueh-Hua Tu. All Rights Reserved.
    </span>
</footer>

            </div>
            
                <div id="bottom-bar" class="post-bottom-bar" data-behavior="5">
                    <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    <a class="post-action-btn btn btn--disabled">
                
                    <i class="fa fa-angle-left" aria-hidden="true"></i>
                    <span class="hide-xs hide-sm text-small icon-ml">上一篇</span>
                </a>
            </li>
            <li class="post-action">
                
                    
                    <a class="post-action-btn btn btn--default tooltip--top" href="/2020/10/12/from-sharing-to-suggestions/" data-tooltip="從分享到建議" aria-label="下一篇: 從分享到建議">
                
                    <span class="hide-xs hide-sm text-small icon-mr">下一篇</span>
                    <i class="fa fa-angle-right" aria-hidden="true"></i>
                </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions" aria-label="Share this post">
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://yuehhua.github.io/2020/10/12/linear-regression-with-mle/" title="分享到 Facebook">
                    <i class="fa fa-facebook-official" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
                <li class="post-action">
                    <a class="post-action-btn btn btn--default" href="#disqus_thread">
                        <i class="fa fa-comment-o"></i>
                    </a>
                </li>
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#" aria-label="Back to top">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


                </div>
                <div id="share-options-bar" class="share-options-bar" data-behavior="5">
    <i id="btn-close-shareoptions" class="fa fa-close"></i>
    <ul class="share-options">
        
            
            
            <li class="share-option">
                <a class="share-option-btn" target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://yuehhua.github.io/2020/10/12/linear-regression-with-mle/">
                    <i class="fa fa-facebook-official" aria-hidden="true"></i><span>分享到 Facebook</span>
                </a>
            </li>
        
    </ul>
</div>

            
        </div>
        


<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-remove"></i>
        </div>
        
            <h4 id="about-card-name">Yueh-Hua Tu</h4>
        
            <div id="about-card-bio"><p>目標是計算生物學家！</br>Systems Biology, Computational Biology, Machine Learning</br>Julia Taiwan 發起人</p>
</div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                <p>研發替代役研究助理</p>

            </div>
        
        
            <div id="about-card-location">
                <i class="fa fa-map-marker"></i>
                <br/>
                Taiwan
            </div>
        
    </div>
</div>

        
        
<div id="cover" style="background-image:url('/assets/images/cover.jpg');"></div>
        <!--SCRIPTS-->

<script src="/assets/js/script-xzfezjobyekpxrjktw5tz6muvzqfsbmo5n6atk3p5om9ulfptldi3p7cyqd8.min.js"></script>

<!--SCRIPTS END-->


<script>
    var disqus_config = function () {
        this.page.url = 'https://yuehhua.github.io/2020/10/12/linear-regression-with-mle/';
                 
            this.page.identifier = '2020/10/12/linear-regression-with-mle/';
                 
             };
    (function () {
        var d = document, s = d.createElement('script');
        var disqus_shortname = 'dream-maker';
        s.src = '//' + disqus_shortname + '.disqus.com/embed.js';

        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/latest.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->



    </body>
</html>
