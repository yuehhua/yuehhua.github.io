<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Dream Maker</title>
  
  <subtitle>Love Math, Science, Biology, Computer science</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://yuehhua.github.io/"/>
  <updated>2018-10-03T15:13:30.811Z</updated>
  <id>https://yuehhua.github.io/</id>
  
  <author>
    <name>Yueh-Hua Tu</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>03 從線性迴歸到感知器</title>
    <link href="https://yuehhua.github.io/2018/10/03/03-from-linear-regression-to-perceptron/"/>
    <id>https://yuehhua.github.io/2018/10/03/03-from-linear-regression-to-perceptron/</id>
    <published>2018-10-03T15:13:30.000Z</published>
    <updated>2018-10-03T15:13:30.811Z</updated>
    
    <content type="html"><![CDATA[<p>感知器（perceptron）是在 1957 年就被發明出來的的模型，對電腦的發展或是人工智慧來說都是非常早期的。</p><p>感知器模型他是一個二元分類的分類器，他解的是分類問題。相對我們前面的線性迴歸解的是迴歸問題，兩者在問題的定義上有根本性的不一樣，那他們兩個有什麼關聯性呢？</p><h2 id="分類"><a href="#分類" class="headerlink" title="分類"></a>分類</h2><p>現在想像一下，如果你手上有一些資料，這些資料都有兩個維度 $(x_1,x_2)$，可以他們畫在二維的平面上，這些資料有的被標記成方塊，有的被標記成圓圈。我現在希望有一種方法可以將不同標記的資料點分開，我們可以怎麼做？</p><p><img src="/images/perceptron1.svg" alt=""></p><p>在資料點上，大多相似的資料點會有接近的座標，所以資料點本身就會因為相似性而聚在一起。最直覺的方法就是畫一條直線將他們分開。</p><p><img src="/images/perceptron2.svg" alt=""></p><p>我們可以在二維平面上畫一條線來把這些點分開的話，那麼要怎麼以數學的方式呈現呢？</p><p>$$<br>x_2 = w x_1 + b<br>$$</p><p>這是我們的二維平面上的線，我們把他移項一下。</p><p>$$<br>x_2 - w x_1 - b = 0<br>$$</p><p>當你試著把資料點代入方程式的時候，你會發現不同的點算出來結果會分成兩種：</p><ol><li>$x_2 - w x_1 - b &gt; 0$</li><li>$x_2 - w x_1 - b &lt; 0$</li></ol><p>如果你的線畫的夠好的話，應該是不會有點剛好位於線上而讓 $y - w x - b = 0$ 發生的。所以我們是不是能夠透過將點代入公式中，計算出他的結果為正或是為負來決定他應該是方塊或是圓圈。新的資料點就可以透過這樣的運算來做預測。</p><p>如果要模型給出一個比較容易理解的預測值的話，我們可以在模型之後再加上一個 $sign$ 來取數值的正負號。</p><p>$$<br>sign(x_2 - w x_1 - b) = 0<br>$$</p><p>$$<br>sign(x) = \begin{cases}<br> -1, &amp;\text{if } x \lt 0\<br> 0, &amp;\text{if } x = 0\<br> 1, &amp;\text{if } x \gt 0<br>\end{cases}<br>$$</p><p>當整件事情拓展到了高維度空間的時候就變成這樣了：</p><p>$$<br>sign(\mathbf{w}^T\mathbf{x} + b)<br>$$</p><p>看到了嗎？中間是不是我們的線性迴歸裡的線性模型了呢？</p><p>準確來說，是跟線性迴歸沒什麼關係啦！但是同為線性模型可以應用在迴歸問題或是分類問題，有兩種些許不同的形式，是不是很妙呢？</p><h2 id="常數項"><a href="#常數項" class="headerlink" title="常數項"></a>常數項</h2><p>前面說過，常數項在分類器上有些許不一樣的的解釋。</p><p><img src="/images/perceptron3.svg" alt=""></p><p>基本上，對一條線來說，常數項仍舊是讓線可以有位移的機會，不過反過來想，如果沒有常數項的話，即便有 $\mathbf{w}^T\mathbf{x}$ 可以計算出結果，但是可能仍不足以分隔資料，所以需要加上（或是減掉）一個閾值或是臨界值。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;感知器（perceptron）是在 1957 年就被發明出來的的模型，對電腦的發展或是人工智慧來說都是非常早期的。&lt;/p&gt;
&lt;p&gt;感知器模型他是一個二元分類的分類器，他解的是分類問題。相對我們前面的線性迴歸解的是迴歸問題，兩者在問題的定義上有根本性的不一樣，那他們兩個有什麼
      
    
    </summary>
    
      <category term="Machine Learning" scheme="https://yuehhua.github.io/categories/Machine-Learning/"/>
    
      <category term="機器學習模型圖書館：從傳統模型到深度學習" scheme="https://yuehhua.github.io/categories/Machine-Learning/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%A8%A1%E5%9E%8B%E5%9C%96%E6%9B%B8%E9%A4%A8%EF%BC%9A%E5%BE%9E%E5%82%B3%E7%B5%B1%E6%A8%A1%E5%9E%8B%E5%88%B0%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92/"/>
    
    
  </entry>
  
  <entry>
    <title>02-linear-regression</title>
    <link href="https://yuehhua.github.io/2018/10/03/02-linear-regression/"/>
    <id>https://yuehhua.github.io/2018/10/03/02-linear-regression/</id>
    <published>2018-10-03T07:31:54.000Z</published>
    <updated>2018-10-03T07:31:54.292Z</updated>
    
    <content type="html"><![CDATA[<p>這個模型大概已經被人講過很多次，講到都快要爛掉了XD</p><p>其實我自己在兩年前的鐵人賽中也有講過同一個模型，所以我就不用講太多基礎的部份：</p><a id="more"></a><ul><li><a href="https://ithelp.ithome.com.tw/articles/10186338" target="_blank" rel="noopener">[Day 02] 解構linear regression</a></li><li><a href="https://ithelp.ithome.com.tw/articles/10186400" target="_blank" rel="noopener">[Day 03] linear regression–線性代數解</a></li><li><a href="https://ithelp.ithome.com.tw/articles/10186401" target="_blank" rel="noopener">[Day 04] Gradient descent</a></li><li><a href="https://ithelp.ithome.com.tw/articles/10186402" target="_blank" rel="noopener">[Day 05] linear regression辛祕</a></li></ul><p>總的來說，線性模型就是依賴著 $y = w_0 + w_1x_1 + w_2x_2 + \dots + w_nx_n$ 這樣的一條數學式子。</p><p>為了方便起見我們將他化成向量的形式：$$y = \mathbf{w}^T\mathbf{x} + b$$</p><p>你會發現線性迴歸會是一個向量的內積的運算再加上一個常數，這個常數被很多人討論很久，很多人可能不是那麼了解他的意義。這個常數代表的就是在空間上的一個位移，在內積的 $\mathbf{w}$ 這個係數向量上，他們決定了在空間中整個線或是平面的傾斜程度，而常數則是在空間上的位移，也就是要將這個線或是平面擺在哪一個地方。</p><p>但是這個常數如果擺在下一篇要講的感知器（perceptron）當中的話，那就有不同的解釋了，這個留到下回再說。</p><p>那麼，基礎的部份都在前面的文章內容中講完了，剩下的要來說點什麼呢？</p><h2 id="模型的統計面向"><a href="#模型的統計面向" class="headerlink" title="模型的統計面向"></a>模型的統計面向</h2><p>我們來講點這個模型的統計面向吧！</p><p>一般來說，我們在計算這個模型的時候，這個模型背後是有他的統計面向的假設的。</p><h3 id="誤差"><a href="#誤差" class="headerlink" title="誤差"></a>誤差</h3><p>線性迴歸對誤差是有假設的，也就是假設誤差會呈現常態分佈（Gaussian distribution），這樣的假設與這個模型所使用的 mean square error 是有關係的，不過今天不會深入這些關係。</p><p>我們要進入這件事之前，我們先來看看常態分佈長什麼樣子。</p><p><img src="/images/Empirical_Rule.png" alt=""></p><blockquote><p>Wikipedia</p></blockquote><p>我們借到了維基百科的圖，其中 X 軸是連續的數值，Y 軸是這些數值出現的機率或是頻率。你會看到他是以平均值 $\mu$ 為中心的一個分佈，整個分佈是單峰的。平均值的出現機率是最高的，機率開始往兩邊遞減。這說明了最常出現的數值會剛好在平均值上，其他離平均值很遠的數值也是有機率出現，但是機率很小。</p><p>整個分佈的寬度是由標準差 $\sigma$ 的大小決定的，如果標準差愈大，代表這個分佈是愈寬的，愈寬代表資料的離散程度是大的。</p><p>這其實來自於對於自然現象的觀察。高爾頓，達爾文的表弟，觀察了自然現象，發現眾多自然現象都有一種趨勢，像是人的身高跟體重都是連續的數值，而且都沒有上下界，為什麼他們不會平均分佈呢？他會向某一個值集中，那個值差不多是整個分佈的平均值，這樣的趨勢被他稱為「迴歸」。這也是迴歸這個詞的由來，但今日的迴歸的意義不相同。</p><p>題外話，高爾頓提出了不少對今日的科學有影響的主張，像是他主張人類的才能是可以透過遺傳延續的，並提倡了優生學。他發表了一些關於指紋的研究，被認為跟今日以指紋鑑定有相關。在統計學上，他也發表了相關係數的概念，並且沿用至今。</p><p>以下是常態分佈的公式：</p><p>$$<br>P(x; \mu, \sigma) = \frac{1}{\sqrt{2 \pi \sigma^2}} e^{- \frac{(x - \mu)^2}{2 \sigma^2}}<br>$$</p><p>整體看起來可能很醜很複雜，我們通常會把平均值歸零，並且讓標準差為 1，他看起來就會簡潔許多。</p><p>$$<br>P(x; 0, 1) = \frac{1}{\sqrt{2 \pi}} e^{- \frac{x^2}{2}}<br>$$</p><p>大家注意一下，在常態分佈的公式中他的主要組成為一個 e 的指數，並且在指數項上有 $x^2$ 項。這些我們以後會用到。</p><h3 id="平均就是最有可能出現的"><a href="#平均就是最有可能出現的" class="headerlink" title="平均就是最有可能出現的"></a>平均就是最有可能出現的</h3><p>那回到線性迴歸，線性回歸是怎麼做出預測的呢？</p><p><img src="/images/stats-linear_reg1.svg" alt=""></p><p>當假設了誤差的分佈是常態分佈之後呢？那麼就可以拿最常出現的那個值作為整個分佈的代表，數學上證明那個值剛好是平均值。</p><p>可以參考上圖，資料在 X 軸上分佈，當我們切了某個點 $x_i$ 來看，那麼 Y 軸上就會有不同資料點的誤差存在。縱使真實資料是有誤差的，我們知道這些誤差會遵從常態分佈，所以這些誤差的平均就可以作為一種預測值。</p><p>從上面我們提到的迴歸效應，我們知道用這些誤差的平均值作為預測是相對合理的。</p><p>數學上是這樣運作的，當我們今天有新的資料點要預測，那麼我們代入 $y = \mathbf{w}^T\mathbf{x} + b$ 公式中，算出來的其實是 Y 軸的平均值 $\hat{y_i}$。</p><p>這就是線性迴歸的假設了。</p><h3 id="誤差的”寬度”是一樣的"><a href="#誤差的”寬度”是一樣的" class="headerlink" title="誤差的”寬度”是一樣的"></a>誤差的”寬度”是一樣的</h3><p>在線性迴歸的假設上還有另一點，就是我們在每個不同 x 的切面上，誤差的寬度（標準差）都是一樣的。</p><p><img src="/images/stats-linear_reg2.svg" alt=""></p><p>如圖所示，我不確定是為了讓模型簡單好計算還是什麼原因。</p><p>今天的介紹就到這邊啦！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;這個模型大概已經被人講過很多次，講到都快要爛掉了XD&lt;/p&gt;
&lt;p&gt;其實我自己在兩年前的鐵人賽中也有講過同一個模型，所以我就不用講太多基礎的部份：&lt;/p&gt;
    
    </summary>
    
      <category term="Machine Learning" scheme="https://yuehhua.github.io/categories/Machine-Learning/"/>
    
      <category term="機器學習模型圖書館：從傳統模型到深度學習" scheme="https://yuehhua.github.io/categories/Machine-Learning/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%A8%A1%E5%9E%8B%E5%9C%96%E6%9B%B8%E9%A4%A8%EF%BC%9A%E5%BE%9E%E5%82%B3%E7%B5%B1%E6%A8%A1%E5%9E%8B%E5%88%B0%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92/"/>
    
    
  </entry>
  
  <entry>
    <title>01 簡介</title>
    <link href="https://yuehhua.github.io/2018/10/03/01-introduction/"/>
    <id>https://yuehhua.github.io/2018/10/03/01-introduction/</id>
    <published>2018-10-03T06:03:40.000Z</published>
    <updated>2018-10-03T06:09:16.636Z</updated>
    
    <content type="html"><![CDATA[<p>上個禮拜才剛從美國回來，周末又講了兩天整天的機器學習課程，完全忘記鐵人賽開賽的事情…….</p><p>這一系列文章將會專注在機器學習的模型上，會從傳統的機器學習模型一路介紹到深度學習的模型。<br>比起介紹個別的模型，我會更專注在模型的演化上，去比較不同模型的差異之處，或是不同模型之間的改進之處。<br>一系列的脈絡會讓讀者更了解數學模型的運作方式，以及數學運算上的意義。</p><a id="more"></a><p>我們的起點一樣是線性迴歸，接著會踩著感知器的腳步，一路走向 SVM。<br>在線性模型上，我們不只有線性迴歸，根據不同的誤差的分佈情形，我們有 logistic regression，還有 Poisson regression，然後走到廣義線性模型。<br>模型俱備，只欠網路。我們可以從既有的模型當中發現，當你把模型堆疊起來，會得到神經網路模型。<br>接下來，就會一一介紹在這五年內發展蓬勃的深度學習模型。</p><p>鐵人賽的文也會發佈在我自己的部落格中。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;上個禮拜才剛從美國回來，周末又講了兩天整天的機器學習課程，完全忘記鐵人賽開賽的事情…….&lt;/p&gt;
&lt;p&gt;這一系列文章將會專注在機器學習的模型上，會從傳統的機器學習模型一路介紹到深度學習的模型。&lt;br&gt;比起介紹個別的模型，我會更專注在模型的演化上，去比較不同模型的差異之處，或是不同模型之間的改進之處。&lt;br&gt;一系列的脈絡會讓讀者更了解數學模型的運作方式，以及數學運算上的意義。&lt;/p&gt;
    
    </summary>
    
      <category term="Machine Learning" scheme="https://yuehhua.github.io/categories/Machine-Learning/"/>
    
      <category term="機器學習模型圖書館：從傳統模型到深度學習" scheme="https://yuehhua.github.io/categories/Machine-Learning/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%A8%A1%E5%9E%8B%E5%9C%96%E6%9B%B8%E9%A4%A8%EF%BC%9A%E5%BE%9E%E5%82%B3%E7%B5%B1%E6%A8%A1%E5%9E%8B%E5%88%B0%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92/"/>
    
    
  </entry>
  
  <entry>
    <title>Energy-based model 以及 Bayesian model 的關聯</title>
    <link href="https://yuehhua.github.io/2018/09/12/energy-model-bayesian/"/>
    <id>https://yuehhua.github.io/2018/09/12/energy-model-bayesian/</id>
    <published>2018-09-12T06:22:48.000Z</published>
    <updated>2018-09-13T02:33:00.799Z</updated>
    
    <content type="html"><![CDATA[<p>在機器學習領域，我們常常會聽到 Energy-based model。</p><p>基本上，他是借了物理的能量觀點來的，在數學上，與物理的公式如出一徹。</p><p>我們先來看看他是長成什麼樣子。</p><a id="more"></a><p>在物理統計力學中，如果一個系統的狀態的機率分佈，是由狀態的能量決定，並且狀態能量及系統溫度與狀態之間可以寫成一個函數關係，我們稱為 Boltzmann distribution。</p><p>$$<br>\large p_i = \frac{1}{Z} e^{- \epsilon_i / kT}<br>$$</p><p>一個系統中，狀態 $i$ 的出現機率 $p_i$ 是狀態能量 $\epsilon_i$ 以及系統溫度 $T$ 的函數，其中 $k$ 為波茲曼常數，$Z$ 為機率分佈的分母，稱為 partition function。</p><p>在機器學習中，借了同樣的概念變成了以下式子：</p><p>$$<br>\large P(X = x) = \frac{1}{Z} e^{f(x)}<br>$$</p><p>主要是將次方項 $- \epsilon_i / kT$ 替換成了更廣義的函數 $f(x)$ 形式，而這個函數會跟系統的狀態 $x$ 相關。</p><p>其中 $Z$ 就變成了以下的樣子：</p><p>$$<br>Z = \sum_{x \in X} e^{f(x)}<br>$$</p><p>如果代入以上的函數中就會是：</p><p>$$<br>\large P(X = x) = \frac{e^{f(x)}}{\sum_{x \in X} e^{f(x)}}<br>$$</p><p>當我們把這樣的模型廣義化之後就稱為 Energy-based model。</p><p>這樣的模型在統計或是機器學習中有非常有趣的連結，$f(x)$ 所代表的應該是一個能量的函數。</p><p>$$<br>f(x) = -E(x)<br>$$</p><p>然而這樣的函數我們可以將他等同於機器學習中常用的 loss function。</p><p>$$<br>f(x) = -E(x) = - \text{loss function}<br>$$</p><p>這樣的等號是基於在熱力學第二定律的描述，熱力學第二定律描述一個封閉系統（closed system），封閉系統不允許系統與環境有任何的物質交換，在環境及熵不變的情況下，而系統的內能會降低，當內能降到最低的時候，系統會達成動態平衡。這稱為最小能量原則（principle of minimum energy），是熱力學第二定律另一個面向的描述。</p><blockquote><p>相對的是，在一個孤立系統（isolated system），孤立系統不允許系統與環境有任何的物質與能量交換，在環境不變的情況下，熵會持續增加。</p></blockquote><p>依據最小能量原則，能量最小跟我們希望的 loss function 最低有同樣的目標，所以我們可以將他們同等起來。不過要強調的是，這裡並沒有意義上的同等，只是在最佳化的方向上是同等的。</p><h3 id="Bayesian-model"><a href="#Bayesian-model" class="headerlink" title="Bayesian model"></a>Bayesian model</h3><p>在 Bayesian model 的方法中就更有趣了。當我們想要最小化 loss function 的時候，他其實在最大化 likelihood function。換句話說，降低 loss 是在降低資料與模型之間的誤差，讓模型更貼近資料，提升 likelihood 則是另一個面向的描述，likelihood 是在測量模型與資料的相似度，最大化 likelihood 也是讓模型愈貼近資料，所以我們可以將他變成這個樣子：</p><p>$$<br>f(x) = -E(x) = \text{likelihood function}<br>$$</p><p>這樣的解釋是什麼呢？</p><p>也就是，在統計學裡常用的 Maximum likelihood estimation （MLE）方法會跟最小能量原則有一致的目標。</p><p>我們從貝氏定理出發。我們先把貝氏定理的分母省略掉。</p><p>$$<br>\large P(\theta \mid x) = \frac{P(x \mid \theta)P(\theta)}{P(x)} = \frac{1}{Z} P(x \mid \theta)P(\theta)<br>$$</p><p>接者，貝氏定理的分子部份其實代表的各自是 likelihood 以及 prior。</p><p>$$<br>\propto P(x \mid \theta)P(\theta)<br>$$</p><p>$$<br>\text{    (likelihood)(prior)}<br>$$</p><p>我們可以將 Energy-based model 代入，容我省略分母。</p><p>$$<br>\propto e^{-E(x)} \times P(\theta)<br>$$</p><p>旁邊的 prior 我們可以忽略他，但是我們可以代入 normal distribution，會有有趣的結果。</p><p>$$<br>\large = e^{-E(x)} \times \frac{1}{\sqrt{2 \pi \sigma^2}} e^{-\frac{\theta^2}{2 \sigma^2}}<br>$$</p><p>接著我們把等號的兩側都取 ln。</p><p>$$<br>-ln P(\theta \mid x) \propto E(x) + \frac{\theta^2}{2 \sigma^2} - ln(\frac{1}{\sqrt{2 \pi \sigma^2}}) + ln(Z)<br>$$</p><p>有沒有看到有趣的部份了？能量的部份顯露出來，當能量最小時，$P(\theta \mid x)$ 就會是最大，而 $P(\theta \mid x)$ 則是 posterior，最小能量原則會對應到貝氏方法的 Maximum a posteriori（MAP）。如果 MAP，將 prior 移除的話，就等同於 MLE 了！</p><p>所以我們可以看到在統計力學與統計學跟機器學習之間非常緊密的關係，而且他們都可以借用物理的熱力學第二定律來加以解釋，如此一來，可以賦予機器學習模型一個物理意義。</p><h3 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h3><p>還有嗎？當然還有阿！</p><p>我們可以進一步將式子整理一下，我們將 $\theta^2$ 分離出來，將 ln 中的分母倒過來：</p><p>$$<br>= E(x) + \frac{1}{2 \sigma^2} \theta^2 + ln(\sqrt{2 \pi \sigma^2}) + ln(Z)<br>$$</p><p>有沒有注意到 $\theta^2$ 非常像什麼？</p><p>是的，他就是一個模型參數的 $\mathcal{l}_2$-norm，也就是，他是一個 regularization term。</p><p>我們再進一步將他凸顯出來。</p><p>$$<br>\text{let } \lambda = \frac{1}{2 \sigma^2}<br>$$</p><p>$$<br>= E(x) + \lambda \theta^2 + ln(\frac{\sqrt{\pi}}{\lambda}) + ln(Z)<br>$$</p><p>你會發現式子的前半部份像極了一般的 loss function，含有 error function 跟 regularization term。$\lambda$ 部份就是你在調整模型的時候，regularization 的強度。</p><p>整體來說，我們在前面的 prior 代入了 normal distribution，最後導出來得到 $\mathcal{l}_2$ regularization。這說明了，如果我們在模型中加入 $\mathcal{l}_2$ regularization，等於是對模型的參數做了假設，也就是假設模型參數會服從 normal distribution。這樣的結果與貝氏的方法與解釋一致。</p><p>最後總結一下，energy-based model 借用了物理的概念，與最佳化的機制有一致的方向，應該有人證明這點，只是我還沒去找。我們也看到 energy-based model 放到貝氏統計中是很自然的。在貝氏統計中的 prior 會對應到 regularization 的機制。這邊說明了物理、統計跟機器學習模型之間的關係。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在機器學習領域，我們常常會聽到 Energy-based model。&lt;/p&gt;
&lt;p&gt;基本上，他是借了物理的能量觀點來的，在數學上，與物理的公式如出一徹。&lt;/p&gt;
&lt;p&gt;我們先來看看他是長成什麼樣子。&lt;/p&gt;
    
    </summary>
    
      <category term="Machine Learning" scheme="https://yuehhua.github.io/categories/Machine-Learning/"/>
    
    
  </entry>
  
  <entry>
    <title>《喚醒你心中的大師：偷學48位大師精進的藝術，做個厲害的人》</title>
    <link href="https://yuehhua.github.io/2018/08/24/mastery/"/>
    <id>https://yuehhua.github.io/2018/08/24/mastery/</id>
    <published>2018-08-24T14:21:21.000Z</published>
    <updated>2018-08-24T14:21:21.806Z</updated>
    
    <content type="html"><![CDATA[<iframe width="560" height="315" src="https://www.youtube.com/embed/xM0HUZ4E5I8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe><p>摘要筆記：</p><ol><li>前置階段<ul><li>發掘內心的召喚</li></ul></li><li>學徒訓練階段（5~10 年）<ul><li>實踐<ul><li>深入觀察</li><li>技能習得（一萬小時）</li><li>實驗</li></ul></li><li>策略<ul><li>選擇成長潛力最大，而不是賺最多錢的</li><li>持續拓展視野</li><li>讓認知框架保持開放</li></ul></li></ul></li><li>積極創造階段<ul><li>尋找具有創造性的任務</li><li>實踐創造力的策略<ul><li>培養 negative capability</li><li>不要一直處於專注模式</li><li>注意細節及異常現象</li></ul></li><li>設定工作期限</li></ul></li><li>大師境界階段<ul><li>掌握部分跟整體的關係</li><li>連結萬物的追求</li><li>成為你自己</li></ul></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/xM0HUZ4E5I8&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; encrypted-media&quot; allowfull
      
    
    </summary>
    
      <category term="Book" scheme="https://yuehhua.github.io/categories/Book/"/>
    
    
  </entry>
  
  <entry>
    <title>Usual topology and subbasis</title>
    <link href="https://yuehhua.github.io/2018/08/08/11-usual-topology-and-subbasis/"/>
    <id>https://yuehhua.github.io/2018/08/08/11-usual-topology-and-subbasis/</id>
    <published>2018-08-08T05:38:50.000Z</published>
    <updated>2018-08-08T05:38:50.090Z</updated>
    
    <content type="html"><![CDATA[<p>我們今天就來談談一些常見的拓樸。</p><a id="more"></a><p>首先是在實數線上的開區間（open interval）：</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>If $\mathcal{B}$ is the collection of all open intervals in the real line,</p><p>$$<br>(a, b) = \{ x \mid a &lt; x &lt; b \}<br>$$</p><p>這就是我們所熟知的開區間，由 $\mathcal{B}$ 所產生出來的拓樸稱之為 <strong>標準拓樸（standard topology）</strong>，（所以在這邊 $\mathcal{B}$ 是一個基底）。我們一般在討論的實數域 $\mathbb{R}$ 就是由這樣的基底所衍生出來的，所以 $\mathbb{R}$ 也是一個拓樸，後續如果沒有特別提，我們就是這樣預設的。</p><p>如果 $\mathcal{B}^\prime$ 是半開區間的集合，</p><p>$$<br>[a, b) = \{ x \mid a \le x &lt; b \}, a &lt; b<br>$$</p><p>那麼由這樣的基底 $\mathcal{B}^\prime$ 所產生出來的拓樸為在 $\mathbb{R}$ 上的 <strong>lower limit topology</strong>，我們記為 $\mathbb{R}_l$。</p><p>我們還有，</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$$<br>K = \{ \frac{1}{n} \mid n \in \mathbb{N} \}<br>$$</p><p>$\mathcal{B}^{\prime \prime}$ is the collection of all open intervals $(a, b)$, and with all sets of the form $(a, b) - K$</p><p>這邊我們定義了所有 $\frac{1}{n}$ 的集合為 $K$，$\mathcal{B}^{\prime \prime}$ 這個基底包含了所有 $(a, b)$ 以及 $(a, b) - K$ 這樣的元素。由這樣的基底產生出來的拓樸稱為在 $\mathbb{R}$ 上的 <strong>K-topology</strong>，記為 $\mathbb{R}_K$。</p><p>我們上面提到的集合都是基底，所以兩兩基底元素之間的交集，要不是另一個基底元素，不然就是空集合。</p><p>接下來我們來看看上面提到的拓樸之間的關係。</p><blockquote><p> <strong><em>Lemma</em></strong></p></blockquote><p>The topology of $\mathbb{R}_l$ and $\mathbb{R}_K$ are strictly finer than standard topology on $\mathbb{R}$. The topology of $\mathbb{R}_l$ and $\mathbb{R}_K$ are not comparable with each other.</p><p>這時候你可能就會問了，因為拓樸可以由一個基底的任意元素聯集組成，那如果隨意取了一個集合的集合做為基底，在有限的交集以及任意的聯集下，會變成什麼？</p><p>這個問題就引領我們到子基底（subbasis）的概念上。</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>A subbasis $\mathcal{S}$ for a topology on $X$.</p><p>$$<br>\mathcal{S} = \{ x \mid x \subseteq X \}, \bigcup_{x \in \mathcal{S}} = X<br>$$</p><p>The <strong>topology generated by the subbasis</strong> $\mathcal{S}$ is the collection $\mathcal{T}$ of all unions of finite intersections of elements of $\mathcal{S}$.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我們今天就來談談一些常見的拓樸。&lt;/p&gt;
    
    </summary>
    
      <category term="Topology" scheme="https://yuehhua.github.io/categories/Topology/"/>
    
    
  </entry>
  
  <entry>
    <title>AI 的核心</title>
    <link href="https://yuehhua.github.io/2018/08/03/the-nutshell-of-ai/"/>
    <id>https://yuehhua.github.io/2018/08/03/the-nutshell-of-ai/</id>
    <published>2018-08-02T16:17:30.000Z</published>
    <updated>2018-08-03T16:42:50.399Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><h2 id="AI-是什麼？"><a href="#AI-是什麼？" class="headerlink" title="AI 是什麼？"></a>AI 是什麼？</h2><p>很多人探討 AI 會追隨前人的探討，去探討什麼是智慧？或是什麼樣的是強人工智慧？</p><p>當然我也做過一樣的事情，只是今天我想從比較 <strong>技術層面</strong>、比較 <strong>務實</strong> 的角度切入這一大類技術。</p><p>從比較技術層面跟務實的角度切入，就表示我想討論的是現今人工智慧的實作層面，也就是 <strong>AI 是怎麼被做出來的？（how）</strong>，並非討論 <strong>AI 是什麼？(what)</strong></p><p><strong>AI 是什麼？</strong> 這議題會牽涉到什麼是智慧？而智慧這種事情連人類自身都說不清楚，有的人從哲學層面討論智慧，動物有動物的智慧，人類有人類的智慧，憑什麼說人類的『智慧』才稱為智慧？有的人從生物角度切入， 從大腦的結構與神經元的連結，到神經元的觸發，這一系列的科學探索，或許我們未來可以回答智慧是什麼？但目前仍舊是一個大謎團。</p><p>我今天要談的都不是這些，我要談的是深度學習的核心，不！是機器學習的核心…… 嗯……等等，所以那是什麼？</p><a id="more"></a><h2 id="星星的故事"><a href="#星星的故事" class="headerlink" title="星星的故事"></a>星星的故事</h2><p>故事的開始是從這裡開始的，自從牛頓引進了數學作為科學的基礎以來，人類一直非常依賴數學工具來解決各種事情。</p><p>第谷大概可以說是第一位資料科學家了，第谷是 16 世紀丹麥的天文學家，還是一個占星學家，他用肉眼觀察了天上星星的位置，並且每天將這些資料紀錄下來。他的學生克卜勒是一位洞察力極強的人，他在他老師蒐集的數據當中找出了規則，並推出了著名的行星三大運動定律。</p><p>當時就已經知道行星的運動軌跡是橢圓（克卜勒第一定律），並且可以計算行星的運動周期（克卜勒第三定律）。後來牛頓在克卜勒三個定律的基礎之上，才確立了萬有引力定律，當時牛頓只知道萬有引力應該會跟兩個物體的質量成正比，但是跟距離的關係始終是個謎。萬有引力跟距離平方成反比這件事情，牛頓自己也猶豫了很久，但是透過克卜勒第三定律可以驗證，萬有引力跟距離平方成反比才是對的。</p><p>我們在這裡看到史上第一個引進了數學的推導，以及從資料的觀察當中，我們可以得知大自然的規律。在這之前，數學都是屬於一個哲學層次的討論，並不會有人拿他來應用。我們從數學式去理解自然的規律，因為我們相信自然是有規律的，資料是可以呈現規律的，數學是可以將規律 <strong>公式化（formulate）</strong> 的。</p><p>除了科學以外，生活中我們應用的是理性的邏輯來理解以及處理事物，我們用了數字以及加減乘除在買東西上面。你需要用數字來跟攤販討價還價，需要用邏輯來將一件事情拆解、重組或是加以推演。</p><p>各位可以邊看邊思考這些脈絡背後的共同點。</p><h2 id="規劃問題"><a href="#規劃問題" class="headerlink" title="規劃問題"></a>規劃問題</h2><p>我們從最簡單的問題開始，在工廠生產一定會遇到典型的生產問題，一個工廠可以生產 A、B 兩種產品，這兩種產品分別需要的成本是 5 元跟 10 元，兩種產品的售價則分別是 9 元跟 15 元，但是每天的生產成本最多不可以超過 1000 元，在有限制條件下，要生產多少的 A、B 兩種產品才能讓整體利潤最大化？這種問題稱為線性規劃問題，我們可以把他用數學式表達出來：</p><p>假設 A、B 兩種產品的生產數量分別是 <code>x_1</code> 跟 <code>x_2</code>，</p><p>max $(9x_1 + 15 x_2) - (5x_1 + 10x_2)$<br>subject to $5x_1 + 10x_2 \le 1000$</p><p>我們可以進一步簡化：</p><p>max $4x_1 + 5 x_2$<br>subject to $5x_1 + 10x_2 \le 1000$</p><p>線性規劃問題他需要最大化的是一個線性函數， 最大化的目標我們稱之為目標函數，他還有一個限制條件，同時這個限制條件也是一個線性方程式，我們稱之為限制式。</p><p>線性規劃問題他要解的是一個最佳化問題，主要的特徵在於它的目標函數以及限制式是線性的。線性規劃問題的主要應用範圍在商管領域。但是除了線性規劃這麼特定的問題以外，我們還有整數規劃問題、二次規劃問題以及非線性規劃問題，這些問題的差別是在目標函數的樣貌上面的不同。</p><p>這類的問題全部都圍繞在最佳化上頭，他底層的理論是最佳化理論或是 convex optimization。這些規劃問題跟最佳化理論在第二次世界大戰中高速發展著，由於戰爭的緣故促使這些方法被發展出來，也包含當時發展對偶理論的天才數學家馮·諾伊曼（John von Neumann）。</p><p>我們一直都認為一個智慧的個體他需要會 <strong>規劃</strong>，但是規劃本身可以被化為一個數學問題，所以解出這個數學問題本身是不是具有智慧的？抑或是，人類利用了他的智慧將一個應用問題轉化成一個可解的數學問題？</p><h2 id="搜尋問題"><a href="#搜尋問題" class="headerlink" title="搜尋問題"></a>搜尋問題</h2><p>我們常常想要在一堆東西當中找到我們要的東西，有的時候像是在圖書館找書，我確定我要找的書在圖書館中，他非常的確切而且範圍也有限，但有的時候他像是在大海中撈針，我確定針就在海裡，但是海實在是太大了。</p><p>有的時候我們上次在網路上找我們想要的資源，網路本身是個複雜的系統，有上億甚至更多的網路節點，這些網路節點互相連結，我們要如何找到一條最有效的路徑到我們想去的地方？</p><p>這些問題都可以被化成一個搜尋問題，有的搜尋問題我們只需要簡單的排序就可以處理，有的搜尋問題牽涉到比較複雜的圖論結構，更有些問題他的搜尋空間是無限維度的。</p><p>我們必須思考一下會解這些問題是不是一個智慧的行為？解這些問題解的快是否意味著比較聰明？</p><h2 id="建模"><a href="#建模" class="headerlink" title="建模"></a>建模</h2><p>建模一直是在科學領域當中非常重要的一件事情，透過模型的建立，模型可以給我們的是對未來的預測，以及因果關係的建立。我們可以透過模型去得知以及解釋為什麼會這樣？為什麼會那樣？</p><p>在物理領域，我們常常用微分方程作為建模的工具，物理學家會去找出自然界中有可能影響的因子，並且把它放到微分方程中成為一個系統。我們可以去觀測這個系統的輸入以及輸出，去推論整個系統的運作。</p><p>但是我們怎麼知道系統內部是怎麼運作的？如果不知道系統是怎麼運作的，我們是無法將一個因子放到微分方程的數學描述中的。如果一個物理系統的狀態是可以被觀察的，我們當然可以很輕易的理解輸入以及輸出之間的關係。但是常常系統的狀態並不是可以被觀察的，像是大氣當中的氣體分子，我們或許知道他的巨觀狀態，但是我們無法得知每個氣體分子在每一個時刻的速度及位置。更別說在微觀的量子世界當中，由於測不準原理，你無法同時知道一個粒子他的確切速度以及位置。</p><p>不過數學提供了我們一個框架，一個邏輯而理性的框架，在純粹邏輯與理性的抽象世界中，我們可以去推論出這個系統的輸入及輸出關係應該是什麼。即便我們不需要一一去觀察每一個系統的輸入及輸出或是觀察系統的狀態，我們仍舊可以透過數學的框架去預測這個系統的行為，或許我們有一天可以從亞馬遜熱帶雨林的一隻蝴蝶翅膀拍動的資料去預測一個超大型颶風的來臨，我們不需要等到真的可以觀測到颶風的那天。</p><p>廣義來說，微分方程模型也可以視為一種機器學習的方法。你可以在機器學習的書當中看到動態系統模型或是 state space model，那些其實是微分方程模型的變體。</p><h2 id="機率"><a href="#機率" class="headerlink" title="機率"></a>機率</h2><p>機率論其實來自數學，更精確的說是測度論。</p><p>我們的生活中常常以機率作為事情的描述，機器學習當然也不例外，同時也是統計的基礎。</p><p>當我們面對 <strong>不確定性</strong> 的時候我們就會用機率作為描述的語言，機率本身就是一個很好的模型。</p><p>在這個假設之下衍生出了非常多有用的方法及模型，像是蒙地卡羅馬可夫法。機率同時也在布朗運動中扮演了重要的角色，無論在技術、科學，甚至是生活當中，數學都扮演著核心的角色。</p><h2 id="機器學習框架"><a href="#機器學習框架" class="headerlink" title="機器學習框架"></a>機器學習框架</h2><p>我曾經點出機器學習的框架，主要由三個層面組成：</p><ol><li>model</li><li>error function or loss function</li><li>optimization</li></ol><p>我們從最底層的最佳化開始講，線性規劃就是一個最簡單的最佳化問題，但是發展出來的演算法只能解這麼一個特定的問題。有沒有更廣義的解法，可以解眾多的最佳化問題？梯度下降法是一個。但是他有個缺點，他會卡在 local minimum，那有沒有可以得到 global minimum 的演算法？最早的應該是模擬退火法，接著有名的是基因演算法，然後是蟻群演算法以及蜂群演算法。另一個在系統模擬的領域很紅的 Markov chain Monte Carlo 法，早期的應該是 Metropolis-Hastings method，近期則是有 No-U-Turn method。</p><p>這些方法都有個共同的特質，他們都有個目標函數需要最大化或是一個損失函數（loss function）需要最小化。這些都是最佳化理論可以解或是處理的對象。</p><p>而 error function 或是損失函數的定義，說明了你要解的問題或是問題的目標。error 是個很好的思考點，真實世界中存在著與理論值不完全相同的測量值，我們把這兩者個差距稱為誤差，我們把這樣的現象稱為不確定性，這時候機率論就進來了！一個自然現象有他的 error pattern，我們可以藉由蒐集資料得知整體的誤差會呈現什麼樣的機率分佈。統計，是希望能從分佈當中得到一點什麼有用的資訊。</p><p>我們希望從這一切的資料中找尋 <strong>規律與模式</strong>，model 是一種數學語言，他是我們能夠理解的 <strong>規律</strong>。我們從乍看之下非常混亂的資料當中，尋找我們想找的規律。規律，是生於混亂的。model 是建立在 error 之上的。當你無法理解 error 是什麼，你就無法在上面建立 model。當今的 model 百百種，深度學習不過是最紅的一類而已。</p><p>機器學習的框架，是漂亮的的把這三者集大成，利用最佳化去推動模型的更新，利用 loss function 去塑造跟定義問題，利用 model 將人類腦中想的規則更具體的描述出來。整個脈絡奠基於數學之上。</p><h2 id="核心"><a href="#核心" class="headerlink" title="核心"></a>核心</h2><blockquote><p>數學充斥著我們的生活。</p></blockquote><p>今天，數學是 AI 的技術核心。 是的，數學披上了 AI 的外表，以全新的姿態展現在人們的面前，人們再一次地為數學的深奧俯首稱臣，但人們不知道的是數學的假設完全來自於人類的理性，甚至我可以很肯定的說 <strong>數學就是人類的理性本身</strong>。</p><p>其實人類本身就蘊含著數學，其實人類是可以完全理解數學的，只是非常多人在理解數學以前，就先用了非理性的恐懼阻擋了自己的去路。</p><h2 id="三位一體"><a href="#三位一體" class="headerlink" title="三位一體"></a>三位一體</h2><p>在 AI 的領域中，最重要的不是去訓練模型，而是 <strong>把數學運算、資料特性以及解釋三者串連起來</strong>。我們想要知道什麼樣的資料特性需要用特定的數學運算處理，我們也想知道使用這樣的數學運算的理由是什麼，這些理由會影響到模型的建構以及後續的解釋，他們三者就像基督教中的三位一體密不可分，但是又個別扮演著角色。</p><p><em>數學運算</em> 代表的是在神經網路模型中的 layer-layer 之間的轉換，他可以是內積可以是捲積，還可以是 recurrent。</p><p><em>資料特性</em> 決定了你應該用怎麼樣的數學運算來處理跟萃取資訊，這很大程度取決於你對於資料以及問題的了解程度。</p><p><em>解釋</em> 是指可以從模型當中去解釋結果所代表的意義，雖然目前可以做到的有限，但是你還是可以從數學運算中去看出一些端倪。</p><p>我在先前的幾篇文章中試圖要做到這件事情，我希望可以連結數學運算、資料特性以及解釋，我想這才是在做 AI 的科學的研究。</p>]]></content>
    
    <summary type="html">
    
      &lt;!-- toc --&gt;
&lt;h2 id=&quot;AI-是什麼？&quot;&gt;&lt;a href=&quot;#AI-是什麼？&quot; class=&quot;headerlink&quot; title=&quot;AI 是什麼？&quot;&gt;&lt;/a&gt;AI 是什麼？&lt;/h2&gt;&lt;p&gt;很多人探討 AI 會追隨前人的探討，去探討什麼是智慧？或是什麼樣的是強人工智慧？&lt;/p&gt;
&lt;p&gt;當然我也做過一樣的事情，只是今天我想從比較 &lt;strong&gt;技術層面&lt;/strong&gt;、比較 &lt;strong&gt;務實&lt;/strong&gt; 的角度切入這一大類技術。&lt;/p&gt;
&lt;p&gt;從比較技術層面跟務實的角度切入，就表示我想討論的是現今人工智慧的實作層面，也就是 &lt;strong&gt;AI 是怎麼被做出來的？（how）&lt;/strong&gt;，並非討論 &lt;strong&gt;AI 是什麼？(what)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AI 是什麼？&lt;/strong&gt; 這議題會牽涉到什麼是智慧？而智慧這種事情連人類自身都說不清楚，有的人從哲學層面討論智慧，動物有動物的智慧，人類有人類的智慧，憑什麼說人類的『智慧』才稱為智慧？有的人從生物角度切入， 從大腦的結構與神經元的連結，到神經元的觸發，這一系列的科學探索，或許我們未來可以回答智慧是什麼？但目前仍舊是一個大謎團。&lt;/p&gt;
&lt;p&gt;我今天要談的都不是這些，我要談的是深度學習的核心，不！是機器學習的核心…… 嗯……等等，所以那是什麼？&lt;/p&gt;
    
    </summary>
    
      <category term="Deep Learning" scheme="https://yuehhua.github.io/categories/Deep-Learning/"/>
    
    
  </entry>
  
  <entry>
    <title>Activation function 到底怎麼影響模型？</title>
    <link href="https://yuehhua.github.io/2018/07/27/activation-function/"/>
    <id>https://yuehhua.github.io/2018/07/27/activation-function/</id>
    <published>2018-07-27T03:02:54.000Z</published>
    <updated>2018-07-27T03:17:56.344Z</updated>
    
    <content type="html"><![CDATA[<p>今天我們來談談 activation function 吧！</p><h2 id="先談談線性轉換"><a href="#先談談線性轉換" class="headerlink" title="先談談線性轉換"></a>先談談線性轉換</h2><p>談 activation function 之前先要談談線性轉換。</p><p>有上到比較後面的線性代數的同學，應該有爬過 SVD 這座高山。</p><p>推薦可以看周老師的線代啟示錄 <a href="https://ccjou.wordpress.com/2009/09/01/%E5%A5%87%E7%95%B0%E5%80%BC%E5%88%86%E8%A7%A3-svd/" target="_blank" rel="noopener">奇異值分解 (SVD)</a></p><p>我們可以知道一個矩陣可以被看成線性轉換，而矩陣這個線性轉換可以被分解成 3 個矩陣：</p><a id="more"></a><p>$$<br>A = U \Sigma V^T<br>$$</p><p>這 3 個矩陣分別是有意義的，$U$、$\Sigma$、$V$ 的意義分別是旋轉、伸縮、旋轉的意思。大家可以參考以下的圖：</p><p><img src="https://ccjou.files.wordpress.com/2009/09/svd32.jpg?w=400&amp;h=300" alt=""></p><blockquote><p>圖來自以上提到的文章</p></blockquote><p>所以我們可以知道矩陣能做的事情大概就是旋轉伸縮這些事情了。</p><p>在模型上，我們還會加上一個 bias 來達到平移的效果。</p><p>我們可以來造一些點：</p><p><img src="/images/activation1.png" alt=""></p><p>我們可以 random 造一個矩陣：</p><p>$$<br>A =<br>\begin{bmatrix}<br>0.35166263&amp; 0.1124966 \\<br>0.25249535&amp; 0.65481947 \\<br>\end{bmatrix}<br>$$</p><p>所以我們可以對每個點做運算 $Ax$：</p><p><img src="/images/activation2.png" alt=""></p><h2 id="去吧！Activation-function！"><a href="#去吧！Activation-function！" class="headerlink" title="去吧！Activation function！"></a>去吧！Activation function！</h2><p>接下來我們先來試試看在 CNN 用最多的 ReLU，我們把上面的點通過 ReLU 之後會發生什麼事呢？</p><p><img src="/images/activation3.png" alt=""></p><p>大家會發現只留下第一象限的點是沒有動到的，剩下的象限的點都被擠到 x 軸跟 y 軸上了。</p><p>所以在高維度的世界中，點都會保留第一象限不變，其他象限被擠壓到軸上。</p><p>那如果是用 sigmoid 的效果呢？</p><p><img src="/images/activation4.png" alt=""></p><p>他將所有的點都壓到 (0, 1) 之間，所以整個形狀就縮小很多。</p><p>我們放大來看看他整體形狀有沒有什麼變化。</p><p><img src="/images/activation5.png" alt=""></p><p>整體形狀有些微被扭曲了，不知道大家有沒有發現呢？</p><p>所以在引進 activation function 之後，模型擁有了 <strong>扭曲</strong> 的能力！</p><p>那麼 activation function 到底實際上做了什麼事呢？</p><h2 id="雕塑的工匠"><a href="#雕塑的工匠" class="headerlink" title="雕塑的工匠"></a>雕塑的工匠</h2><p>以 ReLU 來說，他就像一個工匠正在雕塑一個作品。</p><p>ReLU 就是工匠手上那把彫刻刀，他會把第一象限以外的部份削掉。看起來就會像朱銘大師的作品這樣：</p><p><img src="http://digitalarchives.artcenter.ncku.edu.tw/walkncku_cht/image/a51d2-dsc_7226.jpg" alt=""></p><blockquote><p>圖來自 <a href="http://digitalarchives.artcenter.ncku.edu.tw/walkncku_cht/" target="_blank" rel="noopener">漫遊‧藝術網＠成大校園</a></p></blockquote><p>原諒我私心用成大的雕塑品當範例。XD</p><p>ReLU 會將不重要的部份削掉，剩下重要的特徵接續後面的特徵萃取。</p><h2 id="消失的梯度"><a href="#消失的梯度" class="headerlink" title="消失的梯度"></a>消失的梯度</h2><p>以 sigmoid 來說，他將點壓到 (0, 1) 之間看似很難以理解。</p><p>其實這個 activation function 在影像辨識當中比較不是主流的方法，可能不是那麼適用，不過在 NLP 領域算是還蠻常用的方法。</p><p>那如果放在 CNN 的話，就會發生梯度消失的問題。</p><p>在比較早期的時候，大家在影像處理上都遇到梯度消失的問題。如果直觀上看來，如果每過一次 convolution layer 就會被壓縮到 (0, 1) 一次，那麼後面再接 subsampling 的處理，又會縮小一次，並且失去某些訊息，想當然爾特徵就在不斷縮小的過程中慢慢不見了。這樣的效果讓早期的模型無法變得更深。</p><p>讓 convolution layer 去篩選哪些 feature 該留下來，讓 subsampling layer 去做縮小的動作，各自負責各自的功能，這樣看來是比較好的作法。</p><p>這是一個比較直觀的解釋方式，歡迎大家提出不同的看法。</p><h2 id="模型怎麼知道要從哪裡下刀？"><a href="#模型怎麼知道要從哪裡下刀？" class="headerlink" title="模型怎麼知道要從哪裡下刀？"></a>模型怎麼知道要從哪裡下刀？</h2><p>我想蠻多人應該會有跟我一樣的問題。</p><p>我知道如果用 ReLU 可以把不要的部份削掉，那麼我怎麼知道要削哪裡？</p><p>答案是 backpropagation (gradient descent method) 會告訴你！</p><p>藉由 forward 將訊息傳遞到 output layer，backward 所回饋的 gradient 正提供一個訊息，這個訊息會告訴模型要怎麼調整線性轉換的矩陣，來讓 ReLU 可以切在對的位置。</p><h2 id="為什麼-activation-function-一定要長這樣？"><a href="#為什麼-activation-function-一定要長這樣？" class="headerlink" title="為什麼 activation function 一定要長這樣？"></a>為什麼 activation function 一定要長這樣？</h2><p>其實沒有規定 activation function 一定要長怎樣。</p><p>但是拿多項式函數或是其他函數會讓整個模型非常難以理解，而且當中的參數還不少。</p><p>所以依照 Occam’s razor 的原則，我們先拿簡單的函數來用會比較好。</p><h2 id="結論"><a href="#結論" class="headerlink" title="結論"></a>結論</h2><p>不同的模型跟問題其實適用不同的 activation function。</p><p>像影像辨識中，CNN 的設計是要先做 feature extraction，再進行分類。</p><p>所以在 feature extraction 的階段就需要找適用的 activation function。</p><p>那像在 NLP 領域，他們關心的是機率分佈，而 sigmoid 就很合機率分佈的調調。</p><p>這邊原諒我草率帶過 NLP 的部份，今天的主軸都擺在 CNN 上。XD</p><p>今天就到這邊告一個段落囉。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今天我們來談談 activation function 吧！&lt;/p&gt;
&lt;h2 id=&quot;先談談線性轉換&quot;&gt;&lt;a href=&quot;#先談談線性轉換&quot; class=&quot;headerlink&quot; title=&quot;先談談線性轉換&quot;&gt;&lt;/a&gt;先談談線性轉換&lt;/h2&gt;&lt;p&gt;談 activation function 之前先要談談線性轉換。&lt;/p&gt;
&lt;p&gt;有上到比較後面的線性代數的同學，應該有爬過 SVD 這座高山。&lt;/p&gt;
&lt;p&gt;推薦可以看周老師的線代啟示錄 &lt;a href=&quot;https://ccjou.wordpress.com/2009/09/01/%E5%A5%87%E7%95%B0%E5%80%BC%E5%88%86%E8%A7%A3-svd/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;奇異值分解 (SVD)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;我們可以知道一個矩陣可以被看成線性轉換，而矩陣這個線性轉換可以被分解成 3 個矩陣：&lt;/p&gt;
    
    </summary>
    
      <category term="Deep Learning" scheme="https://yuehhua.github.io/categories/Deep-Learning/"/>
    
    
  </entry>
  
  <entry>
    <title>Basis for topology</title>
    <link href="https://yuehhua.github.io/2018/07/25/10-basis-for-topology/"/>
    <id>https://yuehhua.github.io/2018/07/25/10-basis-for-topology/</id>
    <published>2018-07-25T15:57:56.000Z</published>
    <updated>2018-08-07T03:20:02.035Z</updated>
    
    <content type="html"><![CDATA[<p>上一篇介紹完基本的拓樸結構，接下來我們來看基底（basis）的部份。</p><p>有上過線性代數的朋友們應該會知道，向量如果滿足線性獨立可以 span 到整個空間，而一個空間有他們的基底。</p><p>你可以把向量看成一種數學物件，空間的話就是很多這種數學物件的集合，那相對基底的話就是要擴展成整個空間的基本元素。</p><p>拓樸也是一樣的，開集（open set）也是一種數學物件，一個拓樸空間中所包含的元素就是開集，那麼就會很自然的想知道他的基底是什麼？</p><a id="more"></a><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$X$ is a set, $\mathcal{T}$ is a topology on $X$, a <strong>basis</strong> for $\mathcal{T}$ is a collection $\mathcal{B}$ of subsets of $X$, <strong>basis elements</strong> are elements in $\mathcal{B}$, $\mathcal{B}$ must have the following properties:</p><ol><li>$\forall x \in X, \exists$ basis element $B \supseteq x$</li><li>$B_1, B_2, B_3$ are basis elements, if $x \in B_1 \cap B_2$, $\exists B_3 \supseteq x$ and $B_3 \subseteq B_1 \cap B_2$</li></ol><p>如果一個拓樸有滿足這兩個條件，那我們就可以說 <strong>拓樸 $\mathcal{T}$ 是由 $\mathcal{B}$ 生成的（generated）</strong>。</p><p>現在就來解釋一下上面的意思，我們應該不難理解，如果把拓樸看成一個空間的話，他是很多開集的集合，那麼基底 $\mathcal{B}$ 也會是集合的集合。在線性代數中，我們可以透過線性組合來把基底擴充到整個空間，那就表示那他應該是一組很基本的元素集合。這邊也有類似的概念，當一個基底可以擴充成一個拓樸的時候，那麼他就應該俱備以上兩種特性。</p><p>那麼線性代數可以用線性組合來 span 到整個空間。那麼拓樸的基底可以怎麼辦？我們可以用聯集（union）阿！</p><p>剛剛我們提到開集，我們都還沒定義開集呢！</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>A subset $U \subseteq X$ is <strong>open</strong> in $X$, if $\forall x \in U$, $\exists$ basis element $B \in \mathcal{B}$ s.t. $x \in B$ and $B \subseteq \mathcal{B}$</p><p>開集大概就像向量般的存在，而拓樸就是向量空間這樣子。依據這邊的定義，一個開集 $U$ 他裡面的元素 $x$ 都要在基底的元素當中（$x \in B$），然後基底元素是基底的子集（$B \subseteq \mathcal{B}$）。要記住，每個基底元素都 $\mathcal{T}$ 的元素。</p><p>舉個例子看看吧！</p><blockquote><p>ex.</p></blockquote><p><img src="/images/basis.svg" alt=""></p><p>如果 $\mathcal{B}$ 是所有圓圈區域的基底，那麼他一定滿足上面兩個條件。</p><blockquote><p>ex.</p></blockquote><p>如果 $X$ 是一個集合，那麼所有只包含一個點的 $X$ 的子集合的集合，是 $X$ 的離散拓樸的基底</p><blockquote><p>ex.</p></blockquote><p><img src="/images/basis2.svg" alt=""></p><p>假設 $U_1$ 跟 $U_2$ 是拓樸 $\mathcal{T}$ 的元素，我們是不是可以證明 $U_1 \cap U_2 \in \mathcal{T}$？</p><p>假設有個 $x \in U_1 \cap U_2$，我們可以找到一個基底元素 $B_1$，$x \in B_1$，$B_1 \subseteq U_1$；我們可以找到另一個基底元素 $B_2$，$x \in B_2$，$B_2 \subseteq U_2$。</p><p>這樣從基底的第二的條件是不是可以推出有個 $B_3$，$x \in B_3$，$B_3 \subseteq B_1 \cap B_2$。</p><p>那麼從 $x \in B_3$ 跟 $B_3 \subseteq B_1 \cap B_2 \subseteq U_1 \cap U_2$，可以推出 $U_1 \cap U_2 \in \mathcal{T}$。</p><p>證明了 $U_1 \cap U_2 \in \mathcal{T}$，那麼我們大可以用數學歸納法證明 $\bigcup_{i=1}^{n} U_i \in \mathcal{T}$。</p><p>這樣我們也檢驗了由基底生成的開集的集合是一個拓樸。</p><p>我們也可以從另一個面向切入，描述他們之間的關係。</p><blockquote><p> <strong><em>Lemma</em></strong></p></blockquote><p>$X$ is a set, $\mathcal{B}$ is a basis for topology $\mathcal{T}$, </p><p>$$<br>\mathcal{T} = \bigcup_{B \in \mathcal{B}} B<br>$$</p><p>這個引理說明，一個拓樸 $\mathcal{T}$ 就等同於他的基底所有元素的聯集所成的集合。</p><p>有另一個引理從另一個面向切入：</p><blockquote><p> <strong><em>Lemma</em></strong></p></blockquote><p>$X$ is a topological space, $\mathcal{C}$ is a collection of open sets of $X$ such that</p><p>$\forall$ open set $U \subseteq X, x \in U, \exists C \in \mathcal{C} s.t. x \in C \subseteq U$.</p><p>Then $\mathcal{C}$ is a basis for the topology of $X$.</p><p>這次是從開集的角度來切入的，如果有一個開集的集合 $\mathcal{C}$，這些開集是從 $X$ 這個拓樸空間來，那麼 $\mathcal{C}$ 當中的元素 $C$ 如果滿足 $x \in C \subseteq U$ 這個條件的話，那麼 $\mathcal{C}$ 就是拓樸空間 $X$ 的基底了。</p><p>如果有了基底之後就很有用，由基底生成的拓樸，我們可以藉由基底來判斷一些條件是否滿足：</p><blockquote><p> <strong><em>Lemma</em></strong></p></blockquote><p>$\mathcal{B}$ and $\mathcal{B}^\prime$ are bases for the topology $\mathcal{T}$ and $\mathcal{T}^\prime$, respectively, on $X$. The following are equivalent:</p><ol><li>$\mathcal{T}^\prime$ is finer than $\mathcal{T}$</li><li>for each $x \in X, x \in B \in \mathcal{B}, \exists B^\prime \in \mathcal{B}^\prime s.t. x \in B^\prime \subseteq B$</li></ol><p>一個拓樸的細緻程度，我們可以從他的基底看出來，同樣包含 $x$ 的基底元素（$B$ 跟 $B^\prime$），比較細緻的拓樸的基底元素就會比較小（$B^\prime \subseteq B$）。</p><p>今天討論基底就到這邊拉！下次會介紹一些比較常見的拓樸。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;上一篇介紹完基本的拓樸結構，接下來我們來看基底（basis）的部份。&lt;/p&gt;
&lt;p&gt;有上過線性代數的朋友們應該會知道，向量如果滿足線性獨立可以 span 到整個空間，而一個空間有他們的基底。&lt;/p&gt;
&lt;p&gt;你可以把向量看成一種數學物件，空間的話就是很多這種數學物件的集合，那相對基底的話就是要擴展成整個空間的基本元素。&lt;/p&gt;
&lt;p&gt;拓樸也是一樣的，開集（open set）也是一種數學物件，一個拓樸空間中所包含的元素就是開集，那麼就會很自然的想知道他的基底是什麼？&lt;/p&gt;
    
    </summary>
    
      <category term="Topology" scheme="https://yuehhua.github.io/categories/Topology/"/>
    
    
  </entry>
  
  <entry>
    <title>Topology space and topology</title>
    <link href="https://yuehhua.github.io/2018/07/22/09-topology/"/>
    <id>https://yuehhua.github.io/2018/07/22/09-topology/</id>
    <published>2018-07-21T16:32:23.000Z</published>
    <updated>2018-07-26T05:28:16.524Z</updated>
    
    <content type="html"><![CDATA[<p>我們終於來到拓樸學的大門口了！</p><p>（謎：前面走那麼多圈是在幹什麼的！</p><p>拓樸其實是幾何學的拓展，他往更基礎的方向去，當我們在探討幾何學的時候，其實我們研究的是空間關係。</p><p><img src="https://upload.wikimedia.org/wikipedia/commons/8/85/Stereographic_projection_in_3D.png" alt=""></p><a id="more"></a><p>空間關係裏面，我們研究大小、位置、角度、維度，再到比較高階的概念：面積或體積。</p><p>這邊需要一些線性代數的基礎進來，我們知道高階的概念是建立在較基礎的概念上，像是在有面積跟體積之前，要先定義長度，而長度則是由線性代數的範數（norm）給出，而角度的概念也是要先定義範數。</p><p>賦範空間（normed space）則是有定義範數的座標系。</p><p>空間中的位置與維度則是由座標系定義，而座標系則是我們先前定義的 m-tuple 的集合（所構成的空間）。</p><p>那麼最基礎的東西是什麼呢？</p><p>座標系中的 m-tuple，每個元素是由實數定義的。前面我們花時間討論了實數與整數。</p><p>在實數當中，我們之能知道兩個實數之間的關係，只能是大於、小於或等於三者其中之一。</p><p>但是當我們想討論空間中的 <strong>連續性</strong>，或是空間中的 <strong>鄰近</strong> 關係的時候，我們不知道到底什麼是連續？什麼是鄰近？</p><p>或許你可以說連續就是一個挨著一個，緊接著的元素或是數字，那這樣整數是連續的嗎？</p><p>數字 1 下一個是 2？</p><p>或是 1.0 的下一個是 1.000000000000000000000000000000001？</p><p>不對阿！那你把 1.0000000000000000000000000000000005 放到哪裡去了？</p><p>我們會認為實數是連續的，但整數不是，可是我們在整數中可以找到 <strong>下一個</strong>，可是實數當中不行。</p><p>所以 <em>找不到下一個人的系統</em> 就是連續？當然不是阿！我可以不要定義下一個人是誰就不會有下一個人阿！</p><p>所以拓樸學研究的就是空間上的連續跟鄰近關係。</p><hr><p>我們會先討論 <strong>鄰近</strong>，或是 <strong>鄰居</strong> 的概念。</p><p>近代分析學的基礎是極限，微分跟積分都是根基於這個概念之上，而對於極限的探討跟嚴謹程度造就了拓樸學這個領域。在極限的概念之中，我們談的是逼近，在 $\epsilon - \delta$ 的證明當中，不難發覺他其實給了一個不定的範圍，可大可小，那逼近的程度就可以計算得出來了，而 <strong>鄰近</strong> 的概念正是可以在這邊發揮作用的。</p><p><img src="/images/topology1.svg" alt=""></p><p>一條直線，我們可以把他想成一條軟繩子，繩子上的任何一點，無論繩子怎麼扭曲，點鄰近的區域是不變的。不過這時候如果我們把繩子的兩頭相接起來那就不一樣了。</p><p><img src="/images/topology2.svg" alt=""></p><p>我們可以看上面這個圖，當繩子繞成一個圓的時候，相接的黑點的鄰近區域是黑點的左右兩塊。黑點剛好對應到線段的兩個端點，兩個端點的鄰近區域是上圖中紅色所顯示的。你可以看到繩子因為被接起來，所以改變了他的鄰近區域，而這個改變我們可以用一個函數來把他對映起來：</p><p>$$<br>f(x) = x \enspace mod \enspace 12<br>$$</p><p>你可以想像有類似時鐘的 12 個數字擺在圓的線上，而線段上也有 1~12 的數字，在時鐘上的 12 鄰近有 11 跟 1，但是在線段上的 12 的鄰近只有 11，上述的函數則是可以把線段對映到圓上。</p><div style="text-align:center">線 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 圓</div><p>$$<br>\begin{bmatrix}<br>\vdots \\<br>10 \\<br>11 \\<br>12 \\<br>13 \\<br>14 \\<br>\vdots<br>\end{bmatrix}<br>\rightarrow<br>\begin{bmatrix}<br>\vdots \\<br>10 \\<br>11 \\<br>0 \\<br>1 \\<br>2 \\<br>\vdots<br>\end{bmatrix}<br>$$</p><p>原本在空間上，線段是無法由一頭持續走向另一頭的，但是卻可以透過函數來把兩頭接起來，這樣鄰近的空間也改變了，這時候我們想要描述空間中的鄰近關係，我們透過集合論給出了以下的特性：</p><p>一個鄰近區域（neighborhood） $X$，$\forall x \in X$，我們說 $X$ 是 $x$ 的鄰近區域，他需要滿足：</p><ol><li>$x$ 在它自己的鄰近區域中</li><li>兩個 $x$ 的鄰近區域的交集仍然是 $x$ 的鄰近區域</li><li>若 $X$ 的子集包含了 $x$ 的鄰近區域，那麼他也是 $x$ 的鄰近區域</li><li>$x$ 的鄰近區域的內部也是 $x$ 的鄰近區域</li></ol><p><img src="/images/topology3.svg" alt=""></p><p>這些特性含蠻直觀的。$x$ 要在它自己的鄰近區域中，不滿足的話會導致很多運算都沒有封閉性。鄰近區域的交集仍是 $x$ 的鄰近區域也是很直觀的特性。最後兩條其實是有點相對的概念，第 3 條描述到一個比 $x$ 的鄰近區域大的，他也要是 $x$ 的鄰近區域，而第 4 條則是比 $x$ 的鄰近區域更小的，也要是 $x$ 的鄰近區域。</p><p>不過這樣的定義很複雜，不好用，所以後續引出了 <strong>拓樸（topology）</strong> 的定義，來代表鄰近區域：</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>A topology on a set $X$ is a collection $\mathcal{T}$ of subsets of $X$ having the following properties:</p><ol><li>$\emptyset, X \in \mathcal{T}$</li><li>$\bigcup_{A \in \mathcal{T}} A \in \mathcal{T}$</li><li>$\bigcap_{A_i \in \mathcal{T}} A_i \in \mathcal{T}$, $i$ is finite</li></ol><p>來解釋一下，一個是需要定義在一個集合 $X$ 上的，而拓樸是 $X$ 的子集合的集合 $\mathcal{T}$。這個拓樸 $\mathcal{T}$ 需要滿足一些特性。空集合跟集合 $X$ 本身也在 $\mathcal{T}$ 中，這應該蠻直覺的，也就是集合 $X$ 是在自己的鄰近區域，有時候自己的鄰近區域沒有人也是很正常的。接著是，拓樸中的元素互相取聯集，仍然在這個拓樸中，也就是，鄰近區域的聯集仍然是鄰近區域。最後，拓樸中的元素互相取交集，仍然在這個拓樸中，也就是，鄰近區域的交集仍然是鄰近區域。不過要注意的是，聯集可以取無限聯集，但交集只能有限次數，主要是取無限次的交集很有可能都變成空集合，他就沒有意義，而且我們不知道無限次的交集到底是長什麼樣子。</p><p>這時候我們就會稱這個集合 $X$ 為 <strong>拓樸空間（topological space）</strong>。</p><p>更好的說法是，拓樸空間其實是集合跟拓樸的配對 $(X, \mathcal{T})$，所以他應該包含一個集合跟一個拓樸，但沒有異議的話，常常省略 $\mathcal{T}$ 不講。</p><p>這時候就需要來點例題幫助理解這個抽象概念。</p><h4 id="ex"><a href="#ex" class="headerlink" title="ex."></a><em>ex.</em></h4><p>$X = \{A, B, C\}$ 是一個 3 個元素的集合，以下哪些是一個佈於 $X$ 上的拓樸？</p><ol><li>$\mathcal{T} = \{\emptyset, X\}$ 是一個拓樸</li><li>$\mathcal{T} = \{\emptyset, \{A\}, \{A, B\}, X\}$ 是一個拓樸</li><li>$\mathcal{T} = \{\emptyset, \{B\}, \{A, B\}, \{B, C\}, X\}$ 是一個拓樸</li><li>$\mathcal{T} = \{\emptyset, \{A\}, X\}$ 是一個拓樸</li><li>$\mathcal{T} = \{\emptyset, \{A, B\}, \{C\}, X\}$ 是一個拓樸</li><li>$\mathcal{T} = \{\emptyset, \{A\}, \{B\}, \{A, B\}, X\}$ 是一個拓樸</li><li>$\mathcal{T} = \{\emptyset, \{A\}, \{B\}, X\}$ 不是一個拓樸<ul><li>$\{A\}, \{B\}$ 的聯集不在 $\mathcal{T}$ 中</li></ul></li><li>$\mathcal{T} = \{\emptyset, \{A, B\}, \{B, C\}, X\}$ 不是一個拓樸<ul><li>$\{A, B\}, \{B, C\}$ 的交集不在 $\mathcal{T}$ 中</li></ul></li></ol><p>接下來就來名詞解釋拉！</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$X$ 是一個集合</p><ol><li>The collection of all subsets of $X$ (the power set of $X$, $\mathcal{P}(X)$) is called <strong>discrete topology（離散拓樸）</strong></li><li>$\{ \emptyset, X \}$ is called <strong>trivial topology</strong> or <strong>indiscrete topology</strong></li></ol><p>我們可以來比較看看這兩個拓樸：$\{\emptyset, X\}, \{\emptyset, \{A\}, \{A, B\}, X\}$（用上面例子的集合定義）。</p><p>兩者都是佈於 $X$ 的拓樸，那他們有什麼差別呢？我們可以這樣說：</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$\mathcal{T}, \mathcal{T}’$ 是兩個佈於集合$X$ 的拓樸：</p><ol><li>If $\mathcal{T}’ \supseteq \mathcal{T}$, $\mathcal{T}’$ is <strong>finer（細緻）</strong> than $\mathcal{T}$.</li><li>If $\mathcal{T}’ \subseteq \mathcal{T}$, $\mathcal{T}’$ is <strong>coarser（粗略）</strong> than $\mathcal{T}$.</li></ol><p>引入了這樣的描述方式，我們一樣可以用集合中的 strictly（嚴格）finer or coarser 來描述他們。如果兩個拓樸可以用以上兩種關係來描述的話，我們就說他們是 <strong>comparable</strong>。</p><p>有的人會以 smaller, larger 或是 weaker, stronger 來描述，只是這樣沒有那麼的傳神。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我們終於來到拓樸學的大門口了！&lt;/p&gt;
&lt;p&gt;（謎：前面走那麼多圈是在幹什麼的！&lt;/p&gt;
&lt;p&gt;拓樸其實是幾何學的拓展，他往更基礎的方向去，當我們在探討幾何學的時候，其實我們研究的是空間關係。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/8/85/Stereographic_projection_in_3D.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Topology" scheme="https://yuehhua.github.io/categories/Topology/"/>
    
    
  </entry>
  
  <entry>
    <title>Infinite sets</title>
    <link href="https://yuehhua.github.io/2018/07/22/08-infinite-sets/"/>
    <id>https://yuehhua.github.io/2018/07/22/08-infinite-sets/</id>
    <published>2018-07-21T16:31:24.000Z</published>
    <updated>2018-07-26T05:28:24.757Z</updated>
    
    <content type="html"><![CDATA[<p>我們已經遇到一些無限集（infinite set），接下來會討論他的一些特性，然後會自然地討論到選擇公理（axiom of choice）。</p><blockquote><p> <strong><em>Theorem</em></strong></p></blockquote><p>$A$ 是一個集合，以下的命題等價：</p><ol><li>$\exists \enspace injective \enspace f: \mathbb{N} \rightarrow A$</li><li>$B \subset A, \exists \enspace bijective \enspace f: A \rightarrow B$</li><li>$A$ is infinite</li></ol><a id="more"></a><p>直觀來說，第一點還蠻直覺的，因為 $\mathbb{N}$ 本身就是無限集，如果要滿足有單射函數存在的話，也就意味著 $A$ 至少跟 $\mathbb{N}$ 一樣大。第二點來說，一開始會覺得有點弔詭，怎麼有人跟自身的嚴格子集一樣大，也就是說，這樣的集合即便多一個或是少一個元素都無所謂，反正都是無限大，當然這是直觀上的推論，並非正式推導。</p><p>比較有趣的是要從第三點推導出第一點，證明邏輯是這樣的，因為 $A$ 本身不是有限集，那他就不會是空集合。我們的目標是要證明存在一個單射函數滿足第一點的條件，那我們可以從 $A$ 取一個元素 $a_1$ 他叫作 $f(1)$，那麼根據歸納法，我們可以跳到假設 $f(1), … , f(n-1)$ 都存在，我們來檢查一下 $A - \{f(1), … , f(n-1)\}$ 仍然不是空集合，那這樣我們就可以再拿出一個元素定義 $a_n = f(n)$，這樣我就根據歸納法造出了一個單射函數了。</p><p>證明圓滿結束！嗯？有問題？哪裡有問題？</p><p>如果我每次從 $A$ 當中取出來的元素，他有可能不是唯一的，不是唯一的有什麼樣的問題呢？不是唯一的，那就有可能會重複被選到，那這樣我們不能接受他是個好的歸納法。也就是，$f(n)$ 要相對 $f(1), … , f(n-1)$ 是唯一的。</p><p>要處理唯一的問題，我只要引進唯一就好了阿！像是我可以定義從 $A$ 中取元素的時候只取最小的。如果最小元素存在的話，$A$ 勢必要是有定義次序關係才行！但是純粹的集合是沒有的。</p><p>這時候我們引進選擇公理來幫我們解決這個問題：</p><blockquote><p> <strong><em>Axiom of choice</em></strong></p></blockquote><p>給一個 collection $\mathcal{A}$ 是非空集合的集合，$\exists C \subseteq \bigcup_{A \in \mathcal{A}} A, \forall A \in \mathcal{A}, C \cap A$ contains only one element.</p><p>以上公理我解釋一下，也就是存在一個集合 $C$，他從 $\mathcal{A}$ 的每一個元素 $A$ 中都取一個元素進來。</p><p>接下來就會有以下的引理：</p><blockquote><p> <strong><em>Lemma</em></strong></p></blockquote><p>給一個 collection $\mathcal{B}$ 是非空集合的集合，$\exists c: \mathcal{B} \rightarrow \bigcup_{B \in \mathcal{B}} B$ s.t. $\forall B \in \mathcal{B}, c(B) \in B.$</p><p>目前先寫到這邊，下面的解釋還有構造方法我還沒理解………..嗚嗚。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我們已經遇到一些無限集（infinite set），接下來會討論他的一些特性，然後會自然地討論到選擇公理（axiom of choice）。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt; &lt;strong&gt;&lt;em&gt;Theorem&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;$A$ 是一個集合，以下的命題等價：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;$\exists \enspace injective \enspace f: \mathbb{N} \rightarrow A$&lt;/li&gt;
&lt;li&gt;$B \subset A, \exists \enspace bijective \enspace f: A \rightarrow B$&lt;/li&gt;
&lt;li&gt;$A$ is infinite&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="Topology" scheme="https://yuehhua.github.io/categories/Topology/"/>
    
    
  </entry>
  
  <entry>
    <title>Countable sets</title>
    <link href="https://yuehhua.github.io/2018/07/22/07-countable-sets/"/>
    <id>https://yuehhua.github.io/2018/07/22/07-countable-sets/</id>
    <published>2018-07-21T16:29:45.000Z</published>
    <updated>2018-07-26T05:28:35.770Z</updated>
    
    <content type="html"><![CDATA[<p>前面有提到正整數可以用來作為有限集的原型，我們會把所有正整數的集合稱為 <strong>可數無限集（countably infinite sets）</strong>。</p><a id="more"></a><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>A set A is <strong><em>infinite</em></strong> if not finite.</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>A set A is <strong><em>countably infinite</em></strong> if<br>$$<br>\exists f: A \rightarrow \mathbb{N}, f \enspace is \enspace bijective.<br>$$</p><h4 id="ex"><a href="#ex" class="headerlink" title="ex."></a><em>ex.</em></h4><p>像是整數本身就是 countably infinite，$f: \mathbb{Z} \rightarrow \mathbb{N}$</p><p>$$<br>f(n) = \begin{cases}<br>2n &amp; n\gt 0 \<br>-2n+1 &amp; n \le 0<br>\end{cases}<br>$$</p><h4 id="ex-1"><a href="#ex-1" class="headerlink" title="ex."></a><em>ex.</em></h4><p>$\mathbb{N} \times \mathbb{N}$ 也是 countably infinite，那要如何證明呢？</p><p>我們需要證明 $f: \mathbb{N} \times \mathbb{N} \rightarrow \mathbb{N}$，由於 $\mathbb{N} \times \mathbb{N}$ 是在座標系的第1象限上的格子點，我們先把他向下圖一樣定一個順序，下圖的順序也包含 0，但是在我們的例子中不包含 0，但概念是一樣的。</p><p><img src="https://upload.wikimedia.org/wikipedia/commons/6/6f/Pairing_natural.svg" alt=""></p><p>我們希望像這樣把 $\mathbb{N}$ 一個一個擺到 $\mathbb{N} \times \mathbb{N}$，這樣我們就可以確認兩者的對應關係了，那要怎麼做呢？</p><p>我們先定個函數 $g(x, y) = (x + y - 1 , y)$，這會把每串黑色箭頭都擺直。</p><p>接著可以用另一個函數 $h(x , y) = \frac{1}{2}(x - 1)x + y$ 幫我們對映到數字。</p><p>對映關係會看起來像這樣：</p><p>$(1, 1) \rightarrow (1, 1) \rightarrow 1$</p><p>$(2, 1) \rightarrow (2, 1) \rightarrow 2$</p><p>$(1, 2) \rightarrow (2, 2) \rightarrow 3$</p><p>$(3, 1) \rightarrow (3, 1) \rightarrow 4$</p><p>$(2, 2) \rightarrow (3, 2) \rightarrow 5$</p><p>如此對映起來之後，再證明這兩個函數的組合是雙射的，就可以證明 $\mathbb{N} \times \mathbb{N}$ 是 countably infinite。</p><p>所以我們就可以給可數下個定義：</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>A set A is <strong><em>countable</em></strong> if it is finite or countably infinite.</p><p>A set A is <strong><em>uncountable</em></strong> if it is not countable.</p><p>那如果我們每次都要證明一個集合是不是可數的就會比較麻煩，以下有些等價的敘述：</p><blockquote><p> <strong><em>Theroem</em></strong></p></blockquote><p>A is a nonempty set.</p><ol><li>A is countable</li><li>$\exists f: \mathbb{N} \rightarrow A$, f is surjective</li><li>$\exists g: A \rightarrow \mathbb{N}$, g is injective</li></ol><p>我們有其他定理：</p><blockquote><p> <strong><em>Theroem</em></strong></p></blockquote><p>$$<br>C \subseteq \mathbb{N}, C \enspace is \enspace infinite, then \enspace C \enspace is \enspace countably \enspace infinite.<br>$$</p><p>跟其他結論：</p><blockquote><p> <strong><em>Corollary</em></strong></p></blockquote><p>A subset of a countable set is countable.</p><blockquote><p> <strong><em>Corollary</em></strong></p></blockquote><p>$\mathbb{N} \times \mathbb{N}$ is countably infinite.</p><blockquote><p> <strong><em>Theroem</em></strong></p></blockquote><p>A countable union of countable sets is countable.</p><p>看到這邊大家不知道有沒有跟我一樣的疑問，為什麼會有 <em>countable union</em> 這樣的敘述呢？</p><p>如果有個集合 $A_n$ 是可數的，$f_n$ is surjective，$f_n: \mathbb{N} \rightarrow A_n$，我們可以選另一個函數 $g$ is surjective，$g: \mathbb{N} \rightarrow J$，使得</p><p>$$<br>h: \mathbb{N} \times \mathbb{N} \rightarrow \bigcup_{n \in J} A_n<br>$$</p><p>所以我們把 <em>countable union</em> 看成在 $n \in J$ 的 $J$，$h$ 可以看成 $f_n$ 跟 $g$ 的合成函數 $h(k, m) = f_{g(k)}(m)$，如此一來，我們已經知道 surjective 函數的合成還是 surjective，而 $\mathbb{N} \times \mathbb{N}$ 也是 countable，這樣我們就可以證明 $\bigcup_{n \in J} A_n$ 是 countable。</p><blockquote><p> <strong><em>Theroem</em></strong></p></blockquote><p>A finite product of countable sets is countable.</p><p>也就是說，$A_1 \times A_2 \times … \times A_n$ 是 countable。</p><blockquote><p> <strong><em>Theroem</em></strong></p></blockquote><p>$$<br>X = \{ 0, 1 \}, then \enspace X^\omega \enspace is \enspace uncountable.<br>$$</p><p>這邊描述了一個特例，以下是比較廣義的敘述：</p><blockquote><p> <strong><em>Theroem</em></strong></p></blockquote><p>$A$ is a set,</p><p>$$<br>\nexists \enspace injective \enspace f: \mathcal{P}(A) \rightarrow A<br>$$</p><p>$$<br>\nexists \enspace surjective \enspace g: A \rightarrow \mathcal{P}(A)<br>$$</p><p>這代表著一個集合的冪集是 <em>uncountable set</em>，無論集合裏面長什麼樣子。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前面有提到正整數可以用來作為有限集的原型，我們會把所有正整數的集合稱為 &lt;strong&gt;可數無限集（countably infinite sets）&lt;/strong&gt;。&lt;/p&gt;
    
    </summary>
    
      <category term="Topology" scheme="https://yuehhua.github.io/categories/Topology/"/>
    
    
  </entry>
  
  <entry>
    <title>Finite sets</title>
    <link href="https://yuehhua.github.io/2018/07/22/06-finite-sets/"/>
    <id>https://yuehhua.github.io/2018/07/22/06-finite-sets/</id>
    <published>2018-07-21T16:27:18.000Z</published>
    <updated>2018-07-26T05:28:46.816Z</updated>
    
    <content type="html"><![CDATA[<p>接下來我們會來討論幾個常見的概念，像是有限集及無限集、可數集及不可數集。</p><p>有限集（finite set）：</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>A set A is <strong><em>finite</em></strong> if</p><p>$$<br>\exists f: A \rightarrow \{ 1, …, n \}, f \enspace is \enspace bijective.<br>$$</p><p>這時我們會說 <em>set</em> $A$ 的 cardinality 是 n。</p><a id="more"></a><p>在這其中，這個定義的結果是不是唯一的？也就是，有沒有一個可能存在一個集合，兩個人數當中的元素個數結果不一樣（一個數到 $m$，一個數到 $n$），但兩個人都是對的？在真實世界，你可能會覺得這根本不可能，但是為了這點，數學家做了一些基礎工作。</p><blockquote><p> <strong><em>Lemma</em></strong></p></blockquote><p>$$<br>A \enspace is \enspace a \enspace set, n \in \mathbb{N}, a_0 \in A, \exists f: A \rightarrow \{ 1, … , n+1\}, f \enspace is \enspace bijective<br>$$</p><p>$$<br>\Leftrightarrow \exists g: A - \{ a_0 \} \rightarrow \{ 1, … , n\}, g \enspace is \enspace bijective<br>$$</p><p>也就是呢，當 $A$ 可以對映到 $n+1$ 個元素的集合的時候，把 $A$ 當中的一個元素拿掉，就必須對映到 $n$ 個元素的集合。</p><p>那接下來我們就可以有這個定理：</p><blockquote><p> <strong><em>Theorem</em></strong></p></blockquote><p>$$<br>A \enspace is \enspace a \enspace set, f: A \rightarrow \{ 1, … , n\}, n \in \mathbb{N}, f \enspace is \enspace bijective, B \subset A<br>$$</p><p>$$<br>then \enspace \nexists g: B \rightarrow \{ 1, … , n\}, g \enspace is \enspace bijective<br>$$</p><p>$$<br>\exists h: B \rightarrow \{ 1, … , m\}, h \enspace is \enspace bijective, m &lt; n<br>$$</p><p>所以是說，$B$ 是 $A$ 的嚴格子集，那麼 $B$ 的 cardinality 就必須跟 $A$ 的不同，並且要比較小。</p><p>以此，我們可以導出以下結論：</p><blockquote><p> <strong><em>Corollary</em></strong></p></blockquote><p>$$<br>If \enspace A \enspace is \enspace finite, B \subset A, \nexists f: A \rightarrow B, f \enspace is \enspace bijective<br>$$</p><blockquote><p> <strong><em>Corollary</em></strong></p></blockquote><p>$$<br>\mathbb{N} \enspace is \enspace not \enspace finite<br>$$</p><blockquote><p> <strong><em>Corollary</em></strong></p></blockquote><p>$$<br>The \enspace cardinality \enspace of \enspace a \enspace finite \enspace set \enspace A \enspace is \enspace uniquely \enspace determined \enspace by \enspace A<br>$$</p><blockquote><p> <strong><em>Corollary</em></strong></p></blockquote><p>$$<br>A \enspace is \enspace finite, B \subset A, B \enspace is \enspace finite<br>$$</p><p>有限集，以下等價：</p><blockquote><p> <strong><em>Corollary</em></strong></p></blockquote><ol><li>$A$ is finite</li><li>Exists a surjective function from a section of $\mathbb{N}$ to $A$</li><li>Exists a injective function from $A$ to a section of $\mathbb{N}$</li></ol><blockquote><p> <strong><em>Corollary</em></strong></p></blockquote><p>$$<br>Finite \enspace unions \enspace and \enspace finite \enspace cartesian \enspace products \enspace of \enspace finite \enspace sets \enspace are \enspace finite<br>$$</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;接下來我們會來討論幾個常見的概念，像是有限集及無限集、可數集及不可數集。&lt;/p&gt;
&lt;p&gt;有限集（finite set）：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt; &lt;strong&gt;&lt;em&gt;Def.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A set A is &lt;strong&gt;&lt;em&gt;finite&lt;/em&gt;&lt;/strong&gt; if&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;\exists f: A \rightarrow \{ 1, …, n \}, f \enspace is \enspace bijective.&lt;br&gt;$$&lt;/p&gt;
&lt;p&gt;這時我們會說 &lt;em&gt;set&lt;/em&gt; $A$ 的 cardinality 是 n。&lt;/p&gt;
    
    </summary>
    
      <category term="Topology" scheme="https://yuehhua.github.io/categories/Topology/"/>
    
    
  </entry>
  
  <entry>
    <title>Cartesian products</title>
    <link href="https://yuehhua.github.io/2018/07/22/05-cartesian-products/"/>
    <id>https://yuehhua.github.io/2018/07/22/05-cartesian-products/</id>
    <published>2018-07-21T16:26:26.000Z</published>
    <updated>2018-07-26T05:28:58.969Z</updated>
    
    <content type="html"><![CDATA[<p>前面我們定義了集合的笛卡爾積，這邊我們來定義一個更廣義的，$\mathcal{A}$ 是一個非空集合（collection of sets）：</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$$<br>A \enspace indexing \enspace function \enspace is \enspace a \enspace surjective \enspace function \enspace f: J \rightarrow \mathcal{A},<br>$$</p><p>$$<br>J \enspace is \enspace called \enspace index \enspace set.<br>$$</p><p>$$<br>The \enspace collection \enspace with \enspace the \enspace indexing \enspace function \enspace f \enspace is \enspace called \enspace indexed \enspace family \enspace of \enspace sets.<br>$$</p><a id="more"></a><p>所以如果有 $\alpha \in J$ ，我們會把 $f(\alpha)$ 寫成 $A_\alpha$。那麼 indexed family 本身可以寫成 $\{A_\alpha\}_{\alpha \in J}$。</p><p>這個概念有點類似在電腦科學中的 hash function/dictionary 或是指標的意味，有了一個函數可以對某個集合做 indexing。然而他必須是滿射的（surjective），而不是單射的（injective）。</p><p>應用這樣的概念來描述以往的概念就會有點不太一樣：</p><p>$f: J \rightarrow \mathcal{A} \enspace is \enspace an \enspace indexing \enspace function \enspace for \enspace \mathcal{A}$</p><p>$\bigcup_{\alpha \in J} A_\alpha = \{ x \mid at \enspace least \enspace one \enspace \alpha \in J, x \in A_\alpha \}$</p><p>$\bigcap_{\alpha \in J} A_\alpha = \{ x \mid for \enspace every \enspace \alpha \in J, x \in A_\alpha \}$</p><p>我們進一步定義<strong>m-元組（m-tuple）</strong>：</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$$<br>m \in \mathbb{N}, a \enspace set \enspace X, m-tuple \enspace of \enspace elements \enspace of \enspace X \enspace is<br>$$</p><p>$$<br>x: \{1, …, m\} \rightarrow X<br>$$</p><p>這邊 $x$ 是個 m-tuple，我們通常描述 $x$ 的第 i 個值會寫成 $x_i$ ，也就是第 i 分量，也就是<strong>座標（coordinate）</strong>。那表示 $x$ 本身則會寫成：</p><p>$$<br>(x_1, …, x_m)<br>$$</p><p>接下來，我們讓 $\{ A_1, …, A_m \}$ 是一個 <em>family of indexed sets</em>。 $X = A_1 \cup A_2 \cup … \cup A_m$。我們定義這個 <em>indexed family</em> 的 cartesian product 為：</p><p>$$<br>\prod_{i = 1}^{m} A_i \enspace or \enspace A_1 \times A_2 \times … \times A_m<br>$$</p><p>也就是所有 m-tuple $(x_1, …, x_m)$ 的集合。</p><p>我們有了 m-tuple 就可以來定義一個常用的概念，$\omega-tuple$。</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$$<br>A \enspace set \enspace X, \omega-tuple \enspace of \enspace elements \enspace of \enspace X \enspace is \enspace a \enspace function:<br>$$</p><p>$$<br>x: \mathbb{N} \rightarrow X<br>$$</p><p>這也是微積分當中的 <strong>數列（sequence）</strong>，或是 <strong>無限數列（infinite sequence）</strong>。我們也可以把 $\omega$-tuple $x$ 看成座標，則會表示成：</p><p>$$<br>(x_1, x_2, …)<br>$$</p><p>而 <em>cartesian product</em> 則是：</p><p>$$<br>\prod_{i \in \mathbb{N}} A_i \enspace or \enspace A_1 \times A_2 \times …<br>$$</p><p>這邊大家可能會疑惑，不同的 $A_i$ 之間有什麼不一樣嗎？其實他們都可能是一樣的，跟 $X$ 一樣，只是去表示位在不同的分量上。如果是 $X$ 的元素的 $m$-tuple 的話，就可以簡寫成 $X^m$。如果是 $X$ 的元素的 $\omega$-tuple 的話，就可以簡寫成 $X^\omega$。</p><h4 id="ex"><a href="#ex" class="headerlink" title="ex."></a><em>ex.</em></h4><p>如果 $\mathbb{R}$ 代表實數，那麼 $\mathbb{R}^m$ 就代表所有實數的 $m$-tuple 的集合，也就是歐幾里得空間（Euclidean m-space）。那 $\mathbb{R}^\omega$ 就是無限維度歐氏空間（infinite-dimensional Euclidean space）。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前面我們定義了集合的笛卡爾積，這邊我們來定義一個更廣義的，$\mathcal{A}$ 是一個非空集合（collection of sets）：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt; &lt;strong&gt;&lt;em&gt;Def.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;$$&lt;br&gt;A \enspace indexing \enspace function \enspace is \enspace a \enspace surjective \enspace function \enspace f: J \rightarrow \mathcal{A},&lt;br&gt;$$&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;J \enspace is \enspace called \enspace index \enspace set.&lt;br&gt;$$&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;The \enspace collection \enspace with \enspace the \enspace indexing \enspace function \enspace f \enspace is \enspace called \enspace indexed \enspace family \enspace of \enspace sets.&lt;br&gt;$$&lt;/p&gt;
    
    </summary>
    
      <category term="Topology" scheme="https://yuehhua.github.io/categories/Topology/"/>
    
    
  </entry>
  
  <entry>
    <title>The Integers and the Real Numbers</title>
    <link href="https://yuehhua.github.io/2018/07/22/04-integer-real-numbers/"/>
    <id>https://yuehhua.github.io/2018/07/22/04-integer-real-numbers/</id>
    <published>2018-07-21T16:25:40.000Z</published>
    <updated>2018-07-26T05:29:10.262Z</updated>
    
    <content type="html"><![CDATA[<p>以上我們談了一些 <em>邏輯的基礎</em>，接下來我們會談一些 <em>數學的基礎</em>，也就是整數與實數系統。其實我們已經用了很多，非正式地，接下來我們會正式地討論他們。</p><p>要 <strong><em>建構</em></strong> 實數系統的一個方法就是利用公理跟集合論來建構。</p><a id="more"></a><p>首先我們需要從集合論出發，定義在 <em>set</em> $A$ 上的 <strong>二元運算子（binary operator）</strong>：</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$$<br>f: A \times A \rightarrow A<br>$$</p><p>我們在描述一個二元運算子的時候並不會如同以往的函數一樣， $f(a, a’)$，而是會把運算子寫在中間， $afa’$。一般來說，我們會用符號來表示，而不是字母，像是加號 $+$、乘號 $\cdot$。</p><h4 id="假設"><a href="#假設" class="headerlink" title="假設"></a>假設</h4><p>我們假設存在一個 <em>set</em> $\mathbb{R}$，代表實數，有兩個運算子分別是加法運算子 $+$、乘法運算子 $\cdot$，以及一個次序關係 $\lt$ 定義於 $\mathbb{R}$ 上，會有以下特性：</p><p><em>代數特性（Algebraic Properties）</em></p><ol><li>$(x + y) + z = x + (y + z), \forall x, y, z \in \mathbb{R}$</li></ol><p>$(x \cdot y) \cdot z = x \cdot (y \cdot z), \forall x, y, z \in \mathbb{R}$</p><ol start="2"><li>$x + y = y + x, \forall x, y, z \in \mathbb{R}$</li></ol><p>$x \cdot y = y \cdot x, \forall x, y, z \in \mathbb{R}$</p><ol start="3"><li>$\exists! 0 \in \mathbb{R}, \forall x \in \mathbb{R}, s.t. \enspace x + 0 = x$</li></ol><p>$\exists! 1 \in \mathbb{R}, \forall x \in \mathbb{R}, s.t. \enspace x \cdot 1 = x$</p><ol start="4"><li>$for \enspace each \enspace x, \exists! y, s.t. \enspace x + y = 0$</li></ol><p>$for \enspace each \enspace x, \exists! y, s.t. \enspace x \cdot y = 1$</p><ol start="5"><li>$x \cdot (y + z) = (x \cdot y) + (x \cdot z), \forall x, y, z \in \mathbb{R}$</li></ol><p><em>混合代數與次序特性（A Mixed Algebraic and Order Property）</em></p><ol start="6"><li>$If \enspace x \gt y, then \enspace x + z \gt y + z$</li></ol><p>$If \enspace x \gt y, z \gt 0, then \enspace x \cdot z \gt y \cdot z$</p><p><em>次序特性（Order Properties）</em></p><ol start="7"><li>次序關係 $\lt$ 有最小上界性</li><li>$If \enspace x \lt y, then \enspace \exists z \enspace s.t. \enspace x \lt z, z \lt y$</li></ol><p>由 1~5 點我們可以導出一些代數性質，像是負數、減法運算、倒數跟商的概念。我們可以定義正數（$x \gt 0$）跟負數（$x \lt 0$）。在代數領域，擁有 1~5 點特性的代數結構，我們會稱為域（field）。如果有包含第六點就稱為有序域（ordered field）。在拓樸領域我們通常會討論的是第7、8點，他只牽涉到次序關係，同時擁有這兩點的集合稱為線性連續統（linear continuum）。</p><p>說到這邊我們還沒提到整數呢！我們就用前6點來定義整數（integer）。</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$A \subseteq \mathbb{R} \enspace is \enspace inductive:$</p><ol><li>$1 \in A$</li><li>$\forall x \in A \enspace s.t. \enspace x + 1 \in A$</li></ol><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$\mathcal{A} \enspace is \enspace a \enspace collection \enspace of \enspace all \enspace inductive \enspace subsets \enspace of \enspace \mathbb{R}$<br>$positive \enspace integers \enspace is \enspace a \enspace set \enspace \mathbb{N} = \bigcap_{A \in \mathcal{A}} A$</p><p>這樣的定義是很巧妙的，他其實只有明確的定義了1是在這個集合裡，後面都以 $x+ 1$ 的形式去推演，這稱為可歸納。而正整數是眾多可歸納集合的交集，可見正整數是最小的子集。</p><p>正整數有些特性：</p><ol><li>正整數是可歸納的（inductive）</li><li>（Principle of inductive）如果 <em>set</em> $A$ 是可歸納的，而且含正整數的集合，那麼 $A = \mathbb{N}$</li></ol><p>與實數不同的是，他不會有第八點特性，也就是，$for \enspace each \enspace n \in \mathbb{N}, \nexists a \in \mathbb{N} \enspace s.t. \enspace n \lt a \lt n + 1$。</p><hr><p>如果有個正整數 $n$，我們用 $S_{n}$ 來代表所有小於 $n$ 的正整數的集合，我們稱他為 <em>section</em>：</p><p>$$<br>S_{n + 1} = \{1, \dots , n\}<br>$$</p><p>接下來我們會描述 <del>證明</del> 兩個可能不是很熟悉但很有用的特性，你可以看成是另一個版本的數學歸納法：</p><blockquote><p> <strong><em>Theorem: Well-ordering property</em></strong></p></blockquote><p>$$<br>S \subseteq \mathbb{N}, S \neq \emptyset, S \enspace has \enspace smallest \enspace element.<br>$$</p><p>他描述了 $\mathbb{N}$ 的非空子集，一定有最小元素。</p><blockquote><p> <strong><em>Theorem: Strong induction principle</em></strong></p></blockquote><p>$$<br>A \enspace is \enspace a \enspace set \enspace of \enspace positive \enspace integers,<br>$$</p><p>$$<br>for \enspace each \enspace n, S_n \subseteq A \enspace s.t. \enspace n \in A, then \enspace A = \mathbb{N}<br>$$</p><p>這邊描述了，對每個 $n$ 來說，由 $S_n \subseteq A$ 可以推出 $n \in A$ 的話，那麼 $A$ 就是 $\mathbb{N}$。</p><p>以上我們用了有序域中的第 1~6 點公理，那第 7 點呢？</p><p>你用會用到第 7 點（最小上界公理）來證明，正整數集合 $\mathbb{N}$ 在實數的集合 $\mathbb{R}$ 中是沒有上界的。</p><blockquote><p><strong><em>Theorom: Archimedean ordering property</em></strong></p></blockquote><p>$$<br>the \enspace  set \enspace  \mathbb{N} \enspace  has \enspace  no \enspace  upper \enspace  bound \enspace  in \enspace  \mathbb{R}.<br>$$</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;以上我們談了一些 &lt;em&gt;邏輯的基礎&lt;/em&gt;，接下來我們會談一些 &lt;em&gt;數學的基礎&lt;/em&gt;，也就是整數與實數系統。其實我們已經用了很多，非正式地，接下來我們會正式地討論他們。&lt;/p&gt;
&lt;p&gt;要 &lt;strong&gt;&lt;em&gt;建構&lt;/em&gt;&lt;/strong&gt; 實數系統的一個方法就是利用公理跟集合論來建構。&lt;/p&gt;
    
    </summary>
    
      <category term="Topology" scheme="https://yuehhua.github.io/categories/Topology/"/>
    
    
  </entry>
  
  <entry>
    <title>Relations</title>
    <link href="https://yuehhua.github.io/2018/07/22/03-relations/"/>
    <id>https://yuehhua.github.io/2018/07/22/03-relations/</id>
    <published>2018-07-21T16:24:38.000Z</published>
    <updated>2018-07-26T05:29:20.728Z</updated>
    
    <content type="html"><![CDATA[<p>我們有比函數還要更有彈性、更一般化的概念，稱為 <strong>關係（relations）</strong> 。</p><p>我們會定義數學上的關係，並且談到在數學上大量使用的兩個關係：等價關係及次序關係。次序關係將會貫穿整個拓樸學領域。</p><p><strong>關係（relations）</strong> 的定義如下：</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$$<br>A \enspace relation \enspace on \enspace set \enspace A \enspace is<br>$$</p><p>$$<br>a \enspace subset \enspace C \subseteq A \times A<br>$$</p><a id="more"></a><p>這時候我們會把 <em>relation</em> $C$ 表示成 $xCy$ ，來代表 $(x, y) \in C$。</p><p>這時我們會理解成，$x$ 跟 $y$ 有 $C$ 的關係。</p><p>一個函數 $f: A \rightarrow A$ 是 $A \times A$ 的子集，所以函數也是一種關係。</p><p>任何是 $A \times A$ 的子集，都可以被視為一種關係。</p><h4 id="ex"><a href="#ex" class="headerlink" title="ex."></a><em>ex.</em></h4><p>$P$ 代表世界上全人類的集合，我們定義 $D \subseteq P \times P$ 為一種關係：</p><p>$$<br>D = \{ (x, y) \mid x \enspace is \enspace a \enspace descendant \enspace of \enspace y \}<br>$$</p><p>$D$ 代表的是子孫關係，$xDy$ 代表 $x$ 是 $y$ 的子孫。</p><p>我們也可以定義血緣關係 $B$：</p><p>$$<br>B= \{ (x, y) \mid x \enspace has \enspace an \enspace ancestor \enspace who \enspace is \enspace also \enspace an \enspace ancestor \enspace of \enspace y \}<br>$$</p><p>也就是，$x$ 跟 $y$ 有共同的祖先的話，那代表 $x$ 跟 $y$ 有血緣關係。如此一來，血緣關係就會是對稱的，子孫關係則不是。</p><h2 id="Equivalence-relations"><a href="#Equivalence-relations" class="headerlink" title="Equivalence relations"></a>Equivalence relations</h2><p>在 <em>set</em> $A$ 上的等價關係，是在 <em>set</em> $A$ 上的一種關係 $C$，並且滿足以下條件：</p><ol><li>Reflexivity（自身性）： $\forall x \in A, xCx$</li><li>Symmetry（對稱性）： If $xCy$, then $yCx$</li><li>Transitivity（遞移性）： If $xCy$ and $yCz$, then $xCz$</li></ol><p>關係並沒有強制規定說要用大寫字母表示，所以我們後面改成用大家比較常用的 $\sim$ （tilde）。</p><ol><li>$\forall x \in A, x \sim x$</li><li>If $x \sim y$, then $y \sim x$</li><li>If $x \sim y$ and $y \sim z$, then $x \sim z$</li></ol><h4 id="ex-1"><a href="#ex-1" class="headerlink" title="ex."></a><em>ex.</em></h4><p>我們可以檢驗看看 $\leq$ 在正整數（$\mathbb{N}$）上是不是一種等價關係？</p><ol><li>Reflexivity（自身性）： $\forall x \in \mathbb{N}, x \leq x$ <strong>成立</strong><ul><li>$1 \leq 1, 2 \leq 2, 3 \leq 3, …$</li></ul></li><li>Symmetry（對稱性）： If $x \leq y$, then $y \leq x$ <strong>不成立</strong><ul><li>$1 \leq 2, but \enspace not \enspace 2 \leq 1$</li></ul></li><li>Transitivity（遞移性）： If $x \leq y$ and $y \leq z$, then $x \leq z$ <strong>成立</strong><ul><li>$1 \leq 2, 2 \leq 4, then \enspace 1 \leq 4$</li></ul></li></ol><p>故 $\leq$ 不是等價關係。</p><h4 id="ex-2"><a href="#ex-2" class="headerlink" title="ex."></a><em>ex.</em></h4><p>假設一種等價關係是 $x \sim y$ ，定義為 $x \enspace (mod \enspace 3) = y \enspace (mod \enspace 3)$ ，那麼在 $\mathbb{N}$ 上，我們有 $5 \enspace (mod \enspace 3) = 2 = 8 \enspace (mod \enspace 3)$ 。那這有滿足等價關係嗎？</p><ol><li>Reflexivity（自身性）： $\forall x \in \mathbb{N}, x \sim x$ <strong>成立</strong><ul><li>$1 \enspace (mod \enspace 3) = 1 \enspace (mod \enspace 3), …$</li></ul></li><li>Symmetry（對稱性）： If $x \sim y$, then $y \sim x$ <strong>成立</strong><ul><li>$1 \enspace (mod \enspace 3) = 4 \enspace (mod \enspace 3)$</li><li>$4 \enspace (mod \enspace 3) = 1 \enspace (mod \enspace 3)$</li></ul></li><li>Transitivity（遞移性）： If $x \sim y$ and $y \sim z$, then $x \sim z$ <strong>成立</strong><ul><li>$1 \enspace (mod \enspace 3) = 4 \enspace (mod \enspace 3), 4 \enspace (mod \enspace 3) = 7 \enspace (mod \enspace 3),$</li><li>$then \enspace 1 \enspace (mod \enspace 3) = 7 \enspace (mod \enspace 3)$</li></ul></li></ol><p>故 $\leq$ 是等價關係。（以上非嚴謹證明）</p><p>所以可以把 $5 \sim 8$ 這兩者視為等價。</p><p>如果存在一種等價關係，那麼 <em>set</em> $A$ 裡的元素可以歸類成不同的 <strong>等價類（equivalent class）</strong>，假設 $x \in A, E \subseteq A$ ，我們有：</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$$<br>E = \{ y \mid y \sim x \}<br>$$</p><h4 id="ex-3"><a href="#ex-3" class="headerlink" title="ex."></a><em>ex.</em></h4><p>延續上面一個例子，$x \sim y$ 是等價關係，那麼我們就可以把 $\mathbb{N}$ 拆成不同的等價類：</p><p>$$<br>1 \sim 4, 4 \sim 7, 7 \sim 10, …<br>$$</p><p>$$<br>E_1 = \{1, 4, 7, 10, …\}<br>$$</p><p>$$<br>2 \sim 5, 5 \sim 8, 8 \sim 11, …<br>$$</p><p>$$<br>E_2 = \{2, 5, 8, 11, …\}<br>$$</p><p>$$<br>3 \sim 6, 6 \sim 9, 9 \sim 12, …<br>$$</p><p>$$<br>E_3 = \{3, 6, 9, 12, …\}<br>$$</p><p>等價類有以下的特性：</p><blockquote><p> <strong><em>Lemma</em></strong></p></blockquote><p>$$<br>Two \enspace equivalent \enspace classes \enspace E \enspace and \enspace E’ \enspace are \enspace either \enspace disjoint \enspace or \enspace equal.<br>$$</p><p>白話文就是兩個等價類不是一樣就是互斥的。</p><p>有這樣的等價類，我們可以用 $\mathscr{E}$ 來表示所有等價類的集合（collection）。藉由以上的 Lemma，我們知道每個等價類都是互斥的。這樣我們可以把他看成是對 <em>set</em> $A$ 的<strong>分割（partition）</strong>。</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$$<br>A \enspace partition \enspace of \enspace a \enspace set \enspace A \enspace is \enspace a \enspace collection \enspace of \enspace disjoint \enspace nonempty \enspace subsets \enspace of \enspace A<br>$$</p><p>$$<br>whose \enspace union \enspace is \enspace all \enspace of \enspace A.<br>$$</p><p>研究 <em>set</em> $A$ 上的等價關係等同於是研究 <em>set</em> $A$ 的分割。</p><h2 id="Order-relations"><a href="#Order-relations" class="headerlink" title="Order relations"></a>Order relations</h2><p>在 <em>set</em> $A$ 上的 <strong>次序關係（order relations, simple order or linear order）</strong>，是在 <em>set</em> $A$ 上的一種關係 $\lt$，並且滿足以下條件：</p><ol><li>Comparability（可比性）： $\forall x, y \in A, x \neq y, either \enspace x \lt y \enspace or \enspace y \lt x$</li><li>Nonreflexivity（非自身性）： $\nexists x \in A, x \lt x$</li><li>Transitivity（遞移性）： If $x \lt y$ and $y \lt z$, then $x \lt z$</li></ol><hr><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$$<br>\lt \enspace is \enspace an \enspace order \enspace relation \enspace on \enspace set \enspace X, a \lt b<br>$$</p><p>$$<br>(a, b) = \{ x \mid a \lt x \lt b \} \enspace is \enspace an \enspace open \enspace interval \enspace on \enspace X<br>$$</p><p>我們可以像這樣去定義 <strong>開區間（open interval）</strong>。如果 $(a, b) = \emptyset$，那稱 $a$ 是 $b$ 的 <strong>緊鄰前元（immediate predecessor）</strong>，而 $b$ 是 $a$ 的 <strong>緊鄰後元（immediate successor）</strong>。</p><hr><p>假定有 $A$ 跟 $B$ 兩個集合，有兩個相對應的次序關係 $\lt_A$ 跟 $\lt_B$。我們說這兩個集合有相同的 <strong>次序類型（order type）</strong>：</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$$<br>\exists f: A \rightarrow B, f \enspace is \enspace bijective<br>$$</p><p>$$<br>s.t. \enspace a_1 \lt_A a_2, then \enspace f(a_1) \lt_B f(a_2)<br>$$</p><p>這樣的雙射函數有<strong>保留</strong>次序關係。</p><h4 id="ex-4"><a href="#ex-4" class="headerlink" title="ex."></a><em>ex.</em></h4><p>在實數區間 $(1, -1)$ 有跟 $\mathbb{R}$ 相同的次序類型。</p><p>考慮函數 $f: (1, -1) \rightarrow \mathbb{R}$：</p><p>$$<br>f(x) = \frac{x}{1 - x^2}<br>$$</p><p>他是一個嚴格遞增函數（保留次序關係）且為雙射。</p><hr><p>接下來我們談談 <strong>字典序關係（dictionary order relation）</strong>，他是定義在 $A \times B$ 上的次序關係，假定 $A$ 跟 $B$ 集合上有次序關係 $\lt_A$ 跟 $\lt_B$。</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$$<br>\lt \enspace on \enspace A \times B \enspace is \enspace a_1 \times b_1 \lt a_2 \times b_2<br>$$</p><p>$$<br>if \enspace a_1 \lt_A a_2, or \enspace a_1 = a_2 \enspace and \enspace b_1 \lt_B b_2<br>$$</p><h4 id="ex-5"><a href="#ex-5" class="headerlink" title="ex."></a><em>ex.</em></h4><p>所謂的字典序就是先比較第一個字元，如果一樣再比較第二的字元的次序，如此繼續下去。</p><p>$$<br>aaa &lt; aab &lt; abb<br>$$</p><p>如此一來，就可以為 $A \times B \times \dots$ 這樣子的集合定義次序了。</p><hr><p>在實數中，你或許以前看過最小上界的特性。你可以為任意的有序集合定義這樣的特性。</p><p>假設 <em>set</em> $A$ 有次序關係 $\lt$，$A_0 \subseteq A$，</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$$<br>b \in A_0, \forall x \in A_0, x \le b<br>$$</p><p>$$<br>b \enspace is \enspace the \enspace largest \enspace element \enspace of \enspace A_0<br>$$</p><p>如果相反的話，</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$$<br>a \in A_0, \forall x \in A_0, x \ge a<br>$$</p><p>$$<br>a \enspace is \enspace the \enspace smallest \enspace element \enspace of \enspace A_0<br>$$</p><p>我們很簡單可以知道，一個集合會有最多一個最大的元素，以及最多一個最小的元素。</p><p>那如果我們要說，$A_0$ 有<strong>上界（bounded above）</strong>：</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$$<br>b \in A, \forall x \in A_0, x \le b<br>$$</p><p>$$<br>b \enspace is \enspace an \enspace upper \enspace bound \enspace for \enspace A_0<br>$$</p><p>而上界的元素中，最小的稱為<strong>最小上界（least upper bound）</strong>，或是 <strong>supremum</strong>，記為 $sup \enspace A_0$：</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$$<br>X = \{ x \mid \forall x \enspace is \enspace upper \enspace bound \enspace for \enspace A_0 \}<br>$$</p><p>$$<br>The \enspace smallest \enspace element \enspace of \enspace X \enspace is \enspace least \enspace upper \enspace bound<br>$$</p><p>他有可能屬於 $A_0$，如果 $sup \enspace A_0 \in A_0$，他同時也是 $A_0$ 最大的元素。</p><p>相反，$A_0$ 有<strong>下界（bounded below）</strong>：</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$$<br>a \in A, \forall x \in A_0, x \ge a<br>$$</p><p>$$<br>a \enspace is \enspace an \enspace lower \enspace bound \enspace for \enspace A_0<br>$$</p><p>而下界的元素中，最大的稱為<strong>最大下界（greatest lower bound）</strong>，或是 <strong>infimum</strong>，記為 $inf \enspace A_0$：</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$$<br>Y = \{ y \mid \forall y \enspace is \enspace lower \enspace bound \enspace for \enspace A_0 \}<br>$$</p><p>$$<br>The \enspace greatest \enspace element \enspace of \enspace Y \enspace is \enspace greatest \enspace lower \enspace bound<br>$$</p><p>他有可能屬於 $A_0$，如果 $inf \enspace A_0 \in A_0$，他同時也是 $A_0$ 最小的元素。</p><p>這些跟所謂的 <strong>最大值（maximum）</strong> 或是 <strong>最小值（minimum）</strong> 不太一樣：</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$$<br>b \in A_0, \forall x \in A_0, x \le b<br>$$</p><p>$$<br>b \enspace is \enspace the \enspace maximum \enspace of \enspace A_0<br>$$</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$$<br>a \in A_0, \forall x \in A_0, x \ge a<br>$$</p><p>$$<br>a \enspace is \enspace the \enspace minimum \enspace of \enspace A_0<br>$$</p><p>主要差別會是值是否在 $A_0$ 裏面。</p><p>這時候就可以來定義 <strong>最小上界性（least upper bound property）</strong>：</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$$<br>\forall A_0 \subseteq A, A_0 \enspace has \enspace a \enspace least \enspace upper \enspace bound<br>$$</p><p>$$<br>A \enspace has \enspace least \enspace upper \enspace bound \enspace property.<br>$$</p><p>相反則是，<strong>最大下界性（greatest lower bound property）</strong>。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我們有比函數還要更有彈性、更一般化的概念，稱為 &lt;strong&gt;關係（relations）&lt;/strong&gt; 。&lt;/p&gt;
&lt;p&gt;我們會定義數學上的關係，並且談到在數學上大量使用的兩個關係：等價關係及次序關係。次序關係將會貫穿整個拓樸學領域。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;關係（relations）&lt;/strong&gt; 的定義如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt; &lt;strong&gt;&lt;em&gt;Def.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;$$&lt;br&gt;A \enspace relation \enspace on \enspace set \enspace A \enspace is&lt;br&gt;$$&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;a \enspace subset \enspace C \subseteq A \times A&lt;br&gt;$$&lt;/p&gt;
    
    </summary>
    
      <category term="Topology" scheme="https://yuehhua.github.io/categories/Topology/"/>
    
    
  </entry>
  
  <entry>
    <title>Functions</title>
    <link href="https://yuehhua.github.io/2018/07/22/02-functions/"/>
    <id>https://yuehhua.github.io/2018/07/22/02-functions/</id>
    <published>2018-07-21T16:21:18.000Z</published>
    <updated>2018-07-26T05:29:28.734Z</updated>
    
    <content type="html"><![CDATA[<p>Function 會是在數學上常常看到的概念，但他到底是什麼？Function 常常被視為兩個集合之間<strong>對映的規則</strong>。我們先來定義<strong>對映的規則（rule of assignment）</strong>：</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$$<br>two \enspace sets \enspace C, D, r \subseteq C \times D, \forall c \in C , d \in D,<br>$$</p><p>$$<br>\exists \enspace at \enspace most \enspace one \enspace (c, d) \in r<br>$$</p><a id="more"></a><p>所以如果當兩個對映關係（如下）有相同的第一分量 $c$，那他們其實是同一個對映關係，並且第二分量也會相同。</p><p>$$<br>[ (c, d) \in r, (c, d’) \in r ] \rightarrow [ d = d’ ]<br>$$</p><p>給定一個對映規則 $r$，<strong>定義域（domain）</strong> 也就是 $C$ 的子集合，他包含了所有 $r$ 中的第一分量。</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$$<br>domain \enspace r = \{c \mid \exists d \in D \enspace s.t. \enspace (c, d) \in r \}<br>$$</p><p>相對，<strong>值域（image）</strong>是 $D$ 的子集合，他包含了所有 $r$ 中的第二分量。</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$$<br>image \enspace r = \{d \mid \exists c \in C \enspace s.t. \enspace (c, d) \in r \}<br>$$</p><p>現在我們把所有需要的東西都定義好了，那<strong>函數（function）</strong> 的定義就會是一個對映規則，以及一個 <em>set</em> $B$ 包含了 $image \enspace r$，稱為函數的 <strong>對應域（codomain）</strong> ，而函數的 <em>domain</em> $A$ 也就是 $domain \enspace r$，函數的值域就是 $image \enspace r$ ，我們會以下列表示法表示：</p><p>$$<br>f: A \rightarrow B<br>$$</p><p>這表示他是一個從 $A$ map 到 $B$ 的函數。有時候我們會想像成在空間上的轉換，將 $A$ 上的點對映到 $B$ 上的點。我們會以 $f(a)$ 來代表 $f$ 在 $a$ 點的<strong>值（value）</strong>。</p><p>我們可以在函數上定義<strong>限制（restriction）</strong>：</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$$<br>A_0 \enspace is \enspace the \enspace restriction \enspace of \enspace f<br>$$</p><p>$$<br>f: A \rightarrow B, A_0 \subseteq A \enspace s.t. \enspace f = \{ (a, f(a)) \mid a \in A_0 \}<br>$$</p><p>我們可以藉由限制（restriction）來限制我們的函數形式。我們還有另外一個方法，<strong>合成函數（function composition）</strong>：</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$$<br>g \circ f \enspace is \enspace the \enspace composite \enspace of \enspace function \enspace f \enspace and \enspace g<br>$$</p><p>$$<br>f: A \rightarrow B, g: B \rightarrow C, g \circ f: A \rightarrow C, (g \circ f)(a) = g(f(a))<br>$$</p><p>$$<br>g \circ f = \{(a, c) \mid b \in B, f(a) = b, g(b) = c \}<br>$$</p><p><img src="https://upload.wikimedia.org/wikipedia/commons/3/38/Example_for_a_composition_of_two_functions.svg" alt="Function composition"></p><blockquote><p> <small>from Wikipedia</small></p></blockquote><p>接著我們來討論一些不同的函數。</p><p>如果一個函數 $f: A \rightarrow B$ 是<strong>單射的（injective）</strong>，或是<strong>一對一（one-to-one）</strong>，那也就是說在 $A$ 中，不同的點會對映到不同的 <strong>像（image）</strong> 的。</p><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/0/02/Injection.svg/240px-Injection.svg.png" alt="Injection"></p><blockquote><p> <small>from Wikipedia</small></p></blockquote><p>如果一個函數 $f: A \rightarrow B$ 是<strong>滿射的（surjective）</strong>，或是<strong>映成（onto）</strong>，那也就是說每個在 $B$ 中的元素都有被對映到。</p><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/6/6c/Surjection.svg/240px-Surjection.svg.png" alt="Surjection"></p><blockquote><p> <small>from Wikipedia</small></p></blockquote><p>如果一個函數 $f: A \rightarrow B$ 是<strong>雙射的（bijective）</strong>，那也就是說這個函數同時滿足 <strong>單射的（injective）</strong> 以及 <strong>滿射的（surjective）</strong>。</p><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/a/a5/Bijection.svg/240px-Bijection.svg.png" alt="Bijection"></p><blockquote><p> <small>from Wikipedia</small></p></blockquote><p>兩個 injective function 的 composite 是個 injective function。兩個 surjective function 的 composite 是個 surjective function。兩個 bijective function 的 composite 是個 bijective function。</p><p>那如果 <em>function</em> $f$ 是 bijective，那麼他的 <strong>反函數（inverse）</strong> 存在，也就是：<br>$$<br>f: A \rightarrow B, f \enspace is \enspace bijective, \exists<br> f^{-1}<br>$$</p><p>$$<br>s.t. \enspace f^{-1}(b) = a, a \in A, b \in B<br>$$</p><p>反函數有一個特性就是， $f$ 的反函數為 $f^{-1}$，而 $f^{-1}$ 本身也是雙射的，所以他的反函數也存在，他的反函數則是 $f$。</p><p>那如果要證明一個函數是 bijective 的話，那以下Lemma 會有幫助：</p><blockquote><p> <strong><em>Lemma</em></strong></p></blockquote><p>$$<br>f: A \rightarrow B, \exists g: B \rightarrow A, \exists h: B \rightarrow A<br>$$</p><p>$$<br>s.t. \enspace \forall a \in A, g(f(a)) = a, \forall b \in B, f(h(b)) = b,<br>$$</p><p>$$<br>then \enspace g = h = f^{-1} \enspace is \enspace bijective.<br>$$</p><p><img src="/images/bijective_function.svg" alt=""></p><p>接下來，我們來討論一下 <strong>像（image）</strong>：</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$$<br>f: A \rightarrow B, A_0 \subseteq A, the \enspace image \enspace of \enspace A_0 \enspace of \enspace f \enspace is<br>$$</p><p>$$<br>f(A_0) = \{ b \mid b = f(a) \enspace for \enspace at \enspace least \enspace one \enspace a \in A_0 \}<br>$$</p><p><img src="/images/image.svg" alt=""></p><p>另一方面，我們可以討論像的 <strong>原像（preimage）</strong>：</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$$<br>f: A \rightarrow B, B_0 \subseteq B, f^{-1}(B_0) = \{ a \mid f(a) \in B_0\}<br>$$</p><p>$$<br>f^{-1}(B_0) \enspace is \enspace the \enspace preimage \enspace of \enspace B_0 \enspace under \enspace f.<br>$$</p><p><img src="/images/preimage.svg" alt=""></p><p>如果 $f: A \rightarrow B$ 是 bijective， $B_0 \subseteq B$，我們對 $f^{-1}(B_0)$ 有兩種解釋，他可以是 preimage of $B_0$ under $f$ ，或者是 image of $B_0$ under $f^{-1}: B \rightarrow A$。</p><p>在使用 $f$ 及 $f^{-1}$ 上需要小心。如果是 $f^{-1}$ 應用在 $B$ 的子集合上，他有很好的行為，他保留了包含、聯集、交集、差集的特性。我們應該要常用他。如果是 $f$ 應用在 $A$ 的子集合上，他只保留了包含及聯集的特性。</p><p>另一個需要小心的，以下兩個並不是總是為真：</p><p>$$<br>f^{-1}(f(A_0)) = A_0<br>$$</p><p>$$<br>f(f^{-1}(B_0)) = B_0<br>$$</p><p>結論是這樣的，如果 $f: A \rightarrow B, A_0 \subseteq A, B_0 \subseteq B$，則以下成立：</p><p>$$<br>A_0 \subseteq f^{-1}(f(A_0))<br>$$</p><p>$$<br>f(f^{-1}(B_0)) \subseteq B_0<br>$$</p><p>第一條式子的等號成立的條件為 $f$ 是 injective，第二條式子的等號成立的條件為 $f$ 是 surjective。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Function 會是在數學上常常看到的概念，但他到底是什麼？Function 常常被視為兩個集合之間&lt;strong&gt;對映的規則&lt;/strong&gt;。我們先來定義&lt;strong&gt;對映的規則（rule of assignment）&lt;/strong&gt;：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt; &lt;strong&gt;&lt;em&gt;Def.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;$$&lt;br&gt;two \enspace sets \enspace C, D, r \subseteq C \times D, \forall c \in C , d \in D,&lt;br&gt;$$&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;\exists \enspace at \enspace most \enspace one \enspace (c, d) \in r&lt;br&gt;$$&lt;/p&gt;
    
    </summary>
    
      <category term="Topology" scheme="https://yuehhua.github.io/categories/Topology/"/>
    
    
  </entry>
  
  <entry>
    <title>Set theory (集合論)</title>
    <link href="https://yuehhua.github.io/2018/07/22/01-set-theory/"/>
    <id>https://yuehhua.github.io/2018/07/22/01-set-theory/</id>
    <published>2018-07-21T16:19:48.000Z</published>
    <updated>2018-07-26T05:29:38.360Z</updated>
    
    <content type="html"><![CDATA[<p>先以集合論開始切入，集合論是以後各門數學相關學科的根基，也就是很多數學的分支都會定義在集合論上。</p><p>在數學上，集合就是一群不重複的物件（object）或是元素（element）。像我們可以定義<strong>一個set A當中的elements有a、b、c</strong>，寫成：</p><p>$$<br>A = \{ a, b, c \}<br>$$</p><a id="more"></a><p>但有時候我們想表達一個set，可是卻無法將裡面的elements一一列出，像是我們定義一個只有偶數的set B，我們會寫成以下的方式：</p><p>$$<br>B = \{x \mid x \enspace is \enspace even \enspace integer.\}<br>$$</p><p>裡頭的$x$代表著一個變數，後面會描述這變數的特質，所以在這邊的描述是$x$是一個偶數，那如果我們收集這樣的變數成為一個集合，我們就有了所有偶數的集合了。</p><p>我們在描述<em>element</em>及<em>set</em>的關係的時候會使用<strong>屬於</strong>，<strong>一個element a屬於set A</strong>，則會表示成：</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$$<br>a \in A<br>$$</p><p>相對，<strong>不屬於</strong>則會寫成以下的形式：</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$$<br>d \notin A<br>$$</p><p><strong>等於</strong>的符號是會視為<em>邏輯上的相等（logical identity）</em>，如果我們說$a = b$，那麼$a$跟$b$就是兩個完全一樣的東西。如果是不一樣的東西，則寫成$a \neq b$。</p><p>同樣的，集合也可以同等起來，如果我們說$A = B$，就表示$A$跟$B$這兩個集合內的東西完全相同。如果有一個element不同，則$A \neq B$。</p><p>如果$A$有的elements，在$B$中也有，那我們會說<strong>A是B的子集合（subset）</strong>：</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$$<br>A \subseteq B<br>$$</p><p>從定義當中我們無法區分出$A$跟$B$是否相同。那前面講到的$A = B$也就等同於是$A \subseteq B$及$B \subseteq A$兩者都要成立。</p><p>那如果$A \subseteq B$且$A \neq B$，那我們稱<strong>A為B的嚴格子集（proper subset）</strong>：</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$$<br>A \subset B<br>$$</p><p>$\subseteq$及$\subset$關係則分別稱為<strong>包含（inclusion）</strong> 及 <strong>嚴格包含（proper inclusion）</strong>。</p><p>如果我們有兩個集合$A$跟$B$，如果有一個集合包含了所有$A$和$B$的元素，那我們稱它為$A$和$B$的<strong>聯集（union）</strong>：</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$$<br>A \cup B = \{x \mid x \in A \enspace or \enspace x \in B\}<br>$$</p><div style="text-align:center"><img src="https://upload.wikimedia.org/wikipedia/commons/3/30/Venn0111.svg" alt="Union"></div><blockquote><p> <small>from Wikipedia</small></p></blockquote><p>如果我們有兩個集合$A$跟$B$，如果有一個集合只包含$A$和$B$的共同元素，那我們稱它為$A$和$B$的<strong>交集（intersection）</strong>：</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$$<br>A \cap B = \{x \mid x \in A \enspace and \enspace x \in B\}<br>$$</p><div style="text-align:center"><img src="https://upload.wikimedia.org/wikipedia/commons/9/99/Venn0001.svg" alt="Intersection"></div><blockquote><p> <small>from Wikipedia</small></p></blockquote><p>如果一個集合裏面沒有任何元素，那我們定義這樣的集合為<strong>空集合（empty set）</strong>，$\emptyset$。</p><p>若是兩個集合沒有共同的元素，我們會說這兩個集合是<strong>互斥的（disjoint）</strong>：</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$$<br>A \cap B = \emptyset<br>$$</p><div style="text-align:center"><img src="https://upload.wikimedia.org/wikipedia/commons/d/df/Disjunkte_Mengen.svg" alt="Disjoint sets"></div><blockquote><p> <small>from Wikipedia</small></p></blockquote><p>由於空集合這個概念非常簡單，就是集合內沒有任何元素，我們可以把他跟之前介紹過的概念結合起來。像是，如果我們讓 $x$ 是某個元素，</p><p>$$<br>x \in \emptyset<br>$$</p><p>是不會成立的。對於任何一個set $A$，我們有</p><p>$$<br>A \cap \emptyset = \emptyset<br>$$</p><p>和</p><p>$$<br>A \cup \emptyset = A<br>$$<br>。</p><p>包含的關係就有點微妙，像是 $\emptyset \subseteq A$ ，我們會考慮很多的實例，要讓每一個實例都成立，這個式子才算是成立。不過討論這件事本身就蠻無趣的，他基本上是成立的。</p><p>在這邊我們可以再定義新的運算，那就是<strong>差集（difference）</strong>，他的定義如下：</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$$<br>A - B = \{x \mid x \in A \enspace and \enspace x \notin B\}<br>$$</p><div style="text-align:center"><img src="https://upload.wikimedia.org/wikipedia/commons/5/5a/Venn0010.svg" alt="Difference set"></div><blockquote><p> <small>from Wikipedia</small></p></blockquote><hr><h2 id="Rules"><a href="#Rules" class="headerlink" title="Rules"></a>Rules</h2><p>在集合論中，有些跟我們一般的算術運算很像的性質，像是以下的<strong>分配律（distributive law）</strong>：</p><p>$$<br>A \cap (B \cup C) = (A \cap B) \cup (A \cap C)<br>$$</p><p>$$<br>A \cup (B \cap C) = (A \cup B) \cap (A \cup C)<br>$$</p><p>以及<strong>狄莫根定律（DeMorgan ‘s laws）</strong>：</p><p>$$<br>A - (B \cap C) = (A - B) \cup (A - C)<br>$$</p><p>$$<br>A - (B \cup C) = (A - B) \cap (A - C)<br>$$</p><hr><p>我們在緊接著介紹一個有趣的概念，<strong>冪集（power set）</strong>，<strong>$A$的冪集（$\mathcal{P}(A)$）是指所有$A$的子集的所有排列組合所成的集合</strong>，像是假設$A = \{1, 2, 3\}$，那麼$\mathcal{P}(A) = \{ \emptyset, \{1\}, \{2\}, \{3\}, \{1, 2\}, \{1, 3\}, \{2, 3\}, \{1, 2, 3\} \}$。</p><p>往後，當我們在描述一個 <em>set</em>，他的 <em>element</em> 也是 <em>set</em> 的時候，我們會稱他為 <em>collection of sets</em>，並且會以書寫體$\mathcal{A}$、$\mathcal{B}$表示，以示區別。</p><p>我們已經定義了任兩個集合的交集跟聯集。那如果我們想要聯集或是交集任意多數量的集合，$\mathcal{A}$為一 <em>collection of sets</em>，我們可以用以下表示法：</p><p>$$<br>\bigcup_{A \in \mathcal{A}} A = \{ x \mid x \in A, for \enspace at \enspace least \enspace one \enspace A \in \mathcal{A} \}<br>$$</p><p>直白的說，就是這個聯集會將在$\mathcal{A}$中，至少出現過一次的$A$，將$A$中的元素$x$都蒐集起來。</p><p>$$<br>\bigcap_{A \in \mathcal{A}} A = \{ x \mid x \in A, for \enspace every \enspace A \in \mathcal{A} \}<br>$$</p><p>這個交集則是會將在$\mathcal{A}$中，每個$A$，將$A$中都出現的元素$x$蒐集起來。</p><p>這些定義都沒什麼大問題。不過當$\mathcal{A}$是個空的 <em>collection</em> 的時候就會顯的比較特別，根據字面定義，這個情況下沒有任何人可以符合這樣的定義，所以我們可以說：</p><p>$$<br>\bigcup_{A \in \mathcal{A}} A = \emptyset<br>$$</p><p>接下來我們來定義一個重要的東西，<strong>笛卡爾積（Cartesian product）</strong>，數學上常常會用這樣的概念來為其他概念下定義，例如空間上的座標位置。</p><blockquote><p> <strong><em>Def.</em></strong></p></blockquote><p>$$<br>A \times B = \{(a, b) \mid a \in A \enspace and \enspace b \in B\}<br>$$</p><p>像是當 $A = \{ a, b, c\}$， $B = \{1, 2\}$，那麼 $A \times B = \{(a, 1), (a, 2), (b, 1), (b, 2), (c, 1), (c, 2)\}$ 。</p><p>這在概念上非常直覺，可以把他想成是在 <em>set</em> $A$ 中的元素跟在 <em>set</em> $B$ 中的元素，拿出來一一做排列組合，所有的排列組合所成的集合就是 $A \times B$。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;先以集合論開始切入，集合論是以後各門數學相關學科的根基，也就是很多數學的分支都會定義在集合論上。&lt;/p&gt;
&lt;p&gt;在數學上，集合就是一群不重複的物件（object）或是元素（element）。像我們可以定義&lt;strong&gt;一個set A當中的elements有a、b、c&lt;/strong&gt;，寫成：&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;A = \{ a, b, c \}&lt;br&gt;$$&lt;/p&gt;
    
    </summary>
    
      <category term="Topology" scheme="https://yuehhua.github.io/categories/Topology/"/>
    
    
  </entry>
  
  <entry>
    <title>Reference commands</title>
    <link href="https://yuehhua.github.io/2018/07/21/04-reference/"/>
    <id>https://yuehhua.github.io/2018/07/21/04-reference/</id>
    <published>2018-07-21T14:59:51.000Z</published>
    <updated>2018-07-26T05:30:47.530Z</updated>
    
    <content type="html"><![CDATA[<pre><code>attach    Attach to a running containerbuild     Build an image from a Dockerfilecommit    Create a new image from a container&apos;s changescp        Copy files/folders from the containers filesystem to the host pathdiff      Inspect changes on a container&apos;s filesystemevents    Get real time events from the serverexport    Stream the contents of a container as a tar archivehistory   Show the history of an imageimages    List imagesimport    Create a new filesystem image from the contents of a tarballinfo      Display system-wide informationinspect   Return low-level information on a containerkill      Kill a running containerload      Load an image from a tar archivelogin     Register or Login to the docker registry serverlogs      Fetch the logs of a containerport      Lookup the public-facing port which is NAT-ed to PRIVATE_PORTpause     Pause all processes within a containerps        List containerspull      Pull an image or a repository from the docker registry serverpush      Push an image or a repository to the docker registry serverrestart   Restart a running containerrm        Remove one or more containersrmi       Remove one or more imagesrun       Run a command in a new containersave      Save an image to a tar archivesearch    Search for an image in the docker indexstart     Start a stopped containerstop      Stop a running containertag       Tag an image into a repositorytop       Lookup the running processes of a containerunpause   Unpause a paused containerversion   Show the docker version informationwait      Block until a container stops, then print its exit code</code></pre><h2 id="Docker-Commands-Diagram"><a href="#Docker-Commands-Diagram" class="headerlink" title="Docker Commands Diagram"></a><strong>Docker Commands Diagram</strong></h2><p><img src="https://raw.githubusercontent.com/philipz/docker_practice/master/_images/cmd_logic.png" alt="Docker Commands Diagram"></p><a id="more"></a>]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;attach    Attach to a running container
build     Build an image from a Dockerfile
commit    Create a new image from a container&amp;apos;s changes
cp        Copy files/folders from the containers filesystem to the host path
diff      Inspect changes on a container&amp;apos;s filesystem
events    Get real time events from the server
export    Stream the contents of a container as a tar archive
history   Show the history of an image
images    List images
import    Create a new filesystem image from the contents of a tarball
info      Display system-wide information
inspect   Return low-level information on a container
kill      Kill a running container
load      Load an image from a tar archive
login     Register or Login to the docker registry server
logs      Fetch the logs of a container
port      Lookup the public-facing port which is NAT-ed to PRIVATE_PORT
pause     Pause all processes within a container
ps        List containers
pull      Pull an image or a repository from the docker registry server
push      Push an image or a repository to the docker registry server
restart   Restart a running container
rm        Remove one or more containers
rmi       Remove one or more images
run       Run a command in a new container
save      Save an image to a tar archive
search    Search for an image in the docker index
start     Start a stopped container
stop      Stop a running container
tag       Tag an image into a repository
top       Lookup the running processes of a container
unpause   Unpause a paused container
version   Show the docker version information
wait      Block until a container stops, then print its exit code
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;Docker-Commands-Diagram&quot;&gt;&lt;a href=&quot;#Docker-Commands-Diagram&quot; class=&quot;headerlink&quot; title=&quot;Docker Commands Diagram&quot;&gt;&lt;/a&gt;&lt;strong&gt;Docker Commands Diagram&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/philipz/docker_practice/master/_images/cmd_logic.png&quot; alt=&quot;Docker Commands Diagram&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Docker" scheme="https://yuehhua.github.io/categories/Docker/"/>
    
    
  </entry>
  
  <entry>
    <title>Recommended docker apps</title>
    <link href="https://yuehhua.github.io/2018/07/21/03-recommend/"/>
    <id>https://yuehhua.github.io/2018/07/21/03-recommend/</id>
    <published>2018-07-21T14:58:45.000Z</published>
    <updated>2018-07-26T05:30:30.391Z</updated>
    
    <content type="html"><![CDATA[<a id="more"></a><pre><code>docker pull sequenceiq/hadoop-ubuntudocker pull nginx  # official reposdocker pull php  # official reposdocker pull dockerfile/javadocker pull dockerfile/pythondocker pull pypy  # official reposdocker pull rocker/rstudio:latest</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;pre&gt;&lt;code&gt;docker pull sequenceiq/hadoop-ubuntu
docker pull nginx  # official repos
docker pull php  # official repos
dock
      
    
    </summary>
    
      <category term="Docker" scheme="https://yuehhua.github.io/categories/Docker/"/>
    
    
  </entry>
  
</feed>
