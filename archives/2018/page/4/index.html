
<!DOCTYPE html>
<html lang="zh-tw,en,default">
    
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Dream Maker">
    <title>所有文章: 2018 - Dream Maker</title>
    <meta name="author" content="Yueh-Hua Tu">
    
        <meta name="keywords" content="machine learning,deep learning,topology,">
    
    
    
        <link rel="alternate" type="application/atom+xml" title="RSS" href="/atom.xml">
    
    <script type="application/ld+json">{}</script>
    <meta property="og:type" content="blog">
<meta property="og:title" content="Dream Maker">
<meta property="og:url" content="https://yuehhua.github.io/archives/2018/page/4/index.html">
<meta property="og:site_name" content="Dream Maker">
<meta property="og:locale" content="zh_TW">
<meta property="article:author" content="Yueh-Hua Tu">
<meta property="article:tag" content="machine learning">
<meta property="article:tag" content="deep learning">
<meta property="article:tag" content="topology">
<meta name="twitter:card" content="summary">
    
    
        
    
    
    
    
    
    <!--STYLES-->
    
<link rel="stylesheet" href="/assets/css/style-3frockyt2j28isvdztjchy5nhkz8tjki9ermufc1ckptmvjdftux94m2ahub.min.css">

    <!--STYLES END-->
    
    <script type="text/javascript">
        (function (i, s, o, g, r, a, m) {
        i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
            (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date(); a = s.createElement(o),
            m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
        })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-119690895-1', 'auto');
        ga('send', 'pageview');
    </script>
    
    
</head>

    <body>
        <div id="blog">
            <!-- Define author's picture -->


    

<header id="header" data-behavior="2">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a class="header-title-link" href="/%20">Dream Maker</a>
    </div>
    
        
            <a  class="header-right-picture "
                href="#about">
        
        
        </a>
    
</header>

            <!-- Define author's picture -->


<nav id="sidebar" data-behavior="2">
    <div class="sidebar-container">
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/%20"
                            
                            title="首頁"
                        >
                    
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">首頁</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/all-categories"
                            
                            title="分類"
                        >
                    
                        <i class="sidebar-button-icon fa fa-bookmark" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">分類</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/all-tags"
                            
                            title="標籤"
                        >
                    
                        <i class="sidebar-button-icon fa fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">標籤</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/all-archives"
                            
                            title="所有文章"
                        >
                    
                        <i class="sidebar-button-icon fa fa-archive" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">所有文章</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link open-algolia-search"
                             href="#search"
                            
                            title="搜尋"
                        >
                    
                        <i class="sidebar-button-icon fa fa-search" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">搜尋</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="#about"
                            
                            title="關於"
                        >
                    
                        <i class="sidebar-button-icon fa fa-question" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">關於</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link " href="https://github.com/yuehhua/" target="_blank" rel="noopener" title="GitHub">
                    
                        <i class="sidebar-button-icon fab fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">GitHub</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link " href="https://www.facebook.com/a504082002" target="_blank" rel="noopener" title="Facebook">
                    
                        <i class="sidebar-button-icon fab fa-facebook" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Facebook</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link " href="https://www.linkedin.com/in/%E5%B2%B3%E8%8F%AF-%E6%9D%9C-6a3995a0/" target="_blank" rel="noopener" title="LinkedIn">
                    
                        <i class="sidebar-button-icon fab fa-linkedin" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">LinkedIn</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link " href="mailto:a504082002@gmail.com" target="_blank" rel="noopener" title="Email">
                    
                        <i class="sidebar-button-icon fab fa-envelope" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Email</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/atom.xml"
                            
                            title="Atom"
                        >
                    
                        <i class="sidebar-button-icon fa fa-rss" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Atom</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="2"
                 class="
                        hasCoverMetaIn
                        ">
                
    <section class="postShorten-group main-content-wrap">
    
    
    <article class="postShorten postShorten--thumbnailimg-right">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a class="link-unstyled" href="/2018/10/03/03-from-linear-regression-to-perceptron/">
                            03 從線性迴歸到感知器
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2018-10-03T23:13:30+08:00">
	
		    10月 03, 2018
    	
    </time>
    
        <span>分類 </span>
        
    <a class="category-link" href="/categories/Machine-Learning/">Machine Learning</a>, <a class="category-link" href="/categories/Machine-Learning/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%A8%A1%E5%9E%8B%E5%9C%96%E6%9B%B8%E9%A4%A8%EF%BC%9A%E5%BE%9E%E5%82%B3%E7%B5%B1%E6%A8%A1%E5%9E%8B%E5%88%B0%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92/">機器學習模型圖書館：從傳統模型到深度學習</a>


    
</div>

            </div>
            
                <div class="postShorten-excerpt">
                    <p>感知器（perceptron）是在 1957 年就被發明出來的的模型，對電腦的發展或是人工智慧來說都是非常早期的。</p>
<p>感知器模型他是一個二元分類的分類器，他解的是分類問題。相對我們前面的線性迴歸解的是迴歸問題，兩者在問題的定義上有根本性的不一樣，那他們兩個有什麼關聯性呢？</p>
                    
                        <a href="/2018/10/03/03-from-linear-regression-to-perceptron/" class="postShorten-excerpt_link link">
                            繼續閱讀
                        </a>
                        
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-right">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a class="link-unstyled" href="/2018/10/03/02-linear-regression/">
                            02 線性迴歸 -- 迴歸問題中的線性模型
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2018-10-03T15:31:54+08:00">
	
		    10月 03, 2018
    	
    </time>
    
        <span>分類 </span>
        
    <a class="category-link" href="/categories/Machine-Learning/">Machine Learning</a>, <a class="category-link" href="/categories/Machine-Learning/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%A8%A1%E5%9E%8B%E5%9C%96%E6%9B%B8%E9%A4%A8%EF%BC%9A%E5%BE%9E%E5%82%B3%E7%B5%B1%E6%A8%A1%E5%9E%8B%E5%88%B0%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92/">機器學習模型圖書館：從傳統模型到深度學習</a>


    
</div>

            </div>
            
                <div class="postShorten-excerpt">
                    <p>這個模型大概已經被人講過很多次，講到都快要爛掉了XD</p>
<p>其實我自己在兩年前的鐵人賽中也有講過同一個模型，所以我就不用講太多基礎的部份：</p>
                    
                        <a href="/2018/10/03/02-linear-regression/" class="postShorten-excerpt_link link">
                            繼續閱讀
                        </a>
                        
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-right">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a class="link-unstyled" href="/2018/10/03/01-introduction/">
                            01 簡介及目錄
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2018-10-03T14:03:40+08:00">
	
		    10月 03, 2018
    	
    </time>
    
        <span>分類 </span>
        
    <a class="category-link" href="/categories/Machine-Learning/">Machine Learning</a>, <a class="category-link" href="/categories/Machine-Learning/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E6%A8%A1%E5%9E%8B%E5%9C%96%E6%9B%B8%E9%A4%A8%EF%BC%9A%E5%BE%9E%E5%82%B3%E7%B5%B1%E6%A8%A1%E5%9E%8B%E5%88%B0%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92/">機器學習模型圖書館：從傳統模型到深度學習</a>


    
</div>

            </div>
            
                <div class="postShorten-excerpt">
                    <p>上個禮拜才剛從美國回來，周末又講了兩天整天的機器學習課程，完全忘記鐵人賽開賽的事情…….</p>
<p>這一系列文章將會專注在機器學習的模型上，會從傳統的機器學習模型一路介紹到深度學習的模型。<br>比起介紹個別的模型，我會更專注在模型的演化上，去比較不同模型的差異之處，或是不同模型之間的改進之處。<br>一系列的脈絡會讓讀者更了解數學模型的運作方式，以及數學運算上的意義。</p>
                    
                        <a href="/2018/10/03/01-introduction/" class="postShorten-excerpt_link link">
                            繼續閱讀
                        </a>
                        
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-right">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a class="link-unstyled" href="/2018/09/12/energy-model-bayesian/">
                            Energy-based model 以及 Bayesian model 的關聯
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2018-09-12T14:22:48+08:00">
	
		    9月 12, 2018
    	
    </time>
    
        <span>分類 </span>
        
    <a class="category-link" href="/categories/Machine-Learning/">Machine Learning</a>


    
</div>

            </div>
            
                <div class="postShorten-excerpt">
                    <p>在機器學習領域，我們常常會聽到 Energy-based model。</p>
<p>基本上，他是借了物理的能量觀點來的，在數學上，與物理的公式如出一徹。</p>
<p>我們先來看看他是長成什麼樣子。</p>
                    
                        <a href="/2018/09/12/energy-model-bayesian/" class="postShorten-excerpt_link link">
                            繼續閱讀
                        </a>
                        
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a class="link-unstyled" href="/2018/08/24/mastery/">
                            《喚醒你心中的大師：偷學48位大師精進的藝術，做個厲害的人》
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2018-08-24T22:21:21+08:00">
	
		    8月 24, 2018
    	
    </time>
    
        <span>分類 </span>
        
    <a class="category-link" href="/categories/Book/">Book</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <iframe width="560" height="315" src="https://www.youtube.com/embed/xM0HUZ4E5I8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>

<p>摘要筆記：</p>
<ol>
<li>前置階段<ul>
<li>發掘內心的召喚</li>
</ul>
</li>
<li>學徒訓練階段（5~10 年）<ul>
<li>實踐<ul>
<li>深入觀察</li>
<li>技能習得（一萬小時）</li>
<li>實驗</li>
</ul>
</li>
<li>策略<ul>
<li>選擇成長潛力最大，而不是賺最多錢的</li>
<li>持續拓展視野</li>
<li>讓認知框架保持開放</li>
</ul>
</li>
</ul>
</li>
<li>積極創造階段<ul>
<li>尋找具有創造性的任務</li>
<li>實踐創造力的策略<ul>
<li>培養 negative capability</li>
<li>不要一直處於專注模式</li>
<li>注意細節及異常現象</li>
</ul>
</li>
<li>設定工作期限</li>
</ul>
</li>
<li>大師境界階段<ul>
<li>掌握部分跟整體的關係</li>
<li>連結萬物的追求</li>
<li>成為你自己</li>
</ul>
</li>
</ol>

                    
                        

                    
                    
                        <p>
                            <a href="/2018/08/24/mastery/#post-footer" class="postShorten-excerpt_link link">
                                留言與分享
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-right">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a class="link-unstyled" href="/2018/08/08/11-usual-topology-and-subbasis/">
                            Usual topology and subbasis
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2018-08-08T13:38:50+08:00">
	
		    8月 08, 2018
    	
    </time>
    
        <span>分類 </span>
        
    <a class="category-link" href="/categories/Topology/">Topology</a>


    
</div>

            </div>
            
                <div class="postShorten-excerpt">
                    <p>我們今天就來談談一些常見的拓樸。</p>
                    
                        <a href="/2018/08/08/11-usual-topology-and-subbasis/" class="postShorten-excerpt_link link">
                            繼續閱讀
                        </a>
                        
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-right">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a class="link-unstyled" href="/2018/08/03/the-nutshell-of-ai/">
                            AI 的核心
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2018-08-03T00:17:30+08:00">
	
		    8月 03, 2018
    	
    </time>
    
        <span>分類 </span>
        
    <a class="category-link" href="/categories/Deep-Learning/">Deep Learning</a>


    
</div>

            </div>
            
                <div class="postShorten-excerpt">
                    <!-- toc -->
<h2 id="AI-是什麼？"><a href="#AI-是什麼？" class="headerlink" title="AI 是什麼？"></a>AI 是什麼？</h2><p>很多人探討 AI 會追隨前人的探討，去探討什麼是智慧？或是什麼樣的是強人工智慧？</p>
<p>當然我也做過一樣的事情，只是今天我想從比較 <strong>技術層面</strong>、比較 <strong>務實</strong> 的角度切入這一大類技術。</p>
<p>從比較技術層面跟務實的角度切入，就表示我想討論的是現今人工智慧的實作層面，也就是 <strong>AI 是怎麼被做出來的？（how）</strong>，並非討論 <strong>AI 是什麼？(what)</strong></p>
<p><strong>AI 是什麼？</strong> 這議題會牽涉到什麼是智慧？而智慧這種事情連人類自身都說不清楚，有的人從哲學層面討論智慧，動物有動物的智慧，人類有人類的智慧，憑什麼說人類的『智慧』才稱為智慧？有的人從生物角度切入， 從大腦的結構與神經元的連結，到神經元的觸發，這一系列的科學探索，或許我們未來可以回答智慧是什麼？但目前仍舊是一個大謎團。</p>
<p>我今天要談的都不是這些，我要談的是深度學習的核心，不！是機器學習的核心…… 嗯……等等，所以那是什麼？</p>
                    
                        <a href="/2018/08/03/the-nutshell-of-ai/" class="postShorten-excerpt_link link">
                            繼續閱讀
                        </a>
                        
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-right">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a class="link-unstyled" href="/2018/07/27/activation-function/">
                            Activation function 到底怎麼影響模型？
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2018-07-27T11:02:54+08:00">
	
		    7月 27, 2018
    	
    </time>
    
        <span>分類 </span>
        
    <a class="category-link" href="/categories/Deep-Learning/">Deep Learning</a>


    
</div>

            </div>
            
                <div class="postShorten-excerpt">
                    <p>今天我們來談談 activation function 吧！</p>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在神經網路模型（neural network）及深度學習（deep learning）中，activation function 一直扮演重要的角色。</p>
<p>網路模型中的層的概念基本上是由以下的式子構成：</p>
<script type="math/tex; mode=display">
\sigma(Wx + b)</script><p>其中 $Wx$ 的矩陣相乘是大家在線性代數中常見的線性運算（linear operation），$Wx + b$ 嚴格來說是稱為仿射運算（affine operation）。相對應線性空間，仿射運算會構成仿射空間，不過兩者只差一個位移 $b$ 而已，但是大家都把它叫做線性（其實是錯誤的阿阿阿阿阿阿阿阿）。最後就是最外層的 $\sigma$ 了。這就是我們今天要談的 activation function。大家應該知道 activation function 會提供神經網路模型非線性的特性，而在沒有非線性特性前的神經網路長什麼樣子呢？</p>
<h2 id="仿射？線性？"><a href="#仿射？線性？" class="headerlink" title="仿射？線性？"></a>仿射？線性？</h2><p>其實是可以將仿射看成線性的。假設</p>
<script type="math/tex; mode=display">
Wx + b = \begin{bmatrix}
w_{11}& w_{12}& \cdots& w_{1n} \\\\
\vdots& \vdots& \ddots& \vdots \\\\
w_{m1}& w_{m2}& \cdots& w_{mn} \\\\
\end{bmatrix}
\begin{bmatrix}
x_{1} \\\\
\vdots \\\\
x_{n} \\\\
\end{bmatrix} + \begin{bmatrix}
b_{1} \\\\
\vdots \\\\
b_{m} \\\\
\end{bmatrix}</script><p>然後把 $W$ 跟 $b$ 合併，有點像高中學的增廣矩陣那樣，就變成了：</p>
<script type="math/tex; mode=display">
= \begin{bmatrix}
w_{11}& w_{12}& \cdots& w_{1n}& b_{1} \\\\
\vdots& \vdots& \ddots& \vdots& \vdots \\\\
w_{m1}& w_{m2}& \cdots& w_{mn}& b_{m} \\\\
\end{bmatrix}
\begin{bmatrix}
x_{1} \\\\
\vdots \\\\
x_{n} \\\\
1
\end{bmatrix} = W'x'</script><p>這樣就可以把 $b$ 吸收到 $W$ 裡面，整體就變成線性的了。</p>
<h2 id="先談談線性轉換"><a href="#先談談線性轉換" class="headerlink" title="先談談線性轉換"></a>先談談線性轉換</h2><p>談 activation function 之前先要談談線性轉換。去除掉 activation function 後的神經網路層只剩下 $Wx + b$ 的部份，而如果講這部份看成線性，我們就可以用線性代數裡的東西來解釋它。</p>
<p>有上到比較後面的線性代數的同學，應該有爬過 SVD 這座高山。基本上，SVD 是一種矩陣分解的技巧，可以適用各式的矩陣（只要是可分解的）。SVD 可以告訴我們一些關於線性運算的特質。</p>
<p>推薦可以看周老師的線代啟示錄 <a href="https://ccjou.wordpress.com/2009/09/01/%E5%A5%87%E7%95%B0%E5%80%BC%E5%88%86%E8%A7%A3-svd/" target="_blank" rel="noopener">奇異值分解 (SVD)</a></p>
<p>我們可以知道一個矩陣可以被看成線性轉換，而矩陣這個線性轉換可以被分解成 3 個矩陣：</p>
                    
                        <a href="/2018/07/27/activation-function/" class="postShorten-excerpt_link link">
                            繼續閱讀
                        </a>
                        
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-right">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a class="link-unstyled" href="/2018/07/25/10-basis-for-topology/">
                            Basis for topology
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2018-07-25T23:57:56+08:00">
	
		    7月 25, 2018
    	
    </time>
    
        <span>分類 </span>
        
    <a class="category-link" href="/categories/Topology/">Topology</a>


    
</div>

            </div>
            
                <div class="postShorten-excerpt">
                    <p>上一篇介紹完基本的拓樸結構，接下來我們來看基底（basis）的部份。</p>
<p>有上過線性代數的朋友們應該會知道，向量如果滿足線性獨立可以 span 到整個空間，而一個空間有他們的基底。</p>
<p>你可以把向量看成一種數學物件，空間的話就是很多這種數學物件的集合，那相對基底的話就是要擴展成整個空間的基本元素。</p>
<p>拓樸也是一樣的，開集（open set）也是一種數學物件，一個拓樸空間中所包含的元素就是開集，那麼就會很自然的想知道他的基底是什麼？</p>
                    
                        <a href="/2018/07/25/10-basis-for-topology/" class="postShorten-excerpt_link link">
                            繼續閱讀
                        </a>
                        
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-right">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a class="link-unstyled" href="/2018/07/22/09-topology/">
                            Topology space and topology
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2018-07-22T00:32:23+08:00">
	
		    7月 22, 2018
    	
    </time>
    
        <span>分類 </span>
        
    <a class="category-link" href="/categories/Topology/">Topology</a>


    
</div>

            </div>
            
                <div class="postShorten-excerpt">
                    <p>我們終於來到拓樸學的大門口了！</p>
<p>（謎：前面走那麼多圈是在幹什麼的！</p>
<p>拓樸其實是幾何學的拓展，他往更基礎的方向去，當我們在探討幾何學的時候，其實我們研究的是空間關係。</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/8/85/Stereographic_projection_in_3D.png" alt=""></p>
                    
                        <a href="/2018/07/22/09-topology/" class="postShorten-excerpt_link link">
                            繼續閱讀
                        </a>
                        
                    
                </div>
            
        </div>
        
    </article>
    
    <div class="pagination-bar">
    <ul class="pagination">
        
          <li class="pagination-prev">
            <a class="btn btn--default btn--small" href="/archives/2018/page/3/">
              <i class="fa fa-angle-left text-base icon-mr"></i>
              <span>上一頁</span>
            </a>
          </li>
        
        
          <li class="pagination-next">
            <a class="btn btn--default btn--small" href="/archives/2018/page/5/">
              <span>下一頁</span>
              <i class="fa fa-angle-right text-base icon-ml"></i>
            </a>
          </li>
        
        <li class="pagination-number">第 4 頁 共 6 頁</li>
    </ul>
</div>

</section>



                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2020 Yueh-Hua Tu. All Rights Reserved.
    </span>
</footer>

            </div>
            
        </div>
        


<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-remove"></i>
        </div>
        
            <h4 id="about-card-name">Yueh-Hua Tu</h4>
        
            <div id="about-card-bio"><p>目標是計算生物學家！&lt;/br&gt;Systems Biology, Computational Biology, Machine Learning&lt;/br&gt;Julia Taiwan 發起人</p>
</div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                <p>研發替代役研究助理</p>

            </div>
        
        
            <div id="about-card-location">
                <i class="fa fa-map-marker"></i>
                <br/>
                Taiwan
            </div>
        
    </div>
</div>

        
        
<div id="cover" style="background-image:url('/assets/images/cover.jpg');"></div>
        <!--SCRIPTS-->

<script src="/assets/js/script-xzfezjobyekpxrjktw5tz6muvzqfsbmo5n6atk3p5om9ulfptldi3p7cyqd8.min.js"></script>

<!--SCRIPTS END-->


    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>
